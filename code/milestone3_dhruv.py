# -*- coding: utf-8 -*-
"""Milestone3_Dhruv.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wih9fi6BEMtPZdg5GrBP8YJlTYN4wtCl

# Check Optimizer params and do we make the final classifier (Linear layers) bigger?
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip "/content/drive/MyDrive/ESE 5460 Term Project/Cleaned Data/Images/test_images.zip"

!unzip "/content/drive/MyDrive/ESE 5460 Term Project/Cleaned Data/Images/train_images.zip"

!unzip "/content/drive/MyDrive/ESE 5460 Term Project/Cleaned Data/Images/validation_images.zip"

# Import Libraries
import pandas as pd
import numpy as np
import torch
import sys
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from torchvision import transforms

## Ensure TensorFlow is not used
import os
os.environ["USE_TF"] = "0"

# For reproducability
random_state = 42

"""# Changed this"""

train_data = "/content/drive/MyDrive/ESE 5460 Term Project/Cleaned Data/Text/train.csv"
test_data = "/content/drive/MyDrive/ESE 5460 Term Project/Cleaned Data/Text/test_5k.csv"
validation_data = "/content/drive/MyDrive/ESE 5460 Term Project/Cleaned Data/Text/validation_5k.csv"

import pandas as pd

TRAIN_DATA = pd.read_csv(train_data)
VALIDATION_DATA = pd.read_csv(validation_data, index_col=0)
TEST_DATA = pd.read_csv(test_data, index_col=0)

TRAIN_DATA

"""# Getting image path from indexes"""

TRAIN_DATA['image_num'] = TRAIN_DATA.index.astype(str).str.zfill(5)
VALIDATION_DATA['image_num'] = VALIDATION_DATA.index.astype(str).str.zfill(5)
TEST_DATA['image_num'] = TEST_DATA.index.astype(str).str.zfill(5)

TRAIN_DATA

VALIDATION_DATA

# Ignore rows in corrupted_indices.txt files
def filter_out_corrupted_rows(split, DF):
    # File with corrupted indices
    # THIS PATH IS FOR DHRUV LAPTOP
    if split == "train":
        corrupted_indices_file = f"/content/drive/MyDrive/ESE 5460 Term Project/Cleaned Data/New Corrupted File Information/{split}_corrupted_indices.txt"

    else:
        corrupted_indices_file = f"/content/drive/MyDrive/ESE 5460 Term Project/Cleaned Data/New Corrupted File Information/{split}_5k_corrupted_indices.txt"

    # Store list of corrupted indices
    corrupted_indices = None

    # Get list of corrupted indices
    with open(corrupted_indices_file, "r") as f:
        corrupted_indices = list(int(line.strip()) for line in f if line.strip())

    print(f"Split: {split}, Corrupted Indices: {corrupted_indices}, Length: {len(corrupted_indices)}")

    # Filter out corrupted rows
    DF = DF.drop(index = corrupted_indices)

    return DF

TRAIN_DATA = filter_out_corrupted_rows("train", TRAIN_DATA)
VALIDATION_DATA = filter_out_corrupted_rows("validation", VALIDATION_DATA)
TEST_DATA = filter_out_corrupted_rows("test", TEST_DATA)

TRAIN_DATA

VALIDATION_DATA

class RedditDataset(Dataset):
    def __init__(self, df, image_dir, transform=None):
        self.df = df
        self.image_dir = image_dir
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        # Fetch text
        text = row['clean_title']

        # Get image number
        image_num = row['image_num']

        # Fetch Image
        img_path = os.path.join(self.image_dir, f"{image_num}.jpg")
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)

        # Label
        label = torch.tensor(row['2_way_label'], dtype=torch.long)

        return text, image, label

train_tfms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

val_test_tfms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

def collate_fn(batch):
    texts, images, labels = zip(*batch)
    images = torch.stack(images)
    labels = torch.stack(labels)
    return list(texts), images, labels

train_dataset = RedditDataset(
    df = TRAIN_DATA,
    image_dir = "train_images",
    transform = train_tfms
)

validation_dataset = RedditDataset(
    df = VALIDATION_DATA,
    image_dir = "validation_images",
    transform = val_test_tfms
)

test_dataset = RedditDataset(
    df = TEST_DATA,
    image_dir = "test_images",
    transform = val_test_tfms
)

B = 32

train_loader = DataLoader(
    train_dataset,
    batch_size=B,
    shuffle=True,
    collate_fn=collate_fn
)

validation_loader = DataLoader(
    validation_dataset,
    batch_size=B,
    shuffle=False,
    collate_fn=collate_fn
)

test_loader = DataLoader(
    test_dataset,
    batch_size=B,
    shuffle=False,
    collate_fn=collate_fn
)

## Sanity Check
texts, imgs, labels = next(iter(train_loader))
print("Number of texts:", len(texts))
print("Example text:", texts[0])
print("Images shape:", imgs.shape)      # (B, 3, 224, 224)
print("Labels shape:", labels.shape)
print("Labels:", labels)

# Use CPU/MPS if possible
import sys
device = None
if "google.colab" in sys.modules:
    # Running in Colab
    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
else:
    # Not in Colab (e.g., Mac)
    device = torch.device("mps") if torch.backends.mps.is_available() else torch.device("cpu")

print("Using device:", device)

"""# Freezing weights for BERT and ResNet"""

import torch
import torch.nn as nn
from transformers import BertTokenizer, BertModel
from torchvision import models

class MultimodalClassifier(nn.Module):
    def __init__(self, num_classes=2):
        super().__init__()

        # ----- TEXT ENCODER -----
        self.bert = BertModel.from_pretrained("bert-base-uncased")
        self.tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

        bert_hidden = 768  # CLS embedding size

        # ----- IMAGE ENCODER -----
        resnet = models.resnet101(weights='IMAGENET1K_V1')
        # Remove the final FC head → get (B, 2048)
        resnet.fc = nn.Identity()
        self.cnn = resnet
        img_hidden = 2048

        # Freeze BERT
        for param in self.bert.parameters():
            param.requires_grad = False

        # Freeze ResNet
        for param in self.cnn.parameters():
            param.requires_grad = False

        # ----- FUSION + CLASSIFICATION HEAD -----
        fusion_dim = bert_hidden + img_hidden
        self.classifier = nn.Sequential(
            nn.Linear(fusion_dim, num_classes)
        )

    def forward(self, texts, images):
        # Encode text
        encoding = self.tokenizer(
            texts,
            padding=True,
            truncation=True,
            max_length=self.tokenizer.model_max_length,
            return_tensors="pt"
        ).to(images.device)

        bert_outputs = self.bert(**encoding)
        cls_emb = bert_outputs.last_hidden_state[:, 0, :]   # (B, 768)

        # Encode image
        img_feat = self.cnn(images)       # (B, 2048, 1, 1)
        img_feat = img_feat.view(img_feat.size(0), -1)  # (B, 2048)

        # Fuse
        fused = torch.cat([cls_emb, img_feat], dim=1)

        # Classify
        logits = self.classifier(fused)
        return logits

p0 = (TRAIN_DATA['2_way_label'] == 0).mean()
p1 = (TRAIN_DATA['2_way_label'] == 1).mean()
print(f"{p0*100:.2f}% label=0, {p1*100:.2f}% label=1")

class_weights = torch.tensor([p1, p0]).float().to(device)
criterion = nn.CrossEntropyLoss(weight=class_weights)
print("Class Weights:", class_weights)

model = MultimodalClassifier(num_classes=2).to(device)

optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)

from tqdm import tqdm

def train_model(model, train_loader, val_loader, device, criterion, optimizer, num_epochs=3):
    model = model.to(device)

    # --- simple bookkeeping lists ---
    train_losses, train_accuracies = [], []
    val_losses, val_accuracies = [], []

    global_step = 0

    for epoch in range(num_epochs):
        print(f"\n===== Epoch {epoch+1}/{num_epochs} =====")
        model.train()

        for texts, images, labels in tqdm(train_loader):
            images = images.to(device)
            labels = labels.to(device)

            # ---- Forward + Backward ----
            optimizer.zero_grad()
            outputs = model(texts, images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # ---- Track training metrics at every update ----
            preds = torch.argmax(outputs, dim=1)
            train_acc = (preds == labels).float().mean().item()
            train_losses.append(loss.item())
            train_accuracies.append(train_acc)

            # ---- Validate every 100 weight updates ----
            if global_step % 100 == 0:
                model.eval()
                val_loss_total = 0.0
                val_correct_total = 0
                val_samples_total = 0

                with torch.no_grad():
                    for v_texts, v_images, v_labels in val_loader:
                        v_images = v_images.to(device)
                        v_labels = v_labels.to(device)
                        v_outputs = model(v_texts, v_images)
                        v_loss = criterion(v_outputs, v_labels)

                        v_preds = torch.argmax(v_outputs, dim=1)
                        val_correct_total += (v_preds == v_labels).sum().item()
                        val_samples_total += v_labels.size(0)
                        val_loss_total += v_loss.item() * v_labels.size(0)  # sum up batch loss

                avg_val_loss = val_loss_total / val_samples_total
                avg_val_acc = val_correct_total / val_samples_total

                val_losses.append(avg_val_loss)
                val_accuracies.append(avg_val_acc)

                # save model in Milestone 3 directory
                save_dir = "Milestone #3"
                if not os.path.exists(save_dir):
                    os.makedirs(save_dir)

                torch.save(model.state_dict(), f"{save_dir}/pretrained_latest_model.pt")

                print(
                    f"[Update {global_step}] "
                    f"Train Loss: {loss.item():.4f}, Train Acc: {train_acc:.4f} | "
                    f"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}"
                )
                model.train()

            global_step += 1

    # save model in Milestone 3 directory
    save_dir = "Milestone #3"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    torch.save(model.state_dict(), f"{save_dir}/pretrained_latest_model.pt")

    return train_losses, train_accuracies, val_losses, val_accuracies

train_losses, train_accs, val_losses, val_accs = train_model(
    model=model,
    train_loader=train_loader,
    val_loader=validation_loader,
    device=device,
    criterion=criterion,
    optimizer=optimizer,
    num_epochs=3
)

import pickle

with open("multimodal_pretrained_metrics.pkl", "wb") as f:
    pickle.dump({
        "train_losses": train_losses,
        "train_accs": train_accs,
        "val_losses": val_losses,
        "val_accs": val_accs
    }, f)

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def compute_metrics(logits, labels):
    logits = np.array(logits)
    labels = np.array(labels)
    predictions = np.argmax(logits, axis=-1)

    return {
        "accuracy": accuracy_score(labels, predictions),

        "pos_precision": precision_score(labels, predictions, pos_label=1, average="binary", zero_division=0),
        "pos_recall": recall_score(labels, predictions, pos_label=1, average="binary", zero_division=0),
        "pos_f1": f1_score(labels, predictions, pos_label=1, average="binary", zero_division=0),

        "neg_precision": precision_score(labels, predictions, pos_label=0, average="binary", zero_division=0),
        "neg_recall": recall_score(labels, predictions, pos_label=0, average="binary", zero_division=0),
        "neg_f1": f1_score(labels, predictions, pos_label=0, average="binary", zero_division=0),

        "f1_macro": f1_score(labels, predictions, average="macro"),
        "f1_micro": f1_score(labels, predictions, average="micro"),
        "f1_weighted": f1_score(labels, predictions, average="weighted"),
    }

def evaluate_model(model, dataloader):
    model.eval()
    all_logits = []
    all_labels = []

    with torch.no_grad():
        for txts, imgs, labels in dataloader:
            imgs = imgs.to(device)
            labels = labels.to(device)

            outputs = model(txts, imgs)      # logits
            all_logits.append(outputs.cpu().numpy())
            all_labels.append(labels.cpu().numpy())

    all_logits = np.concatenate(all_logits, axis=0)
    all_labels = np.concatenate(all_labels, axis=0)

    return compute_metrics(all_logits, all_labels)

# ---- evaluate ----
train_metrics = evaluate_model(model, train_loader)
val_metrics   = evaluate_model(model, validation_loader)
test_metrics  = evaluate_model(model, test_loader)

# ---- save to CSV ----
pd.DataFrame([train_metrics]).to_csv("Multimodal_pretrained_train_metrics.csv", index=False)
pd.DataFrame([val_metrics]).to_csv("Multimodal_pretrained_val_metrics.csv", index=False)
pd.DataFrame([test_metrics]).to_csv("Multimodal_pretrained_test_metrics.csv", index=False)

"""# Finetuned model"""

import torch
import torch.nn as nn
from transformers import BertTokenizer, BertModel
from torchvision import models

class FineMultimodalClassifier(nn.Module):
    def __init__(self, num_classes=2):
        super().__init__()

        # ----- TEXT ENCODER -----
        self.bert = BertModel.from_pretrained("bert-base-uncased")
        self.tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

        bert_hidden = 768  # CLS embedding size

        # ----- IMAGE ENCODER -----
        resnet = models.resnet101(weights='IMAGENET1K_V1')
        resnet.fc = nn.Identity()
        # Remove the final FC head → get (B, 2048)
        self.cnn = resnet
        img_hidden = 2048

        # ----- FUSION + CLASSIFICATION HEAD -----
        fusion_dim = bert_hidden + img_hidden
        self.classifier = nn.Sequential(
            nn.Linear(fusion_dim, num_classes)
        )

    def forward(self, texts, images):
        # Encode text
        encoding = self.tokenizer(
            texts,
            padding=True,
            truncation=True,
            max_length=self.tokenizer.model_max_length,
            return_tensors="pt"
        ).to(images.device)

        bert_outputs = self.bert(**encoding)
        cls_emb = bert_outputs.last_hidden_state[:, 0, :]   # (B, 768)

        # Encode image
        img_feat = self.cnn(images)       # (B, 2048, 1, 1)
        img_feat = img_feat.view(img_feat.size(0), -1)  # (B, 2048)

        # Fuse
        fused = torch.cat([cls_emb, img_feat], dim=1)

        # Classify
        logits = self.classifier(fused)
        return logits

p0 = (TRAIN_DATA['2_way_label'] == 0).mean()
p1 = (TRAIN_DATA['2_way_label'] == 1).mean()
print(f"{p0*100:.2f}% label=0, {p1*100:.2f}% label=1")

class_weights = torch.tensor([p1, p0]).float().to(device)
criterion = nn.CrossEntropyLoss(weight=class_weights)
print("Class Weights:", class_weights)

model = FineMultimodalClassifier(num_classes=2).to(device)

optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)

from tqdm import tqdm

def train_model(model, train_loader, val_loader, device, criterion, optimizer, num_epochs=3):
    model = model.to(device)

    # --- simple bookkeeping lists ---
    train_losses, train_accuracies = [], []
    val_losses, val_accuracies = [], []

    global_step = 0

    for epoch in range(num_epochs):
        print(f"\n===== Epoch {epoch+1}/{num_epochs} =====")
        model.train()

        for texts, images, labels in tqdm(train_loader):
            images = images.to(device)
            labels = labels.to(device)

            # ---- Forward + Backward ----
            optimizer.zero_grad()
            outputs = model(texts, images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # ---- Track training metrics at every update ----
            preds = torch.argmax(outputs, dim=1)
            train_acc = (preds == labels).float().mean().item()
            train_losses.append(loss.item())
            train_accuracies.append(train_acc)

            # ---- Validate every 100 weight updates ----
            if global_step % 100 == 0:
                model.eval()
                val_loss_total = 0.0
                val_correct_total = 0
                val_samples_total = 0

                with torch.no_grad():
                    for v_texts, v_images, v_labels in val_loader:
                        v_images = v_images.to(device)
                        v_labels = v_labels.to(device)
                        v_outputs = model(v_texts, v_images)
                        v_loss = criterion(v_outputs, v_labels)

                        v_preds = torch.argmax(v_outputs, dim=1)
                        val_correct_total += (v_preds == v_labels).sum().item()
                        val_samples_total += v_labels.size(0)
                        val_loss_total += v_loss.item() * v_labels.size(0)  # sum up batch loss

                avg_val_loss = val_loss_total / val_samples_total
                avg_val_acc = val_correct_total / val_samples_total

                val_losses.append(avg_val_loss)
                val_accuracies.append(avg_val_acc)

                # save model in Milestone 3 directory
                save_dir = "Milestone #3"
                if not os.path.exists(save_dir):
                    os.makedirs(save_dir)

                torch.save(model.state_dict(), f"{save_dir}/finetuned_latest_model.pt")

                print(
                    f"[Update {global_step}] "
                    f"Train Loss: {loss.item():.4f}, Train Acc: {train_acc:.4f} | "
                    f"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}"
                )
                model.train()

            global_step += 1

    # save model in Milestone 3 directory
    save_dir = "Milestone #3"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    torch.save(model.state_dict(), f"{save_dir}/finetuned_latest_model.pt")
    return train_losses, train_accuracies, val_losses, val_accuracies

train_losses, train_accs, val_losses, val_accs = train_model(
    model=model,
    train_loader=train_loader,
    val_loader=validation_loader,
    device=device,
    criterion=criterion,
    optimizer=optimizer,
    num_epochs=3
)

import pickle

with open("multimodal_finetuned_metrics.pkl", "wb") as f:
    pickle.dump({
        "train_losses": train_losses,
        "train_accs": train_accs,
        "val_losses": val_losses,
        "val_accs": val_accs
    }, f)

# ---- evaluate ----
train_metrics = evaluate_model(model, train_loader)
val_metrics   = evaluate_model(model, validation_loader)
test_metrics  = evaluate_model(model, test_loader)

# ---- save to CSV ----
pd.DataFrame([train_metrics]).to_csv("Multimodal_finetuned_train_metrics.csv", index=False)
pd.DataFrame([val_metrics]).to_csv("Multimodal_finetuned_val_metrics.csv", index=False)
pd.DataFrame([test_metrics]).to_csv("Multimodal_finetuned_test_metrics.csv", index=False)

