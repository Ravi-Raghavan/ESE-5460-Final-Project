{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa3e2d6",
   "metadata": {},
   "source": [
    "# Milestone #2: Ravi Raghavan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10cb88",
   "metadata": {},
   "source": [
    "## Milestone Aim\n",
    "\n",
    "The goal is to use a **pretrained BERT-Base, Uncased** model and **fine-tune it on the r/Fakeeddit dataset**.\n",
    "\n",
    "This work presents evaluation results on: \n",
    "- Pretrained BERT\n",
    "- Fine-Tuned BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010603eb",
   "metadata": {},
   "source": [
    "## Script Sanity Check\n",
    "\n",
    "Please ensure your directory is structured as follows\n",
    "\n",
    "```text\n",
    "cleaned_data/\n",
    "├── test_5k.csv\n",
    "├── train.csv\n",
    "└── validation_5k.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439c021f",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a2acde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "\n",
    "## Ensure TensorFlow is not used\n",
    "import os\n",
    "os.environ[\"USE_TF\"] = \"0\"\n",
    "\n",
    "# Import Hugging Face Tooling\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "\n",
    "# Define data directory\n",
    "DATA_DIR = \"cleaned_data\"\n",
    "\n",
    "# Define file paths\n",
    "TRAIN_DATA_FILE = os.path.join(DATA_DIR, \"train.csv\")\n",
    "VALIDATION_DATA_FILE = os.path.join(DATA_DIR, \"validation_5k.csv\")\n",
    "TEST_DATA_FILE = os.path.join(DATA_DIR, \"test_5k.csv\")\n",
    "\n",
    "# For reproducability\n",
    "random_state = 42\n",
    "\n",
    "# Use CPU/MPS if possible\n",
    "device = None\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Running in Colab\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "else:\n",
    "    # Not in Colab (e.g., Mac)\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de9611",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c462c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = pd.read_csv(TRAIN_DATA_FILE)\n",
    "VALIDATION_DATA = pd.read_csv(VALIDATION_DATA_FILE, index_col = 0)\n",
    "TEST_DATA = pd.read_csv(TEST_DATA_FILE, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1809b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore rows in corrupted_indices.txt files\n",
    "def filter_out_corrupted_rows(split, DF):\n",
    "    # File with corrupted indices\n",
    "    if split == \"train\":\n",
    "        corrupted_indices_file = f\"{split}_corrupted_indices.txt\"\n",
    "    else:\n",
    "        corrupted_indices_file = f\"{split}_5k_corrupted_indices.txt\"\n",
    "\n",
    "    # Store list of corrupted indices\n",
    "    corrupted_indices = None\n",
    "\n",
    "    # Get list of corrupted indices\n",
    "    with open(corrupted_indices_file, \"r\") as f:\n",
    "        corrupted_indices = list(int(line.strip()) for line in f if line.strip())\n",
    "\n",
    "    print(f\"Split: {split}, Corrupted Indices: {corrupted_indices}, Length: {len(corrupted_indices)}\")\n",
    "\n",
    "    # Filter out corrupted rows\n",
    "    DF = DF.drop(index = corrupted_indices)\n",
    "\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a89f79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train, Corrupted Indices: [2862, 26040, 28337, 18547, 13374, 11288, 31984, 18451, 19000, 22479, 8048, 32075, 22918, 5586, 19345, 12770, 32189, 14628, 9081, 6611, 2927], Length: 21\n",
      "Split: validation, Corrupted Indices: [6568, 32176], Length: 2\n",
      "Split: test, Corrupted Indices: [29133, 9437, 26504, 11394], Length: 4\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = filter_out_corrupted_rows(\"train\", TRAIN_DATA)\n",
    "VALIDATION_DATA = filter_out_corrupted_rows(\"validation\", VALIDATION_DATA)\n",
    "TEST_DATA = filter_out_corrupted_rows(\"test\", TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30eaef3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>image_url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>3_way_label</th>\n",
       "      <th>6_way_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this spongebob squarepants branded battery</td>\n",
       "      <td>2019-07-30 20:00:50</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/f39wxxk8yhd31.jpg?widt...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>award for careless talk</td>\n",
       "      <td>2011-09-03 17:26:23</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/KgPHCi1u3fY5j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>propagandaposters</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>four aligned airplanes</td>\n",
       "      <td>2017-11-20 06:05:45</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/88v9axk19phx.jpg?width...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>198</td>\n",
       "      <td>confusing_perspective</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>columbus discovers the new world</td>\n",
       "      <td>2019-08-28 15:40:17</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/x4wzpd0am7j31.jpg?widt...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>318</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feed me drummmmssssssss</td>\n",
       "      <td>2014-05-09 13:23:59</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/yNN57loQnVhLk...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  clean_title          created_utc  \\\n",
       "0  this spongebob squarepants branded battery  2019-07-30 20:00:50   \n",
       "1                     award for careless talk  2011-09-03 17:26:23   \n",
       "2                      four aligned airplanes  2017-11-20 06:05:45   \n",
       "3            columbus discovers the new world  2019-08-28 15:40:17   \n",
       "4                     feed me drummmmssssssss  2014-05-09 13:23:59   \n",
       "\n",
       "        domain                                          image_url  \\\n",
       "0    i.redd.it  https://preview.redd.it/f39wxxk8yhd31.jpg?widt...   \n",
       "1  i.imgur.com  https://external-preview.redd.it/KgPHCi1u3fY5j...   \n",
       "2    i.redd.it  https://preview.redd.it/88v9axk19phx.jpg?width...   \n",
       "3    i.redd.it  https://preview.redd.it/x4wzpd0am7j31.jpg?widt...   \n",
       "4  i.imgur.com  https://external-preview.redd.it/yNN57loQnVhLk...   \n",
       "\n",
       "   num_comments  score              subreddit  upvote_ratio  2_way_label  \\\n",
       "0           4.0     33      mildlyinteresting          0.95            1   \n",
       "1           1.0     14      propagandaposters          1.00            0   \n",
       "2          24.0    198  confusing_perspective          0.98            0   \n",
       "3           5.0    318        fakehistoryporn          0.98            0   \n",
       "4           0.0      3             pareidolia          0.62            0   \n",
       "\n",
       "   3_way_label  6_way_label  \n",
       "0            0            0  \n",
       "1            1            5  \n",
       "2            2            2  \n",
       "3            2            2  \n",
       "4            2            2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249d8404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>image_url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>3_way_label</th>\n",
       "      <th>6_way_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>not as heartwarming as it could have been anth...</td>\n",
       "      <td>2019-09-19 17:48:33</td>\n",
       "      <td>lifestyle.clickhole.com</td>\n",
       "      <td>https://external-preview.redd.it/850kBbKdgMKfz...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>theonion</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20669</th>\n",
       "      <td>other discussions</td>\n",
       "      <td>2013-12-09 23:58:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://i.dailymail.co.uk/i/pix/2013/12/09/arti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>psbattle_artwork</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13179</th>\n",
       "      <td>on reflection oc</td>\n",
       "      <td>2015-01-12 17:14:55</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/tiFw8Ggb178E4...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565</th>\n",
       "      <td>viet congo setting booby trap</td>\n",
       "      <td>2019-02-27 09:57:07</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/mj81gkh533j21.jpg?widt...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15504</th>\n",
       "      <td>chief has some happy shoulder armour</td>\n",
       "      <td>2013-02-20 01:00:02</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/kqqIlnAOZxzxA...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_title          created_utc  \\\n",
       "8637   not as heartwarming as it could have been anth...  2019-09-19 17:48:33   \n",
       "20669                                  other discussions  2013-12-09 23:58:43   \n",
       "13179                                   on reflection oc  2015-01-12 17:14:55   \n",
       "20565                      viet congo setting booby trap  2019-02-27 09:57:07   \n",
       "15504               chief has some happy shoulder armour  2013-02-20 01:00:02   \n",
       "\n",
       "                        domain  \\\n",
       "8637   lifestyle.clickhole.com   \n",
       "20669                      NaN   \n",
       "13179              i.imgur.com   \n",
       "20565                i.redd.it   \n",
       "15504              i.imgur.com   \n",
       "\n",
       "                                               image_url  num_comments  score  \\\n",
       "8637   https://external-preview.redd.it/850kBbKdgMKfz...           0.0     15   \n",
       "20669  http://i.dailymail.co.uk/i/pix/2013/12/09/arti...           NaN      0   \n",
       "13179  https://external-preview.redd.it/tiFw8Ggb178E4...           0.0      3   \n",
       "20565  https://preview.redd.it/mj81gkh533j21.jpg?widt...           4.0     14   \n",
       "15504  https://external-preview.redd.it/kqqIlnAOZxzxA...           0.0      6   \n",
       "\n",
       "              subreddit  upvote_ratio  2_way_label  3_way_label  6_way_label  \n",
       "8637           theonion          0.86            0            2            1  \n",
       "20669  psbattle_artwork           NaN            0            2            4  \n",
       "13179        pareidolia          0.67            0            2            2  \n",
       "20565   fakehistoryporn          0.80            0            2            2  \n",
       "15504        pareidolia          1.00            0            2            2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b40b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>image_url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>3_way_label</th>\n",
       "      <th>6_way_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>young homosexuals gather outside of a nightclu...</td>\n",
       "      <td>2018-07-29 13:59:38</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/16j830998wc11.jpg?widt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32879</th>\n",
       "      <td>cara al sol facing the sun a series of posters...</td>\n",
       "      <td>2013-05-20 18:25:00</td>\n",
       "      <td>imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/S_nXt5X8VMqZD...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19</td>\n",
       "      <td>propagandaposters</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>he is awake and rises from the depths</td>\n",
       "      <td>2013-10-13 20:02:17</td>\n",
       "      <td>imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/JetvyFQFm4fYt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>the reason germany invades france and not spain</td>\n",
       "      <td>2018-09-03 08:22:07</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/ws91cs7lgzj11.png?widt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15061</th>\n",
       "      <td>frozen body preserved on mount everest nsfw</td>\n",
       "      <td>2017-09-12 08:10:21</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/zxwc8gq8uelz.jpg?width...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_title          created_utc  \\\n",
       "19660  young homosexuals gather outside of a nightclu...  2018-07-29 13:59:38   \n",
       "32879  cara al sol facing the sun a series of posters...  2013-05-20 18:25:00   \n",
       "15071              he is awake and rises from the depths  2013-10-13 20:02:17   \n",
       "5198     the reason germany invades france and not spain  2018-09-03 08:22:07   \n",
       "15061        frozen body preserved on mount everest nsfw  2017-09-12 08:10:21   \n",
       "\n",
       "          domain                                          image_url  \\\n",
       "19660  i.redd.it  https://preview.redd.it/16j830998wc11.jpg?widt...   \n",
       "32879  imgur.com  https://external-preview.redd.it/S_nXt5X8VMqZD...   \n",
       "15071  imgur.com  https://external-preview.redd.it/JetvyFQFm4fYt...   \n",
       "5198   i.redd.it  https://preview.redd.it/ws91cs7lgzj11.png?widt...   \n",
       "15061  i.redd.it  https://preview.redd.it/zxwc8gq8uelz.jpg?width...   \n",
       "\n",
       "       num_comments  score          subreddit  upvote_ratio  2_way_label  \\\n",
       "19660           1.0     75    fakehistoryporn          0.92            0   \n",
       "32879           4.0     19  propagandaposters          0.89            0   \n",
       "15071           0.0      7         pareidolia          0.99            0   \n",
       "5198            0.0     57    fakehistoryporn          0.97            0   \n",
       "15061           0.0     24    fakehistoryporn          1.00            0   \n",
       "\n",
       "       3_way_label  6_way_label  \n",
       "19660            2            2  \n",
       "32879            1            5  \n",
       "15071            2            2  \n",
       "5198             2            2  \n",
       "15061            2            2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DATA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9320f8a0",
   "metadata": {},
   "source": [
    "## Compute Class Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ffab1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.62961294778248% of our dataset has label = 0 and 55.37038705221752% of our dataset has label = 1\n"
     ]
    }
   ],
   "source": [
    "# Compute Class Proportions\n",
    "p0 = (TRAIN_DATA['2_way_label'] == 0).mean() # Computes the percentage of our training dataset that has label = 0 [Fake News]\n",
    "p1 = (TRAIN_DATA['2_way_label'] == 1).mean() # Computes the percentage of our training dataset that has label = 1 [Non-Fake News]\n",
    "print(f\"{p0  * 100}% of our dataset has label = 0 and {p1  * 100}% of our dataset has label = 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646829c0",
   "metadata": {},
   "source": [
    "## Define Prior Adjusted Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9cd843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: tensor([0.5537, 0.4463], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Define Weighted Loss Criterion\n",
    "class_weights = torch.tensor([p1, p0]).float().to(device)\n",
    "custom_criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "print(f\"Class Weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c5719",
   "metadata": {},
   "source": [
    "## Fetch BERT From HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fca89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Fetch BERT Model from HuggingFace\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(bert_model_name, num_labels = 2) # num_labels = 2 since we have 2 classes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60e77f",
   "metadata": {},
   "source": [
    "## Create `Hugging Face` Datasets [Train + Dev + Test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7105f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hf_dataset = Dataset.from_pandas(TRAIN_DATA)\n",
    "dev_hf_dataset = Dataset.from_pandas(VALIDATION_DATA)\n",
    "test_hf_dataset = Dataset.from_pandas(TEST_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a2188",
   "metadata": {},
   "source": [
    "## Tokenize Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637e204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(row):\n",
    "  tokens = tokenizer(row['clean_title'], truncation = True, padding = 'max_length', max_length = tokenizer.model_max_length)\n",
    "  row['input_ids'] = tokens['input_ids']\n",
    "  row['attention_mask'] = tokens['attention_mask']\n",
    "  row['token_type_ids'] = tokens['token_type_ids']\n",
    "  row['label'] = int(row['2_way_label'])\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f0bd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898dd34841d14806ad669d19f33cd4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33303 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c60643afea4be98905c30d71219f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8a282722464b0e9ebc3b4a63d801c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4996 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_hf_dataset = train_hf_dataset.map(tokenize_function)\n",
    "dev_hf_dataset = dev_hf_dataset.map(tokenize_function)\n",
    "test_hf_dataset = test_hf_dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc838c",
   "metadata": {},
   "source": [
    "## Define Accuracy, Precision, Recall, and F1 Metrics from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bec9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load('recall')\n",
    "f1_metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c9b1c",
   "metadata": {},
   "source": [
    "## Define a compute_metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495ce2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    # Get the model predictions\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Return Metrics\n",
    "    return {\n",
    "        \"accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)['accuracy'], # Accuracy\n",
    "        \"pos_precision\": precision_metric.compute(predictions=predictions, references=labels, pos_label = 1, average = 'binary', zero_division = 0)[\"precision\"], # Precision on the Class w/ Label = 1 [Hate Samples]\n",
    "        \"pos_recall\": recall_metric.compute(predictions=predictions, references=labels, pos_label = 1, average = 'binary', zero_division = 0)['recall'], # Recall on the Class w/ Label = 1 [Hate Samples]\n",
    "        \"pos_f1\": f1_metric.compute(predictions=predictions, references=labels, pos_label = 1, average = 'binary')[\"f1\"], # F1 Score on the Class w/ Label = 1 [Hate Samples]\n",
    "        \"neg_precision\": precision_metric.compute(predictions=predictions, references=labels, pos_label = 0, average = 'binary', zero_division = 0)['precision'], # Precision on the Class w/ Label = 0 [Non-Hate Samples]\n",
    "        \"neg_recall\": recall_metric.compute(predictions=predictions, references=labels, pos_label = 0, average = 'binary', zero_division = 0)['recall'], # Recall on the Class w/ Label = 0 [Non-Hate Samples]\n",
    "        \"neg_f1\": f1_metric.compute(predictions=predictions, references=labels, pos_label = 0, average = 'binary')['f1'], # F1 Score on the Class w/ Label = 0 [Non-Hate Samples]\n",
    "        \"f1_macro\": f1_metric.compute(predictions=predictions, references=labels, average='macro')['f1'], # Macro F1 Score\n",
    "        \"f1_micro\": f1_metric.compute(predictions=predictions, references=labels, average='micro')['f1'], # Micro F1 Score\n",
    "        \"f1_weighted\": f1_metric.compute(predictions=predictions, references=labels, average='weighted')['f1'], # Weighted F1 Score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26113c3",
   "metadata": {},
   "source": [
    "## Subclass the `Trainer` Class from HuggingFace to use Custom Loss Criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38626840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subclassed Trainer that enables us to use the custom loss function defined earlier\n",
    "class SubTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs = False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = custom_criterion(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d630f6c",
   "metadata": {},
   "source": [
    "## **Initialize the `TrainingArguments` and `Trainer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4785702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"Milestone2-Baseline-BERT-FineTuning\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"steps\",      # save checkpoints every N steps\n",
    "    save_steps=100,             # save every 100 steps\n",
    "    eval_strategy=\"steps\",      # evaluate every N steps\n",
    "    eval_steps=100,             # evaluate every 100 steps\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,          # log every 100 steps\n",
    "    report_to=\"none\",\n",
    "    full_determinism=True\n",
    ")\n",
    "\n",
    "trainer = SubTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_hf_dataset,\n",
    "    eval_dataset=dev_hf_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3e91e",
   "metadata": {},
   "source": [
    "# **Evaluate Pre-Trained Model on Train, Dev, and Test Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8b9add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1512' max='1041' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1041/1041 12:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train evaluation metrics to Milestone #2 Pre-Trained BERT Baseline train Results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dev evaluation metrics to Milestone #2 Pre-Trained BERT Baseline dev Results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test evaluation metrics to Milestone #2 Pre-Trained BERT Baseline test Results.csv\n"
     ]
    }
   ],
   "source": [
    "# Split: Train, Dev, or Test\n",
    "def generate_evaluation_results(split):\n",
    "    dataset = None\n",
    "    if split == \"train\":\n",
    "        dataset = train_hf_dataset\n",
    "    elif split == \"dev\" or split == \"validation\" or split == \"val\":\n",
    "        dataset = dev_hf_dataset\n",
    "    elif split == \"test\":\n",
    "        dataset = test_hf_dataset\n",
    "    \n",
    "    results = trainer.evaluate(eval_dataset=dataset, metric_key_prefix=split)\n",
    "    df_results = pd.DataFrame([results])\n",
    "    df_results.to_csv(f\"Milestone #2 Pre-Trained BERT Baseline {split} Results.csv\", index=False)\n",
    "    print(f\"Saved {split} evaluation metrics to Milestone #2 Pre-Trained BERT Baseline {split} Results.csv\")\n",
    "\n",
    "# Generate Evaluation Results on Train, Dev, and Test Splits\n",
    "generate_evaluation_results(\"train\")\n",
    "generate_evaluation_results(\"dev\")\n",
    "generate_evaluation_results(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2d952",
   "metadata": {},
   "source": [
    "# **Train the Model: `Fine-Tuning`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ee435fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3123' max='3123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3123/3123 3:30:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos Precision</th>\n",
       "      <th>Pos Recall</th>\n",
       "      <th>Pos F1</th>\n",
       "      <th>Neg Precision</th>\n",
       "      <th>Neg Recall</th>\n",
       "      <th>Neg F1</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.575700</td>\n",
       "      <td>0.487445</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.770908</td>\n",
       "      <td>0.750926</td>\n",
       "      <td>0.878022</td>\n",
       "      <td>0.809516</td>\n",
       "      <td>0.807736</td>\n",
       "      <td>0.637629</td>\n",
       "      <td>0.712673</td>\n",
       "      <td>0.761094</td>\n",
       "      <td>0.770908</td>\n",
       "      <td>0.766365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>0.471866</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.791317</td>\n",
       "      <td>0.839089</td>\n",
       "      <td>0.771563</td>\n",
       "      <td>0.803911</td>\n",
       "      <td>0.741633</td>\n",
       "      <td>0.815896</td>\n",
       "      <td>0.776994</td>\n",
       "      <td>0.790452</td>\n",
       "      <td>0.791317</td>\n",
       "      <td>0.791917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.460400</td>\n",
       "      <td>0.454135</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.804722</td>\n",
       "      <td>0.807258</td>\n",
       "      <td>0.850956</td>\n",
       "      <td>0.828531</td>\n",
       "      <td>0.801156</td>\n",
       "      <td>0.747194</td>\n",
       "      <td>0.773234</td>\n",
       "      <td>0.800883</td>\n",
       "      <td>0.804722</td>\n",
       "      <td>0.803892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.431254</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.799720</td>\n",
       "      <td>0.844626</td>\n",
       "      <td>0.782750</td>\n",
       "      <td>0.812512</td>\n",
       "      <td>0.752263</td>\n",
       "      <td>0.820835</td>\n",
       "      <td>0.785055</td>\n",
       "      <td>0.798783</td>\n",
       "      <td>0.799720</td>\n",
       "      <td>0.800277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.464500</td>\n",
       "      <td>0.416621</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.810524</td>\n",
       "      <td>0.802588</td>\n",
       "      <td>0.872970</td>\n",
       "      <td>0.836301</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.732824</td>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.805707</td>\n",
       "      <td>0.810524</td>\n",
       "      <td>0.809037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.437300</td>\n",
       "      <td>0.412407</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.809724</td>\n",
       "      <td>0.777608</td>\n",
       "      <td>0.919885</td>\n",
       "      <td>0.842784</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.672654</td>\n",
       "      <td>0.759058</td>\n",
       "      <td>0.800921</td>\n",
       "      <td>0.809724</td>\n",
       "      <td>0.805477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.826731</td>\n",
       "      <td>0.827207</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.847589</td>\n",
       "      <td>0.826066</td>\n",
       "      <td>0.774136</td>\n",
       "      <td>0.799258</td>\n",
       "      <td>0.823424</td>\n",
       "      <td>0.826731</td>\n",
       "      <td>0.826054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0.390640</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.826130</td>\n",
       "      <td>0.827931</td>\n",
       "      <td>0.866474</td>\n",
       "      <td>0.846764</td>\n",
       "      <td>0.823642</td>\n",
       "      <td>0.775932</td>\n",
       "      <td>0.799075</td>\n",
       "      <td>0.822920</td>\n",
       "      <td>0.826130</td>\n",
       "      <td>0.825515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.428900</td>\n",
       "      <td>0.392939</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.818727</td>\n",
       "      <td>0.867850</td>\n",
       "      <td>0.793937</td>\n",
       "      <td>0.829250</td>\n",
       "      <td>0.768169</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>0.806823</td>\n",
       "      <td>0.818036</td>\n",
       "      <td>0.818727</td>\n",
       "      <td>0.819257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.375042</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.835934</td>\n",
       "      <td>0.837426</td>\n",
       "      <td>0.873692</td>\n",
       "      <td>0.855175</td>\n",
       "      <td>0.833887</td>\n",
       "      <td>0.788954</td>\n",
       "      <td>0.810798</td>\n",
       "      <td>0.832987</td>\n",
       "      <td>0.835934</td>\n",
       "      <td>0.835402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.318200</td>\n",
       "      <td>0.408970</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.833533</td>\n",
       "      <td>0.841013</td>\n",
       "      <td>0.862865</td>\n",
       "      <td>0.851799</td>\n",
       "      <td>0.823666</td>\n",
       "      <td>0.797036</td>\n",
       "      <td>0.810132</td>\n",
       "      <td>0.830966</td>\n",
       "      <td>0.833533</td>\n",
       "      <td>0.833233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.269100</td>\n",
       "      <td>0.422119</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.834334</td>\n",
       "      <td>0.853401</td>\n",
       "      <td>0.846626</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.811027</td>\n",
       "      <td>0.819039</td>\n",
       "      <td>0.815013</td>\n",
       "      <td>0.832507</td>\n",
       "      <td>0.834334</td>\n",
       "      <td>0.834411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>0.401553</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.837335</td>\n",
       "      <td>0.830967</td>\n",
       "      <td>0.887044</td>\n",
       "      <td>0.858090</td>\n",
       "      <td>0.846569</td>\n",
       "      <td>0.775483</td>\n",
       "      <td>0.809468</td>\n",
       "      <td>0.833779</td>\n",
       "      <td>0.837335</td>\n",
       "      <td>0.836425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.258800</td>\n",
       "      <td>0.400139</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.835934</td>\n",
       "      <td>0.859565</td>\n",
       "      <td>0.841573</td>\n",
       "      <td>0.850474</td>\n",
       "      <td>0.807877</td>\n",
       "      <td>0.828918</td>\n",
       "      <td>0.818262</td>\n",
       "      <td>0.834368</td>\n",
       "      <td>0.835934</td>\n",
       "      <td>0.836121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.425135</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.831333</td>\n",
       "      <td>0.825676</td>\n",
       "      <td>0.881992</td>\n",
       "      <td>0.852905</td>\n",
       "      <td>0.839549</td>\n",
       "      <td>0.768298</td>\n",
       "      <td>0.802345</td>\n",
       "      <td>0.827625</td>\n",
       "      <td>0.831333</td>\n",
       "      <td>0.830377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.262700</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.830732</td>\n",
       "      <td>0.844365</td>\n",
       "      <td>0.851678</td>\n",
       "      <td>0.848006</td>\n",
       "      <td>0.813436</td>\n",
       "      <td>0.804670</td>\n",
       "      <td>0.809029</td>\n",
       "      <td>0.828518</td>\n",
       "      <td>0.830732</td>\n",
       "      <td>0.830639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>0.411832</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.836935</td>\n",
       "      <td>0.858504</td>\n",
       "      <td>0.845182</td>\n",
       "      <td>0.851791</td>\n",
       "      <td>0.811013</td>\n",
       "      <td>0.826673</td>\n",
       "      <td>0.818768</td>\n",
       "      <td>0.835280</td>\n",
       "      <td>0.836935</td>\n",
       "      <td>0.837077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.392772</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.840136</td>\n",
       "      <td>0.848903</td>\n",
       "      <td>0.865752</td>\n",
       "      <td>0.857245</td>\n",
       "      <td>0.828729</td>\n",
       "      <td>0.808262</td>\n",
       "      <td>0.818368</td>\n",
       "      <td>0.837806</td>\n",
       "      <td>0.840136</td>\n",
       "      <td>0.839922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.393337</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.834934</td>\n",
       "      <td>0.852281</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.850895</td>\n",
       "      <td>0.813506</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0.815147</td>\n",
       "      <td>0.833021</td>\n",
       "      <td>0.834934</td>\n",
       "      <td>0.834966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>0.408210</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.835534</td>\n",
       "      <td>0.862402</td>\n",
       "      <td>0.836882</td>\n",
       "      <td>0.849451</td>\n",
       "      <td>0.804244</td>\n",
       "      <td>0.833857</td>\n",
       "      <td>0.818783</td>\n",
       "      <td>0.834117</td>\n",
       "      <td>0.835534</td>\n",
       "      <td>0.835786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>0.432073</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.841737</td>\n",
       "      <td>0.850071</td>\n",
       "      <td>0.867557</td>\n",
       "      <td>0.858725</td>\n",
       "      <td>0.830876</td>\n",
       "      <td>0.809609</td>\n",
       "      <td>0.820105</td>\n",
       "      <td>0.839415</td>\n",
       "      <td>0.841737</td>\n",
       "      <td>0.841516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.535565</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.835534</td>\n",
       "      <td>0.835456</td>\n",
       "      <td>0.875857</td>\n",
       "      <td>0.855180</td>\n",
       "      <td>0.835643</td>\n",
       "      <td>0.785361</td>\n",
       "      <td>0.809722</td>\n",
       "      <td>0.832451</td>\n",
       "      <td>0.835534</td>\n",
       "      <td>0.834925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.557269</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.838735</td>\n",
       "      <td>0.840083</td>\n",
       "      <td>0.875857</td>\n",
       "      <td>0.857597</td>\n",
       "      <td>0.836890</td>\n",
       "      <td>0.792546</td>\n",
       "      <td>0.814114</td>\n",
       "      <td>0.835856</td>\n",
       "      <td>0.838735</td>\n",
       "      <td>0.838222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.101300</td>\n",
       "      <td>0.611746</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.833733</td>\n",
       "      <td>0.822688</td>\n",
       "      <td>0.892458</td>\n",
       "      <td>0.856154</td>\n",
       "      <td>0.850402</td>\n",
       "      <td>0.760665</td>\n",
       "      <td>0.803034</td>\n",
       "      <td>0.829594</td>\n",
       "      <td>0.833733</td>\n",
       "      <td>0.832485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.557591</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.837935</td>\n",
       "      <td>0.850054</td>\n",
       "      <td>0.859257</td>\n",
       "      <td>0.854630</td>\n",
       "      <td>0.822485</td>\n",
       "      <td>0.811405</td>\n",
       "      <td>0.816908</td>\n",
       "      <td>0.835769</td>\n",
       "      <td>0.837935</td>\n",
       "      <td>0.837822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.592643</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.834534</td>\n",
       "      <td>0.851156</td>\n",
       "      <td>0.850235</td>\n",
       "      <td>0.850695</td>\n",
       "      <td>0.813901</td>\n",
       "      <td>0.814998</td>\n",
       "      <td>0.814449</td>\n",
       "      <td>0.832572</td>\n",
       "      <td>0.834534</td>\n",
       "      <td>0.834545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.582954</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.832733</td>\n",
       "      <td>0.843939</td>\n",
       "      <td>0.856730</td>\n",
       "      <td>0.850287</td>\n",
       "      <td>0.818307</td>\n",
       "      <td>0.802874</td>\n",
       "      <td>0.810517</td>\n",
       "      <td>0.830402</td>\n",
       "      <td>0.832733</td>\n",
       "      <td>0.832566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.557876</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.836535</td>\n",
       "      <td>0.845474</td>\n",
       "      <td>0.862865</td>\n",
       "      <td>0.854081</td>\n",
       "      <td>0.824885</td>\n",
       "      <td>0.803772</td>\n",
       "      <td>0.814191</td>\n",
       "      <td>0.834136</td>\n",
       "      <td>0.836535</td>\n",
       "      <td>0.836307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.551571</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.854286</td>\n",
       "      <td>0.825265</td>\n",
       "      <td>0.803772</td>\n",
       "      <td>0.814377</td>\n",
       "      <td>0.834331</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.836503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.585466</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.836134</td>\n",
       "      <td>0.841737</td>\n",
       "      <td>0.867557</td>\n",
       "      <td>0.854452</td>\n",
       "      <td>0.828665</td>\n",
       "      <td>0.797036</td>\n",
       "      <td>0.812543</td>\n",
       "      <td>0.833497</td>\n",
       "      <td>0.836134</td>\n",
       "      <td>0.835778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.581944</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.836134</td>\n",
       "      <td>0.838654</td>\n",
       "      <td>0.872248</td>\n",
       "      <td>0.855121</td>\n",
       "      <td>0.832703</td>\n",
       "      <td>0.791199</td>\n",
       "      <td>0.811421</td>\n",
       "      <td>0.833271</td>\n",
       "      <td>0.836134</td>\n",
       "      <td>0.835649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "trainer.train() # Always Resume from Last Checkpoint to Save Time\n",
    "trainer.save_model('Milestone2-Baseline-BERT-FinalModel') # Save the Final Model\n",
    "trainer.save_state() # Save the State of the Trainer (e.g. Losses, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f7e60",
   "metadata": {},
   "source": [
    "# **Evaluate Fine-Tuned Model on Train, Dev, and Test Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aab0758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1355' max='1041' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1041/1041 10:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train evaluation metrics to Milestone #2 Fine-Tuned BERT Baseline train Results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dev evaluation metrics to Milestone #2 Fine-Tuned BERT Baseline dev Results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test evaluation metrics to Milestone #2 Fine-Tuned BERT Baseline test Results.csv\n"
     ]
    }
   ],
   "source": [
    "# Split: Train, Dev, or Test\n",
    "def generate_evaluation_results(split):\n",
    "    dataset = None\n",
    "    if split == \"train\":\n",
    "        dataset = train_hf_dataset\n",
    "    elif split == \"dev\" or split == \"validation\" or split == \"val\":\n",
    "        dataset = dev_hf_dataset\n",
    "    elif split == \"test\":\n",
    "        dataset = test_hf_dataset\n",
    "    \n",
    "    results = trainer.evaluate(eval_dataset=dataset, metric_key_prefix=split)\n",
    "    df_results = pd.DataFrame([results])\n",
    "    df_results.to_csv(f\"Milestone #2 Fine-Tuned BERT Baseline {split} Results.csv\", index=False)\n",
    "    print(f\"Saved {split} evaluation metrics to Milestone #2 Fine-Tuned BERT Baseline {split} Results.csv\")\n",
    "\n",
    "# Generate Evaluation Results on Train, Dev, and Test Splits\n",
    "generate_evaluation_results(\"train\")\n",
    "generate_evaluation_results(\"dev\")\n",
    "generate_evaluation_results(\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
