{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa3e2d6",
   "metadata": {},
   "source": [
    "# Milestone #2: Ravi Raghavan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10cb88",
   "metadata": {},
   "source": [
    "## Milestone Aim\n",
    "\n",
    "The goal is to use a **pretrained BERT-Base, Uncased** model and **fine-tune it on the r/Fakeeddit dataset**.\n",
    "\n",
    "This work presents evaluation results on: \n",
    "- Pretrained BERT\n",
    "- Fine-Tuned BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010603eb",
   "metadata": {},
   "source": [
    "## Script Sanity Check\n",
    "\n",
    "Please ensure your directory is structured as follows\n",
    "\n",
    "```text\n",
    "cleaned_data/\n",
    "├── test_5k.csv\n",
    "├── train.csv\n",
    "└── validation_5k.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439c021f",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a2acde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "\n",
    "## Ensure TensorFlow is not used\n",
    "import os\n",
    "os.environ[\"USE_TF\"] = \"0\"\n",
    "\n",
    "# Import Hugging Face Tooling\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "\n",
    "# Define data directory\n",
    "DATA_DIR = \"cleaned_data\"\n",
    "\n",
    "# Define file paths\n",
    "TRAIN_DATA_FILE = os.path.join(DATA_DIR, \"train.csv\")\n",
    "VALIDATION_DATA_FILE = os.path.join(DATA_DIR, \"validation_5k.csv\")\n",
    "TEST_DATA_FILE = os.path.join(DATA_DIR, \"test_5k.csv\")\n",
    "\n",
    "# For reproducability\n",
    "random_state = 42\n",
    "\n",
    "# Use CPU/MPS if possible\n",
    "device = None\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Running in Colab\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "else:\n",
    "    # Not in Colab (e.g., Mac)\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de9611",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c462c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = pd.read_csv(TRAIN_DATA_FILE)\n",
    "VALIDATION_DATA = pd.read_csv(VALIDATION_DATA_FILE, index_col = 0)\n",
    "TEST_DATA = pd.read_csv(TEST_DATA_FILE, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1809b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore rows in corrupted_indices.txt files\n",
    "def filter_out_corrupted_rows(split, DF):\n",
    "    # File with corrupted indices\n",
    "    if split == \"train\":\n",
    "        corrupted_indices_file = f\"{split}_corrupted_indices.txt\"\n",
    "    else:\n",
    "        corrupted_indices_file = f\"{split}_5k_corrupted_indices.txt\"\n",
    "\n",
    "    # Store list of corrupted indices\n",
    "    corrupted_indices = None\n",
    "\n",
    "    # Get list of corrupted indices\n",
    "    with open(corrupted_indices_file, \"r\") as f:\n",
    "        corrupted_indices = list(int(line.strip()) for line in f if line.strip())\n",
    "\n",
    "    print(f\"Split: {split}, Corrupted Indices: {corrupted_indices}, Length: {len(corrupted_indices)}\")\n",
    "\n",
    "    # Filter out corrupted rows\n",
    "    DF = DF.drop(index = corrupted_indices)\n",
    "\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a89f79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train, Corrupted Indices: [2862, 26040, 28337, 18547, 13374, 11288, 31984, 18451, 19000, 22479, 8048, 32075, 22918, 5586, 19345, 12770, 32189, 14628, 9081, 6611, 2927], Length: 21\n",
      "Split: validation, Corrupted Indices: [6568, 32176], Length: 2\n",
      "Split: test, Corrupted Indices: [29133, 9437, 26504, 11394], Length: 4\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = filter_out_corrupted_rows(\"train\", TRAIN_DATA)\n",
    "VALIDATION_DATA = filter_out_corrupted_rows(\"validation\", VALIDATION_DATA)\n",
    "TEST_DATA = filter_out_corrupted_rows(\"test\", TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30eaef3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>image_url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>3_way_label</th>\n",
       "      <th>6_way_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this spongebob squarepants branded battery</td>\n",
       "      <td>2019-07-30 20:00:50</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/f39wxxk8yhd31.jpg?widt...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>award for careless talk</td>\n",
       "      <td>2011-09-03 17:26:23</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/KgPHCi1u3fY5j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>propagandaposters</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>four aligned airplanes</td>\n",
       "      <td>2017-11-20 06:05:45</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/88v9axk19phx.jpg?width...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>198</td>\n",
       "      <td>confusing_perspective</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>columbus discovers the new world</td>\n",
       "      <td>2019-08-28 15:40:17</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/x4wzpd0am7j31.jpg?widt...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>318</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feed me drummmmssssssss</td>\n",
       "      <td>2014-05-09 13:23:59</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/yNN57loQnVhLk...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  clean_title          created_utc  \\\n",
       "0  this spongebob squarepants branded battery  2019-07-30 20:00:50   \n",
       "1                     award for careless talk  2011-09-03 17:26:23   \n",
       "2                      four aligned airplanes  2017-11-20 06:05:45   \n",
       "3            columbus discovers the new world  2019-08-28 15:40:17   \n",
       "4                     feed me drummmmssssssss  2014-05-09 13:23:59   \n",
       "\n",
       "        domain                                          image_url  \\\n",
       "0    i.redd.it  https://preview.redd.it/f39wxxk8yhd31.jpg?widt...   \n",
       "1  i.imgur.com  https://external-preview.redd.it/KgPHCi1u3fY5j...   \n",
       "2    i.redd.it  https://preview.redd.it/88v9axk19phx.jpg?width...   \n",
       "3    i.redd.it  https://preview.redd.it/x4wzpd0am7j31.jpg?widt...   \n",
       "4  i.imgur.com  https://external-preview.redd.it/yNN57loQnVhLk...   \n",
       "\n",
       "   num_comments  score              subreddit  upvote_ratio  2_way_label  \\\n",
       "0           4.0     33      mildlyinteresting          0.95            1   \n",
       "1           1.0     14      propagandaposters          1.00            0   \n",
       "2          24.0    198  confusing_perspective          0.98            0   \n",
       "3           5.0    318        fakehistoryporn          0.98            0   \n",
       "4           0.0      3             pareidolia          0.62            0   \n",
       "\n",
       "   3_way_label  6_way_label  \n",
       "0            0            0  \n",
       "1            1            5  \n",
       "2            2            2  \n",
       "3            2            2  \n",
       "4            2            2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249d8404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>image_url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>3_way_label</th>\n",
       "      <th>6_way_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>not as heartwarming as it could have been anth...</td>\n",
       "      <td>2019-09-19 17:48:33</td>\n",
       "      <td>lifestyle.clickhole.com</td>\n",
       "      <td>https://external-preview.redd.it/850kBbKdgMKfz...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>theonion</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20669</th>\n",
       "      <td>other discussions</td>\n",
       "      <td>2013-12-09 23:58:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://i.dailymail.co.uk/i/pix/2013/12/09/arti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>psbattle_artwork</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13179</th>\n",
       "      <td>on reflection oc</td>\n",
       "      <td>2015-01-12 17:14:55</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/tiFw8Ggb178E4...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565</th>\n",
       "      <td>viet congo setting booby trap</td>\n",
       "      <td>2019-02-27 09:57:07</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/mj81gkh533j21.jpg?widt...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15504</th>\n",
       "      <td>chief has some happy shoulder armour</td>\n",
       "      <td>2013-02-20 01:00:02</td>\n",
       "      <td>i.imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/kqqIlnAOZxzxA...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_title          created_utc  \\\n",
       "8637   not as heartwarming as it could have been anth...  2019-09-19 17:48:33   \n",
       "20669                                  other discussions  2013-12-09 23:58:43   \n",
       "13179                                   on reflection oc  2015-01-12 17:14:55   \n",
       "20565                      viet congo setting booby trap  2019-02-27 09:57:07   \n",
       "15504               chief has some happy shoulder armour  2013-02-20 01:00:02   \n",
       "\n",
       "                        domain  \\\n",
       "8637   lifestyle.clickhole.com   \n",
       "20669                      NaN   \n",
       "13179              i.imgur.com   \n",
       "20565                i.redd.it   \n",
       "15504              i.imgur.com   \n",
       "\n",
       "                                               image_url  num_comments  score  \\\n",
       "8637   https://external-preview.redd.it/850kBbKdgMKfz...           0.0     15   \n",
       "20669  http://i.dailymail.co.uk/i/pix/2013/12/09/arti...           NaN      0   \n",
       "13179  https://external-preview.redd.it/tiFw8Ggb178E4...           0.0      3   \n",
       "20565  https://preview.redd.it/mj81gkh533j21.jpg?widt...           4.0     14   \n",
       "15504  https://external-preview.redd.it/kqqIlnAOZxzxA...           0.0      6   \n",
       "\n",
       "              subreddit  upvote_ratio  2_way_label  3_way_label  6_way_label  \n",
       "8637           theonion          0.86            0            2            1  \n",
       "20669  psbattle_artwork           NaN            0            2            4  \n",
       "13179        pareidolia          0.67            0            2            2  \n",
       "20565   fakehistoryporn          0.80            0            2            2  \n",
       "15504        pareidolia          1.00            0            2            2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b40b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>image_url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>3_way_label</th>\n",
       "      <th>6_way_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>young homosexuals gather outside of a nightclu...</td>\n",
       "      <td>2018-07-29 13:59:38</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/16j830998wc11.jpg?widt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32879</th>\n",
       "      <td>cara al sol facing the sun a series of posters...</td>\n",
       "      <td>2013-05-20 18:25:00</td>\n",
       "      <td>imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/S_nXt5X8VMqZD...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19</td>\n",
       "      <td>propagandaposters</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>he is awake and rises from the depths</td>\n",
       "      <td>2013-10-13 20:02:17</td>\n",
       "      <td>imgur.com</td>\n",
       "      <td>https://external-preview.redd.it/JetvyFQFm4fYt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>pareidolia</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>the reason germany invades france and not spain</td>\n",
       "      <td>2018-09-03 08:22:07</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/ws91cs7lgzj11.png?widt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15061</th>\n",
       "      <td>frozen body preserved on mount everest nsfw</td>\n",
       "      <td>2017-09-12 08:10:21</td>\n",
       "      <td>i.redd.it</td>\n",
       "      <td>https://preview.redd.it/zxwc8gq8uelz.jpg?width...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>fakehistoryporn</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_title          created_utc  \\\n",
       "19660  young homosexuals gather outside of a nightclu...  2018-07-29 13:59:38   \n",
       "32879  cara al sol facing the sun a series of posters...  2013-05-20 18:25:00   \n",
       "15071              he is awake and rises from the depths  2013-10-13 20:02:17   \n",
       "5198     the reason germany invades france and not spain  2018-09-03 08:22:07   \n",
       "15061        frozen body preserved on mount everest nsfw  2017-09-12 08:10:21   \n",
       "\n",
       "          domain                                          image_url  \\\n",
       "19660  i.redd.it  https://preview.redd.it/16j830998wc11.jpg?widt...   \n",
       "32879  imgur.com  https://external-preview.redd.it/S_nXt5X8VMqZD...   \n",
       "15071  imgur.com  https://external-preview.redd.it/JetvyFQFm4fYt...   \n",
       "5198   i.redd.it  https://preview.redd.it/ws91cs7lgzj11.png?widt...   \n",
       "15061  i.redd.it  https://preview.redd.it/zxwc8gq8uelz.jpg?width...   \n",
       "\n",
       "       num_comments  score          subreddit  upvote_ratio  2_way_label  \\\n",
       "19660           1.0     75    fakehistoryporn          0.92            0   \n",
       "32879           4.0     19  propagandaposters          0.89            0   \n",
       "15071           0.0      7         pareidolia          0.99            0   \n",
       "5198            0.0     57    fakehistoryporn          0.97            0   \n",
       "15061           0.0     24    fakehistoryporn          1.00            0   \n",
       "\n",
       "       3_way_label  6_way_label  \n",
       "19660            2            2  \n",
       "32879            1            5  \n",
       "15071            2            2  \n",
       "5198             2            2  \n",
       "15061            2            2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DATA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9320f8a0",
   "metadata": {},
   "source": [
    "## Compute Class Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ffab1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.62961294778248% of our dataset has label = 0 and 55.37038705221752% of our dataset has label = 1\n"
     ]
    }
   ],
   "source": [
    "# Compute Class Proportions\n",
    "p0 = (TRAIN_DATA['2_way_label'] == 0).mean() # Computes the percentage of our training dataset that has label = 0 [Fake News]\n",
    "p1 = (TRAIN_DATA['2_way_label'] == 1).mean() # Computes the percentage of our training dataset that has label = 1 [Non-Fake News]\n",
    "print(f\"{p0  * 100}% of our dataset has label = 0 and {p1  * 100}% of our dataset has label = 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646829c0",
   "metadata": {},
   "source": [
    "## Define Prior Adjusted Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9cd843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: tensor([0.5537, 0.4463], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Define Weighted Loss Criterion\n",
    "class_weights = torch.tensor([p1, p0]).float().to(device)\n",
    "custom_criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "print(f\"Class Weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c5719",
   "metadata": {},
   "source": [
    "## Fetch BERT From HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fca89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Fetch BERT Model from HuggingFace\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(bert_model_name, num_labels = 2) # num_labels = 2 since we have 2 classes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60e77f",
   "metadata": {},
   "source": [
    "## Create `Hugging Face` Datasets [Train + Dev + Test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7105f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hf_dataset = Dataset.from_pandas(TRAIN_DATA)\n",
    "dev_hf_dataset = Dataset.from_pandas(VALIDATION_DATA)\n",
    "test_hf_dataset = Dataset.from_pandas(TEST_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a2188",
   "metadata": {},
   "source": [
    "## Tokenize Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637e204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(row):\n",
    "  tokens = tokenizer(row['clean_title'], truncation = True, padding = 'max_length', max_length = tokenizer.model_max_length)\n",
    "  row['input_ids'] = tokens['input_ids']\n",
    "  row['attention_mask'] = tokens['attention_mask']\n",
    "  row['token_type_ids'] = tokens['token_type_ids']\n",
    "  row['label'] = int(row['2_way_label'])\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f0bd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8549833f4a4a6d87d1dfe1d39d962b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33303 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa615e2c253d4d598fcc2f8aed18a0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af57af77a3b4c9d87e2690ddc6c9318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4996 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_hf_dataset = train_hf_dataset.map(tokenize_function)\n",
    "dev_hf_dataset = dev_hf_dataset.map(tokenize_function)\n",
    "test_hf_dataset = test_hf_dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc838c",
   "metadata": {},
   "source": [
    "## Define Accuracy, Precision, Recall, and F1 Metrics from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bec9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load('recall')\n",
    "f1_metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c9b1c",
   "metadata": {},
   "source": [
    "## Define a compute_metrics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495ce2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    # Get the model predictions\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Return Metrics\n",
    "    return {\n",
    "        \"accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)['accuracy'], # Accuracy\n",
    "        \"pos_precision\": precision_metric.compute(predictions=predictions, references=labels, pos_label = 1, average = 'binary', zero_division = 0)[\"precision\"], # Precision on the Class w/ Label = 1 [Hate Samples]\n",
    "        \"pos_recall\": recall_metric.compute(predictions=predictions, references=labels, pos_label = 1, average = 'binary', zero_division = 0)['recall'], # Recall on the Class w/ Label = 1 [Hate Samples]\n",
    "        \"pos_f1\": f1_metric.compute(predictions=predictions, references=labels, pos_label = 1, average = 'binary')[\"f1\"], # F1 Score on the Class w/ Label = 1 [Hate Samples]\n",
    "        \"neg_precision\": precision_metric.compute(predictions=predictions, references=labels, pos_label = 0, average = 'binary', zero_division = 0)['precision'], # Precision on the Class w/ Label = 0 [Non-Hate Samples]\n",
    "        \"neg_recall\": recall_metric.compute(predictions=predictions, references=labels, pos_label = 0, average = 'binary', zero_division = 0)['recall'], # Recall on the Class w/ Label = 0 [Non-Hate Samples]\n",
    "        \"neg_f1\": f1_metric.compute(predictions=predictions, references=labels, pos_label = 0, average = 'binary')['f1'], # F1 Score on the Class w/ Label = 0 [Non-Hate Samples]\n",
    "        \"f1_macro\": f1_metric.compute(predictions=predictions, references=labels, average='macro')['f1'], # Macro F1 Score\n",
    "        \"f1_micro\": f1_metric.compute(predictions=predictions, references=labels, average='micro')['f1'], # Micro F1 Score\n",
    "        \"f1_weighted\": f1_metric.compute(predictions=predictions, references=labels, average='weighted')['f1'], # Weighted F1 Score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26113c3",
   "metadata": {},
   "source": [
    "## Subclass the `Trainer` Class from HuggingFace to use Custom Loss Criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38626840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subclassed Trainer that enables us to use the custom loss function defined earlier\n",
    "class SubTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs = False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = custom_criterion(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d630f6c",
   "metadata": {},
   "source": [
    "## **Initialize the `TrainingArguments` and `Trainer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4785702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"Milestone2-Baseline-BERT-FineTuning\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"steps\",      # save checkpoints every N steps\n",
    "    save_steps=100,             # save every 100 steps\n",
    "    eval_strategy=\"steps\",      # evaluate every N steps\n",
    "    eval_steps=100,             # evaluate every 100 steps\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,          # log every 100 steps\n",
    "    report_to=\"none\",\n",
    "    full_determinism=True\n",
    ")\n",
    "\n",
    "trainer = SubTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_hf_dataset,\n",
    "    eval_dataset=dev_hf_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3e91e",
   "metadata": {},
   "source": [
    "# **Evaluate Pre-Trained Model on Train, Dev, and Test Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8b9add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1512' max='1041' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1041/1041 13:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train evaluation metrics to Milestone #2 Pre-Trained BERT Baseline train Results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dev evaluation metrics to Milestone #2 Pre-Trained BERT Baseline dev Results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test evaluation metrics to Milestone #2 Pre-Trained BERT Baseline test Results.csv\n"
     ]
    }
   ],
   "source": [
    "# Split: Train, Dev, or Test\n",
    "def generate_evaluation_results(split):\n",
    "    dataset = None\n",
    "    if split == \"train\":\n",
    "        dataset = train_hf_dataset\n",
    "    elif split == \"dev\" or split == \"validation\" or split == \"val\":\n",
    "        dataset = dev_hf_dataset\n",
    "    elif split == \"test\":\n",
    "        dataset = test_hf_dataset\n",
    "    \n",
    "    results = trainer.evaluate(eval_dataset=dataset, metric_key_prefix=split)\n",
    "    df_results = pd.DataFrame([results])\n",
    "    df_results.to_csv(f\"Milestone #2 Pre-Trained BERT Baseline {split} Results.csv\", index=False)\n",
    "    print(f\"Saved {split} evaluation metrics to Milestone #2 Pre-Trained BERT Baseline {split} Results.csv\")\n",
    "\n",
    "# Generate Evaluation Results on Train, Dev, and Test Splits\n",
    "generate_evaluation_results(\"train\")\n",
    "generate_evaluation_results(\"dev\")\n",
    "generate_evaluation_results(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2d952",
   "metadata": {},
   "source": [
    "# **Train the Model: `Fine-Tuning`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ee435fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3123' max='3123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3123/3123 3:34:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Pos Precision</th>\n",
       "      <th>Pos Recall</th>\n",
       "      <th>Pos F1</th>\n",
       "      <th>Neg Precision</th>\n",
       "      <th>Neg Recall</th>\n",
       "      <th>Neg F1</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.594400</td>\n",
       "      <td>0.532574</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.740496</td>\n",
       "      <td>0.701037</td>\n",
       "      <td>0.927463</td>\n",
       "      <td>0.798509</td>\n",
       "      <td>0.849099</td>\n",
       "      <td>0.507858</td>\n",
       "      <td>0.635572</td>\n",
       "      <td>0.717040</td>\n",
       "      <td>0.740496</td>\n",
       "      <td>0.725908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.498200</td>\n",
       "      <td>0.460483</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.831431</td>\n",
       "      <td>0.788524</td>\n",
       "      <td>0.809409</td>\n",
       "      <td>0.752743</td>\n",
       "      <td>0.801078</td>\n",
       "      <td>0.776158</td>\n",
       "      <td>0.792784</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.794593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.451927</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.808523</td>\n",
       "      <td>0.824624</td>\n",
       "      <td>0.831469</td>\n",
       "      <td>0.828032</td>\n",
       "      <td>0.788113</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.784022</td>\n",
       "      <td>0.806027</td>\n",
       "      <td>0.808523</td>\n",
       "      <td>0.808422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.452300</td>\n",
       "      <td>0.429028</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.803121</td>\n",
       "      <td>0.852744</td>\n",
       "      <td>0.779502</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.752130</td>\n",
       "      <td>0.832510</td>\n",
       "      <td>0.790281</td>\n",
       "      <td>0.802380</td>\n",
       "      <td>0.803121</td>\n",
       "      <td>0.803697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.460100</td>\n",
       "      <td>0.408444</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.803430</td>\n",
       "      <td>0.879105</td>\n",
       "      <td>0.839566</td>\n",
       "      <td>0.829603</td>\n",
       "      <td>0.732375</td>\n",
       "      <td>0.777963</td>\n",
       "      <td>0.808765</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.812117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.415498</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.806923</td>\n",
       "      <td>0.777164</td>\n",
       "      <td>0.913750</td>\n",
       "      <td>0.839940</td>\n",
       "      <td>0.862644</td>\n",
       "      <td>0.674001</td>\n",
       "      <td>0.756743</td>\n",
       "      <td>0.798342</td>\n",
       "      <td>0.806923</td>\n",
       "      <td>0.802869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.395243</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.820328</td>\n",
       "      <td>0.804950</td>\n",
       "      <td>0.892097</td>\n",
       "      <td>0.846286</td>\n",
       "      <td>0.844837</td>\n",
       "      <td>0.731028</td>\n",
       "      <td>0.783823</td>\n",
       "      <td>0.815054</td>\n",
       "      <td>0.820328</td>\n",
       "      <td>0.818454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.425900</td>\n",
       "      <td>0.389144</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.825930</td>\n",
       "      <td>0.825402</td>\n",
       "      <td>0.870083</td>\n",
       "      <td>0.847154</td>\n",
       "      <td>0.826673</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.797862</td>\n",
       "      <td>0.822508</td>\n",
       "      <td>0.825930</td>\n",
       "      <td>0.825191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>0.398438</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.817927</td>\n",
       "      <td>0.879641</td>\n",
       "      <td>0.778058</td>\n",
       "      <td>0.825737</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.867535</td>\n",
       "      <td>0.809384</td>\n",
       "      <td>0.817561</td>\n",
       "      <td>0.817927</td>\n",
       "      <td>0.818451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.395072</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.831132</td>\n",
       "      <td>0.814766</td>\n",
       "      <td>0.900036</td>\n",
       "      <td>0.855281</td>\n",
       "      <td>0.856995</td>\n",
       "      <td>0.745397</td>\n",
       "      <td>0.797310</td>\n",
       "      <td>0.826296</td>\n",
       "      <td>0.831132</td>\n",
       "      <td>0.829451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.322100</td>\n",
       "      <td>0.432388</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.832533</td>\n",
       "      <td>0.839537</td>\n",
       "      <td>0.862865</td>\n",
       "      <td>0.851041</td>\n",
       "      <td>0.823256</td>\n",
       "      <td>0.794791</td>\n",
       "      <td>0.808773</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.832533</td>\n",
       "      <td>0.832207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.429140</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.832133</td>\n",
       "      <td>0.857513</td>\n",
       "      <td>0.836160</td>\n",
       "      <td>0.846702</td>\n",
       "      <td>0.802265</td>\n",
       "      <td>0.827122</td>\n",
       "      <td>0.814504</td>\n",
       "      <td>0.830603</td>\n",
       "      <td>0.832133</td>\n",
       "      <td>0.832355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.260300</td>\n",
       "      <td>0.408457</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.833934</td>\n",
       "      <td>0.848975</td>\n",
       "      <td>0.852039</td>\n",
       "      <td>0.850504</td>\n",
       "      <td>0.815065</td>\n",
       "      <td>0.811405</td>\n",
       "      <td>0.813231</td>\n",
       "      <td>0.831868</td>\n",
       "      <td>0.833934</td>\n",
       "      <td>0.833896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.260300</td>\n",
       "      <td>0.420781</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.854572</td>\n",
       "      <td>0.839769</td>\n",
       "      <td>0.847106</td>\n",
       "      <td>0.804835</td>\n",
       "      <td>0.822182</td>\n",
       "      <td>0.813416</td>\n",
       "      <td>0.830261</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.832095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.423367</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.833133</td>\n",
       "      <td>0.828639</td>\n",
       "      <td>0.881270</td>\n",
       "      <td>0.854145</td>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.773238</td>\n",
       "      <td>0.805049</td>\n",
       "      <td>0.829597</td>\n",
       "      <td>0.833133</td>\n",
       "      <td>0.832269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.421481</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.829332</td>\n",
       "      <td>0.848981</td>\n",
       "      <td>0.841934</td>\n",
       "      <td>0.845443</td>\n",
       "      <td>0.805333</td>\n",
       "      <td>0.813651</td>\n",
       "      <td>0.809471</td>\n",
       "      <td>0.827457</td>\n",
       "      <td>0.829332</td>\n",
       "      <td>0.829415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.409163</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.834934</td>\n",
       "      <td>0.842124</td>\n",
       "      <td>0.864309</td>\n",
       "      <td>0.853072</td>\n",
       "      <td>0.825441</td>\n",
       "      <td>0.798383</td>\n",
       "      <td>0.811687</td>\n",
       "      <td>0.832379</td>\n",
       "      <td>0.834934</td>\n",
       "      <td>0.834632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>0.400785</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.834334</td>\n",
       "      <td>0.835116</td>\n",
       "      <td>0.873692</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.833254</td>\n",
       "      <td>0.785361</td>\n",
       "      <td>0.808599</td>\n",
       "      <td>0.831284</td>\n",
       "      <td>0.834334</td>\n",
       "      <td>0.833753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.398059</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.835334</td>\n",
       "      <td>0.840084</td>\n",
       "      <td>0.868279</td>\n",
       "      <td>0.853949</td>\n",
       "      <td>0.828960</td>\n",
       "      <td>0.794342</td>\n",
       "      <td>0.811282</td>\n",
       "      <td>0.832615</td>\n",
       "      <td>0.835334</td>\n",
       "      <td>0.834937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.255200</td>\n",
       "      <td>0.394789</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.834134</td>\n",
       "      <td>0.850795</td>\n",
       "      <td>0.849874</td>\n",
       "      <td>0.850334</td>\n",
       "      <td>0.813453</td>\n",
       "      <td>0.814549</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.832167</td>\n",
       "      <td>0.834134</td>\n",
       "      <td>0.834145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.234900</td>\n",
       "      <td>0.440168</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.839336</td>\n",
       "      <td>0.859124</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.854291</td>\n",
       "      <td>0.815323</td>\n",
       "      <td>0.826673</td>\n",
       "      <td>0.820959</td>\n",
       "      <td>0.837625</td>\n",
       "      <td>0.839336</td>\n",
       "      <td>0.839439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.569675</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.839736</td>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.877661</td>\n",
       "      <td>0.858605</td>\n",
       "      <td>0.838878</td>\n",
       "      <td>0.792546</td>\n",
       "      <td>0.815054</td>\n",
       "      <td>0.836830</td>\n",
       "      <td>0.839736</td>\n",
       "      <td>0.839200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>0.588617</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.837735</td>\n",
       "      <td>0.835616</td>\n",
       "      <td>0.880549</td>\n",
       "      <td>0.857494</td>\n",
       "      <td>0.840712</td>\n",
       "      <td>0.784463</td>\n",
       "      <td>0.811614</td>\n",
       "      <td>0.834554</td>\n",
       "      <td>0.837735</td>\n",
       "      <td>0.837051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.585708</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.838335</td>\n",
       "      <td>0.834869</td>\n",
       "      <td>0.883075</td>\n",
       "      <td>0.858295</td>\n",
       "      <td>0.843251</td>\n",
       "      <td>0.782667</td>\n",
       "      <td>0.811830</td>\n",
       "      <td>0.835063</td>\n",
       "      <td>0.838335</td>\n",
       "      <td>0.837592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.571603</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.838936</td>\n",
       "      <td>0.852330</td>\n",
       "      <td>0.858174</td>\n",
       "      <td>0.855242</td>\n",
       "      <td>0.822011</td>\n",
       "      <td>0.814998</td>\n",
       "      <td>0.818489</td>\n",
       "      <td>0.836866</td>\n",
       "      <td>0.838936</td>\n",
       "      <td>0.838866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.134900</td>\n",
       "      <td>0.552028</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.840736</td>\n",
       "      <td>0.841341</td>\n",
       "      <td>0.878383</td>\n",
       "      <td>0.859463</td>\n",
       "      <td>0.839905</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.816251</td>\n",
       "      <td>0.837857</td>\n",
       "      <td>0.840736</td>\n",
       "      <td>0.840209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>0.587307</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.832933</td>\n",
       "      <td>0.859317</td>\n",
       "      <td>0.835438</td>\n",
       "      <td>0.847210</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.829816</td>\n",
       "      <td>0.815714</td>\n",
       "      <td>0.831462</td>\n",
       "      <td>0.832933</td>\n",
       "      <td>0.833176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.562769</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.842862</td>\n",
       "      <td>0.867196</td>\n",
       "      <td>0.854856</td>\n",
       "      <td>0.828598</td>\n",
       "      <td>0.798833</td>\n",
       "      <td>0.813443</td>\n",
       "      <td>0.834149</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.836403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.129300</td>\n",
       "      <td>0.550149</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.838936</td>\n",
       "      <td>0.845640</td>\n",
       "      <td>0.867918</td>\n",
       "      <td>0.856634</td>\n",
       "      <td>0.830084</td>\n",
       "      <td>0.802874</td>\n",
       "      <td>0.816252</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.838936</td>\n",
       "      <td>0.838641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.585939</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.837135</td>\n",
       "      <td>0.836370</td>\n",
       "      <td>0.878022</td>\n",
       "      <td>0.856690</td>\n",
       "      <td>0.838200</td>\n",
       "      <td>0.786260</td>\n",
       "      <td>0.811399</td>\n",
       "      <td>0.834045</td>\n",
       "      <td>0.837135</td>\n",
       "      <td>0.836510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.582149</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.839336</td>\n",
       "      <td>0.845263</td>\n",
       "      <td>0.869361</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.831471</td>\n",
       "      <td>0.801976</td>\n",
       "      <td>0.816457</td>\n",
       "      <td>0.836800</td>\n",
       "      <td>0.839336</td>\n",
       "      <td>0.839014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "trainer.train() # Always Resume from Last Checkpoint to Save Time\n",
    "trainer.save_model('Milestone2-Baseline-BERT-FinalModel') # Save the Final Model\n",
    "trainer.save_state() # Save the State of the Trainer (e.g. Losses, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f7e60",
   "metadata": {},
   "source": [
    "# **Evaluate Fine-Tuned Model on Train, Dev, and Test Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aab0758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1355' max='1041' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1041/1041 10:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train evaluation metrics to Milestone #2 Fine-Tuned BERT Baseline train Results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dev evaluation metrics to Milestone #2 Fine-Tuned BERT Baseline dev Results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test evaluation metrics to Milestone #2 Fine-Tuned BERT Baseline test Results.csv\n"
     ]
    }
   ],
   "source": [
    "# Split: Train, Dev, or Test\n",
    "def generate_evaluation_results(split):\n",
    "    dataset = None\n",
    "    if split == \"train\":\n",
    "        dataset = train_hf_dataset\n",
    "    elif split == \"dev\" or split == \"validation\" or split == \"val\":\n",
    "        dataset = dev_hf_dataset\n",
    "    elif split == \"test\":\n",
    "        dataset = test_hf_dataset\n",
    "    \n",
    "    results = trainer.evaluate(eval_dataset=dataset, metric_key_prefix=split)\n",
    "    df_results = pd.DataFrame([results])\n",
    "    df_results.to_csv(f\"Milestone #2 Fine-Tuned BERT Baseline {split} Results.csv\", index=False)\n",
    "    print(f\"Saved {split} evaluation metrics to Milestone #2 Fine-Tuned BERT Baseline {split} Results.csv\")\n",
    "\n",
    "# Generate Evaluation Results on Train, Dev, and Test Splits\n",
    "generate_evaluation_results(\"train\")\n",
    "generate_evaluation_results(\"dev\")\n",
    "generate_evaluation_results(\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
