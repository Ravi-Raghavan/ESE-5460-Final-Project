{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0315c124",
      "metadata": {
        "id": "0315c124"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Vwcy2UhPMTam",
      "metadata": {
        "id": "Vwcy2UhPMTam"
      },
      "outputs": [],
      "source": [
        "# KEY PARAMETERS\n",
        "\n",
        "image_resolution = 224\n",
        "B = 32 # batch size, 8 or 32\n",
        "NUM_HEADS = 2 # number of heads for multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b413dd8",
      "metadata": {
        "id": "7b413dd8"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5e00a196",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e00a196",
        "outputId": "436b92ad-86ac-450f-df20-974da6ffd358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "## Ensure TensorFlow is not used\n",
        "import os\n",
        "os.environ[\"USE_TF\"] = \"0\"\n",
        "\n",
        "\n",
        "# # Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Set project directory to the folder containing the .ipynb and image folders\n",
        "# project_dir = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/Final Project\"   # <-- update if your folder name differs\n",
        "# os.chdir(project_dir)\n",
        "\n",
        "# print(\"Using project directory:\", os.getcwd())\n",
        "\n",
        "\n",
        "\n",
        "# Define data directory\n",
        "DATA_DIR = \"cleaned_data\"\n",
        "\n",
        "# Define file paths\n",
        "TRAIN_DATA_FILE = os.path.join(DATA_DIR, \"train.csv\")\n",
        "VALIDATION_DATA_FILE = os.path.join(DATA_DIR, \"validation_5k.csv\")\n",
        "TEST_DATA_FILE = os.path.join(DATA_DIR, \"test_5k.csv\")\n",
        "\n",
        "# For reproducability\n",
        "random_state = 42\n",
        "\n",
        "# Use CPU/MPS if possible\n",
        "device = None\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Running in Colab\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "else:\n",
        "    # Not in Colab (e.g., Mac)\n",
        "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb1533e8",
      "metadata": {
        "id": "eb1533e8"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "86261439",
      "metadata": {
        "id": "86261439"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA = pd.read_csv(TRAIN_DATA_FILE)\n",
        "VALIDATION_DATA = pd.read_csv(VALIDATION_DATA_FILE, index_col = 0)\n",
        "TEST_DATA = pd.read_csv(TEST_DATA_FILE, index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f5e8525e",
      "metadata": {
        "id": "f5e8525e"
      },
      "outputs": [],
      "source": [
        "# Ignore rows in corrupted_indices.txt files\n",
        "def filter_out_corrupted_rows(split, DF):\n",
        "    # File with corrupted indices\n",
        "    if split == \"train\":\n",
        "        corrupted_indices_file = f\"{split}_corrupted_indices.txt\"\n",
        "    else:\n",
        "        corrupted_indices_file = f\"{split}_5k_corrupted_indices.txt\"\n",
        "\n",
        "    # Store list of corrupted indices\n",
        "    corrupted_indices = None\n",
        "\n",
        "    # Get list of corrupted indices\n",
        "    with open(corrupted_indices_file, \"r\") as f:\n",
        "        corrupted_indices = list(int(line.strip()) for line in f if line.strip())\n",
        "\n",
        "    print(f\"Split: {split}, Corrupted Indices: {corrupted_indices}, Length: {len(corrupted_indices)}\")\n",
        "\n",
        "    # Filter out corrupted rows\n",
        "    DF = DF.drop(index = corrupted_indices)\n",
        "\n",
        "    return DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6f9fdbe2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f9fdbe2",
        "outputId": "a414026b-ed77-4435-fabc-c022e372b0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split: train, Corrupted Indices: [2862, 26040, 28337, 18547, 13374, 11288, 31984, 18451, 19000, 22479, 8048, 32075, 22918, 5586, 19345, 12770, 32189, 14628, 9081, 6611, 2927], Length: 21\n",
            "Split: validation, Corrupted Indices: [6568, 32176], Length: 2\n",
            "Split: test, Corrupted Indices: [29133, 9437, 26504, 11394], Length: 4\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DATA = filter_out_corrupted_rows(\"train\", TRAIN_DATA)\n",
        "VALIDATION_DATA = filter_out_corrupted_rows(\"validation\", VALIDATION_DATA)\n",
        "TEST_DATA = filter_out_corrupted_rows(\"test\", TEST_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "844d0c58",
      "metadata": {
        "id": "844d0c58"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA['image_num'] = TRAIN_DATA.index.astype(str).str.zfill(5)\n",
        "VALIDATION_DATA['image_num'] = VALIDATION_DATA.index.astype(str).str.zfill(5)\n",
        "TEST_DATA['image_num'] = TEST_DATA.index.astype(str).str.zfill(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "51548a31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "51548a31",
        "outputId": "03ea7059-4532-4ab9-9efd-5bb8cfd533bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>domain</th>\n",
              "      <th>image_url</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>3_way_label</th>\n",
              "      <th>6_way_label</th>\n",
              "      <th>image_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this spongebob squarepants branded battery</td>\n",
              "      <td>2019-07-30 20:00:50</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>https://preview.redd.it/f39wxxk8yhd31.jpg?widt...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>33</td>\n",
              "      <td>mildlyinteresting</td>\n",
              "      <td>0.95</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>award for careless talk</td>\n",
              "      <td>2011-09-03 17:26:23</td>\n",
              "      <td>i.imgur.com</td>\n",
              "      <td>https://external-preview.redd.it/KgPHCi1u3fY5j...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14</td>\n",
              "      <td>propagandaposters</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>00001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>four aligned airplanes</td>\n",
              "      <td>2017-11-20 06:05:45</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>https://preview.redd.it/88v9axk19phx.jpg?width...</td>\n",
              "      <td>24.0</td>\n",
              "      <td>198</td>\n",
              "      <td>confusing_perspective</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>00002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>columbus discovers the new world</td>\n",
              "      <td>2019-08-28 15:40:17</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>https://preview.redd.it/x4wzpd0am7j31.jpg?widt...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>318</td>\n",
              "      <td>fakehistoryporn</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>00003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>feed me drummmmssssssss</td>\n",
              "      <td>2014-05-09 13:23:59</td>\n",
              "      <td>i.imgur.com</td>\n",
              "      <td>https://external-preview.redd.it/yNN57loQnVhLk...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>pareidolia</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>00004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  clean_title          created_utc  \\\n",
              "0  this spongebob squarepants branded battery  2019-07-30 20:00:50   \n",
              "1                     award for careless talk  2011-09-03 17:26:23   \n",
              "2                      four aligned airplanes  2017-11-20 06:05:45   \n",
              "3            columbus discovers the new world  2019-08-28 15:40:17   \n",
              "4                     feed me drummmmssssssss  2014-05-09 13:23:59   \n",
              "\n",
              "        domain                                          image_url  \\\n",
              "0    i.redd.it  https://preview.redd.it/f39wxxk8yhd31.jpg?widt...   \n",
              "1  i.imgur.com  https://external-preview.redd.it/KgPHCi1u3fY5j...   \n",
              "2    i.redd.it  https://preview.redd.it/88v9axk19phx.jpg?width...   \n",
              "3    i.redd.it  https://preview.redd.it/x4wzpd0am7j31.jpg?widt...   \n",
              "4  i.imgur.com  https://external-preview.redd.it/yNN57loQnVhLk...   \n",
              "\n",
              "   num_comments  score              subreddit  upvote_ratio  2_way_label  \\\n",
              "0           4.0     33      mildlyinteresting          0.95            1   \n",
              "1           1.0     14      propagandaposters          1.00            0   \n",
              "2          24.0    198  confusing_perspective          0.98            0   \n",
              "3           5.0    318        fakehistoryporn          0.98            0   \n",
              "4           0.0      3             pareidolia          0.62            0   \n",
              "\n",
              "   3_way_label  6_way_label image_num  \n",
              "0            0            0     00000  \n",
              "1            1            5     00001  \n",
              "2            2            2     00002  \n",
              "3            2            2     00003  \n",
              "4            2            2     00004  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TRAIN_DATA.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bf021422",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bf021422",
        "outputId": "42e23211-4cf2-4776-e47b-101d73de2c05"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>domain</th>\n",
              "      <th>image_url</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>3_way_label</th>\n",
              "      <th>6_way_label</th>\n",
              "      <th>image_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8637</th>\n",
              "      <td>not as heartwarming as it could have been anth...</td>\n",
              "      <td>2019-09-19 17:48:33</td>\n",
              "      <td>lifestyle.clickhole.com</td>\n",
              "      <td>https://external-preview.redd.it/850kBbKdgMKfz...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15</td>\n",
              "      <td>theonion</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>08637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20669</th>\n",
              "      <td>other discussions</td>\n",
              "      <td>2013-12-09 23:58:43</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://i.dailymail.co.uk/i/pix/2013/12/09/arti...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>psbattle_artwork</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>20669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13179</th>\n",
              "      <td>on reflection oc</td>\n",
              "      <td>2015-01-12 17:14:55</td>\n",
              "      <td>i.imgur.com</td>\n",
              "      <td>https://external-preview.redd.it/tiFw8Ggb178E4...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>pareidolia</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>13179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20565</th>\n",
              "      <td>viet congo setting booby trap</td>\n",
              "      <td>2019-02-27 09:57:07</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>https://preview.redd.it/mj81gkh533j21.jpg?widt...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14</td>\n",
              "      <td>fakehistoryporn</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>20565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15504</th>\n",
              "      <td>chief has some happy shoulder armour</td>\n",
              "      <td>2013-02-20 01:00:02</td>\n",
              "      <td>i.imgur.com</td>\n",
              "      <td>https://external-preview.redd.it/kqqIlnAOZxzxA...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>pareidolia</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>15504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             clean_title          created_utc  \\\n",
              "8637   not as heartwarming as it could have been anth...  2019-09-19 17:48:33   \n",
              "20669                                  other discussions  2013-12-09 23:58:43   \n",
              "13179                                   on reflection oc  2015-01-12 17:14:55   \n",
              "20565                      viet congo setting booby trap  2019-02-27 09:57:07   \n",
              "15504               chief has some happy shoulder armour  2013-02-20 01:00:02   \n",
              "\n",
              "                        domain  \\\n",
              "8637   lifestyle.clickhole.com   \n",
              "20669                      NaN   \n",
              "13179              i.imgur.com   \n",
              "20565                i.redd.it   \n",
              "15504              i.imgur.com   \n",
              "\n",
              "                                               image_url  num_comments  score  \\\n",
              "8637   https://external-preview.redd.it/850kBbKdgMKfz...           0.0     15   \n",
              "20669  http://i.dailymail.co.uk/i/pix/2013/12/09/arti...           NaN      0   \n",
              "13179  https://external-preview.redd.it/tiFw8Ggb178E4...           0.0      3   \n",
              "20565  https://preview.redd.it/mj81gkh533j21.jpg?widt...           4.0     14   \n",
              "15504  https://external-preview.redd.it/kqqIlnAOZxzxA...           0.0      6   \n",
              "\n",
              "              subreddit  upvote_ratio  2_way_label  3_way_label  6_way_label  \\\n",
              "8637           theonion          0.86            0            2            1   \n",
              "20669  psbattle_artwork           NaN            0            2            4   \n",
              "13179        pareidolia          0.67            0            2            2   \n",
              "20565   fakehistoryporn          0.80            0            2            2   \n",
              "15504        pareidolia          1.00            0            2            2   \n",
              "\n",
              "      image_num  \n",
              "8637      08637  \n",
              "20669     20669  \n",
              "13179     13179  \n",
              "20565     20565  \n",
              "15504     15504  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "VALIDATION_DATA.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d697faa7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d697faa7",
        "outputId": "746d999b-d91e-42db-d2b3-bcd262fe7c2b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>domain</th>\n",
              "      <th>image_url</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>3_way_label</th>\n",
              "      <th>6_way_label</th>\n",
              "      <th>image_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19660</th>\n",
              "      <td>young homosexuals gather outside of a nightclu...</td>\n",
              "      <td>2018-07-29 13:59:38</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>https://preview.redd.it/16j830998wc11.jpg?widt...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>75</td>\n",
              "      <td>fakehistoryporn</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>19660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32879</th>\n",
              "      <td>cara al sol facing the sun a series of posters...</td>\n",
              "      <td>2013-05-20 18:25:00</td>\n",
              "      <td>imgur.com</td>\n",
              "      <td>https://external-preview.redd.it/S_nXt5X8VMqZD...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19</td>\n",
              "      <td>propagandaposters</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>32879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15071</th>\n",
              "      <td>he is awake and rises from the depths</td>\n",
              "      <td>2013-10-13 20:02:17</td>\n",
              "      <td>imgur.com</td>\n",
              "      <td>https://external-preview.redd.it/JetvyFQFm4fYt...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>pareidolia</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>15071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5198</th>\n",
              "      <td>the reason germany invades france and not spain</td>\n",
              "      <td>2018-09-03 08:22:07</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>https://preview.redd.it/ws91cs7lgzj11.png?widt...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57</td>\n",
              "      <td>fakehistoryporn</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>05198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15061</th>\n",
              "      <td>frozen body preserved on mount everest nsfw</td>\n",
              "      <td>2017-09-12 08:10:21</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>https://preview.redd.it/zxwc8gq8uelz.jpg?width...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24</td>\n",
              "      <td>fakehistoryporn</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>15061</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             clean_title          created_utc  \\\n",
              "19660  young homosexuals gather outside of a nightclu...  2018-07-29 13:59:38   \n",
              "32879  cara al sol facing the sun a series of posters...  2013-05-20 18:25:00   \n",
              "15071              he is awake and rises from the depths  2013-10-13 20:02:17   \n",
              "5198     the reason germany invades france and not spain  2018-09-03 08:22:07   \n",
              "15061        frozen body preserved on mount everest nsfw  2017-09-12 08:10:21   \n",
              "\n",
              "          domain                                          image_url  \\\n",
              "19660  i.redd.it  https://preview.redd.it/16j830998wc11.jpg?widt...   \n",
              "32879  imgur.com  https://external-preview.redd.it/S_nXt5X8VMqZD...   \n",
              "15071  imgur.com  https://external-preview.redd.it/JetvyFQFm4fYt...   \n",
              "5198   i.redd.it  https://preview.redd.it/ws91cs7lgzj11.png?widt...   \n",
              "15061  i.redd.it  https://preview.redd.it/zxwc8gq8uelz.jpg?width...   \n",
              "\n",
              "       num_comments  score          subreddit  upvote_ratio  2_way_label  \\\n",
              "19660           1.0     75    fakehistoryporn          0.92            0   \n",
              "32879           4.0     19  propagandaposters          0.89            0   \n",
              "15071           0.0      7         pareidolia          0.99            0   \n",
              "5198            0.0     57    fakehistoryporn          0.97            0   \n",
              "15061           0.0     24    fakehistoryporn          1.00            0   \n",
              "\n",
              "       3_way_label  6_way_label image_num  \n",
              "19660            2            2     19660  \n",
              "32879            1            5     32879  \n",
              "15071            2            2     15071  \n",
              "5198             2            2     05198  \n",
              "15061            2            2     15061  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TEST_DATA.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bb63096",
      "metadata": {
        "id": "6bb63096"
      },
      "source": [
        "## Create News Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e4415b61",
      "metadata": {
        "id": "e4415b61"
      },
      "outputs": [],
      "source": [
        "class RedditDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # Fetch text\n",
        "        text = row['clean_title']\n",
        "\n",
        "        # Get image number\n",
        "        image_num = row['image_num']\n",
        "\n",
        "        # Fetch Image\n",
        "        img_path = os.path.join(self.image_dir, f\"{image_num}.jpg\")\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Label\n",
        "        label = torch.tensor(row['2_way_label'], dtype=torch.long)\n",
        "\n",
        "        return text, image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cd1d376a",
      "metadata": {
        "id": "cd1d376a"
      },
      "outputs": [],
      "source": [
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((image_resolution, image_resolution)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_tfms = transforms.Compose([\n",
        "    transforms.Resize((image_resolution, image_resolution)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1850e504",
      "metadata": {
        "id": "1850e504"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    texts, images, labels = zip(*batch)\n",
        "    images = torch.stack(images)\n",
        "    labels = torch.stack(labels)\n",
        "    return list(texts), images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9015c427",
      "metadata": {
        "id": "9015c427"
      },
      "outputs": [],
      "source": [
        "train_dataset = RedditDataset(\n",
        "    df = TRAIN_DATA,\n",
        "    image_dir = \"train_images\",\n",
        "    transform = train_tfms\n",
        ")\n",
        "\n",
        "validation_dataset = RedditDataset(\n",
        "    df = VALIDATION_DATA,\n",
        "    image_dir = \"validation_images\",\n",
        "    transform = val_test_tfms\n",
        ")\n",
        "\n",
        "test_dataset = RedditDataset(\n",
        "    df = TEST_DATA,\n",
        "    image_dir = \"test_images\",\n",
        "    transform = val_test_tfms\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a5a47aed",
      "metadata": {
        "id": "a5a47aed"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=B,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "validation_loader = DataLoader(\n",
        "    validation_dataset,\n",
        "    batch_size=B,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=B,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fd482a11",
      "metadata": {
        "id": "fd482a11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of texts: 32\n",
            "Example text: egg with a nipple\n",
            "Images shape: torch.Size([32, 3, 224, 224])\n",
            "Labels shape: torch.Size([32])\n",
            "Labels: tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
            "        0, 1, 1, 0, 0, 1, 1, 0])\n"
          ]
        }
      ],
      "source": [
        "## Sanity Check\n",
        "texts, imgs, labels = next(iter(train_loader)) # try with validation_loader too\n",
        "print(\"Number of texts:\", len(texts))\n",
        "print(\"Example text:\", texts[0])\n",
        "print(\"Images shape:\", imgs.shape)      # (B, 3, 224, 224)\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "print(\"Labels:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3590e75",
      "metadata": {
        "id": "b3590e75"
      },
      "source": [
        "## Set up Fake News Detection (FND) CLIP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b4e40c57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4e40c57",
        "outputId": "4a38955d-94da-4b82-8de3-2a8ff057add8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "## Ensure TensorFlow is not used\n",
        "import os\n",
        "os.environ[\"USE_TF\"] = \"0\"\n",
        "\n",
        "# Import necessary software\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models as tv_models\n",
        "from transformers import CLIPModel, BertModel, BertTokenizer, CLIPTokenizer\n",
        "\n",
        "# Use CPU/MPS if possible\n",
        "import sys\n",
        "device = None\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Running in Colab\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "else:\n",
        "    # Not in Colab (e.g., Mac)\n",
        "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Projection Head: 2-layer MLP (Reference: Page 4, Figure 2 of Paper)\n",
        "class ProjectionHead(nn.Module):\n",
        "    # in_dim: Number of input features to the Projection Head\n",
        "    # hidden_dim: Size of hidden state representation\n",
        "    # out_dim: Size of output dimension\n",
        "    # dropout: dropout rate\n",
        "    def __init__(self, in_dim, hidden_dim=256, out_dim=64, dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Sequence 1: FC -> BN -> ReLU\n",
        "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Define Dropout \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Sequence 2: FC -> BN -> ReLU\n",
        "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(out_dim)\n",
        "\n",
        "    # Input Shape: (B, D) where B is batch size and D is in_dim\n",
        "    def forward(self, x):\n",
        "        # Sequence 1: FC -> BN -> ReLU\n",
        "        x = self.fc1(x) # Shape: B x hidden_dim\n",
        "        x = self.relu(x) # Shape: B x hidden_dim\n",
        "        x = self.bn1(x) # Shape: B x hidden_dim\n",
        "\n",
        "        # Dropout\n",
        "        x = self.dropout(x) # Shape: B x hidden_dim\n",
        "\n",
        "        # Sequence 2: FC -> BN -> ReLU\n",
        "        x = self.fc2(x) # Shape: B x out_dim\n",
        "        x = self.relu(x) # Shape: B x out_dim\n",
        "        x = self.bn2(x) # Shape: B x out_dim\n",
        "\n",
        "        # Return Output\n",
        "        return x # Shape: B x out_dim\n",
        "\n",
        "class QKVAttention(nn.Module):\n",
        "    def __init__(self, feat_dim, num_heads=1, qkv_dim=16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feat_dim = feat_dim\n",
        "        self.qkv_dim = qkv_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # Project 64 to 16\n",
        "        self.q_proj = nn.Linear(feat_dim, qkv_dim)\n",
        "        self.k_proj = nn.Linear(feat_dim, qkv_dim)\n",
        "        self.v_proj = nn.Linear(feat_dim, qkv_dim)\n",
        "\n",
        "        # Multihead attention in reduced dimension\n",
        "        self.attn = nn.MultiheadAttention(\n",
        "            embed_dim=qkv_dim,\n",
        "            num_heads=num_heads,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Project back to feat_dim (64)\n",
        "        self.out_proj = nn.Linear(qkv_dim, feat_dim)\n",
        "\n",
        "    def forward(self, m_txt, m_img, m_mix):\n",
        "        # Stack modalities (B, 3, feat_dim)\n",
        "        x = torch.stack([m_txt, m_img, m_mix], dim=1)\n",
        "\n",
        "        # Linear projections (B, 3, qkv_dim)\n",
        "        Q = self.q_proj(x)\n",
        "        K = self.k_proj(x)\n",
        "        V = self.v_proj(x)\n",
        "\n",
        "        # Attention in reduced space\n",
        "        out, _ = self.attn(Q, K, V)   # (B, 3, qkv_dim)\n",
        "\n",
        "        # Mean-pool to fuse modalities\n",
        "        mAgg = out.mean(dim=1)  # (B, qkv_dim)\n",
        "\n",
        "        # Project back to feat_dim (64)\n",
        "        return self.out_proj(mAgg)\n",
        "\n",
        "# Define Final Classification Head\n",
        "class ClassificationHead(nn.Module):\n",
        "    # in_dim: Number of input features to the Classification Head\n",
        "    # hidden_dim: Size of hidden state representation\n",
        "    # out_dim: Size of output dimension\n",
        "    def __init__(self, in_dim, hidden_dim = 64, out_dim = 2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Sequence 1: FC -> ReLU\n",
        "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Sequence 2: FC\n",
        "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
        "    \n",
        "    # Shape of x: B(batch size) x d(# of features)\n",
        "    def forward(self, x):\n",
        "        # Pass through first layer\n",
        "        x = self.relu(self.fc1(x))\n",
        "\n",
        "        # Pass through second layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Return output\n",
        "        return x\n",
        "\n",
        "# Fake News Detection(FND) CLIP Model\n",
        "class FND_CLIP(nn.Module):\n",
        "    # resnet_model_name: Name of resnet model\n",
        "    # clip_model_name: Name of CLIP model\n",
        "    # bert_model_name: Name of BERT Model\n",
        "    def __init__(\n",
        "        self,\n",
        "        resnet_model_name = \"resnet101\",\n",
        "        clip_model_name='openai/clip-vit-base-patch32',\n",
        "        bert_model_name='bert-base-uncased',\n",
        "        proj_hidden=256,\n",
        "        proj_out=64,\n",
        "        classifier_hidden=64,\n",
        "        dropout=0.2,\n",
        "        momentum=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Sanity Check\n",
        "        assert resnet_model_name == \"resnet101\"\n",
        "\n",
        "        # 1. Setup ResNet Image Encoder\n",
        "        # Replace the final fully connected layer with Identity because we only need the ResNet feature embeddings.\n",
        "        self.image_encoder = tv_models.resnet101(weights='IMAGENET1K_V1')\n",
        "        self.image_encoder.fc = nn.Identity()\n",
        "\n",
        "        # Sanity Check: Assert that ResNet parameters are going to be fine tuned\n",
        "        for param in self.image_encoder.parameters():\n",
        "            assert param.requires_grad == True\n",
        "\n",
        "        # 2. Setup BERT Text Encoder\n",
        "        self.text_encoder = BertModel.from_pretrained(bert_model_name)\n",
        "        self.text_encoder_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "        # Freeze BERT weights\n",
        "        for param in self.text_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # 3. Setup Multimodal (Text + Image) Encoder\n",
        "        self.multimodal_encoder = CLIPModel.from_pretrained(clip_model_name)\n",
        "        self.multimodal_encoder_tokenizer = CLIPTokenizer.from_pretrained(clip_model_name)\n",
        "\n",
        "        # Freeze CLIP weights\n",
        "        for param in self.multimodal_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # 4. Set up Text Projection Head\n",
        "        self.pTxt = ProjectionHead(in_dim = 1280, hidden_dim = proj_hidden, out_dim = proj_out, dropout = dropout)\n",
        "        self.pImg = ProjectionHead(in_dim = 2560, hidden_dim = proj_hidden, out_dim = proj_out, dropout = dropout)\n",
        "        self.pMix = ProjectionHead(in_dim = 1024, hidden_dim = proj_hidden, out_dim = proj_out, dropout = dropout)\n",
        "\n",
        "        # 5. Set up Modality-Wise Attention\n",
        "        self.attention = QKVAttention(feat_dim = proj_out, num_heads = NUM_HEADS)\n",
        "\n",
        "        # 6. Set up Final Classification Head\n",
        "        self.classification_head = ClassificationHead(in_dim = proj_out, hidden_dim = classifier_hidden, out_dim = 2)\n",
        "\n",
        "        # Set up Running Buffers\n",
        "        self.momentum = momentum\n",
        "        self.eps = 1e-8\n",
        "        self.register_buffer(\"running_mean\", torch.tensor(0.0, device=device))\n",
        "        self.register_buffer(\"running_var\", torch.tensor(1.0, device=device))\n",
        "\n",
        "    # Shape: fCLIP_T (B, 512)\n",
        "    # Shape: fCLIP_I (B, 512)\n",
        "    def compute_multimodal_features(self, fCLIP_T, fCLIP_I):\n",
        "        sim = F.cosine_similarity(fCLIP_T, fCLIP_I) # Compute cosine similarity, Shape: (B, )\n",
        "        fMix = torch.cat((fCLIP_T, fCLIP_I), dim = 1) # Shape: (B, 512 + 512 = 1024)\n",
        "\n",
        "        if self.training:\n",
        "            batch_mean = sim.mean() # Mean\n",
        "            batch_var = sim.var() # Variance\n",
        "\n",
        "            # update running stats\n",
        "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * batch_mean\n",
        "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * batch_var\n",
        "\n",
        "            mean, var = batch_mean, batch_var\n",
        "        else:\n",
        "            # use running stats for eval\n",
        "            mean, var = self.running_mean, self.running_var\n",
        "\n",
        "        # standardize similarity\n",
        "        sim_std = (sim - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "        # weight multimodal features\n",
        "        sim_weight = torch.sigmoid(sim_std).unsqueeze(1) # Shape: (B, 1)\n",
        "\n",
        "        mMix = sim_weight * self.pMix(fMix) # Shape: (B, 64)\n",
        "\n",
        "        # Return fMix and mMix\n",
        "        return fMix, mMix\n",
        "\n",
        "    # txt(B, ), List of Text Strings\n",
        "    # img(B, C_in = 3, H_in = 224, W_in = 224), List of Corresponding Imagess\n",
        "    def forward(self, txt, img):\n",
        "        # Compute BERT Text Features\n",
        "        text_encoding = self.text_encoder_tokenizer(\n",
        "            txt,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length = self.text_encoder_tokenizer.model_max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device) # Tokenize text\n",
        "\n",
        "        fBERT = self.text_encoder(**text_encoding).last_hidden_state[:, 0, :] # Use [CLS] token as text feature\n",
        "        # Shape: (B, 768)\n",
        "\n",
        "        # Compute ResNet Image Features\n",
        "        fResNet = self.image_encoder(img) # Output Shape: (B, 2048)\n",
        "\n",
        "        # Compute CLIP Text and Image Features\n",
        "        text_encoding = self.multimodal_encoder_tokenizer(\n",
        "            txt,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length = self.multimodal_encoder_tokenizer.model_max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device) # Tokenize text\n",
        "\n",
        "        fCLIP_T = self.multimodal_encoder.get_text_features(**text_encoding) # Compute CLIP Text Features\n",
        "        fCLIP_I = self.multimodal_encoder.get_image_features(img) # Compute CLIP Image Features\n",
        "\n",
        "        # Concatenate\n",
        "        fTxt = torch.cat((fBERT, fCLIP_T), dim = 1) # Shape: (B, 768 + 512 = 1280)\n",
        "        fImg = torch.cat((fResNet, fCLIP_I), dim = 1) # Shape: (B, 2048 + 512 = 2560)\n",
        "\n",
        "        # Compute mTxt and mImg\n",
        "        mTxt = self.pTxt(fTxt) # Shape: (B, 64)\n",
        "        mImg = self.pImg(fImg) # Shape: (B, 64)\n",
        "\n",
        "        fMix, mMix = self.compute_multimodal_features(fCLIP_T, fCLIP_I)\n",
        "        # fMix Shape: (B, 512 + 512 = 1024)\n",
        "        # mMix Shape: (B, 64)\n",
        "\n",
        "        # Perform Modality-Wise Attention\n",
        "        mAgg = self.attention(mTxt, mImg, mMix) # Shape: (B, 64)\n",
        "\n",
        "        # Compute Final Logits\n",
        "        logits = self.classification_head(mAgg) # Shape: (B, 2)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a779017d",
      "metadata": {
        "id": "a779017d"
      },
      "outputs": [],
      "source": [
        "model = FND_CLIP().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c899f00",
      "metadata": {
        "id": "4c899f00"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b69b3ce9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b69b3ce9",
        "outputId": "0eddf597-a357-4014-a351-13731869f20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44.62961294778248% of our dataset has label = 0 and 55.37038705221752% of our dataset has label = 1\n"
          ]
        }
      ],
      "source": [
        "# Compute Class Proportions\n",
        "p0 = (TRAIN_DATA['2_way_label'] == 0).mean() # Computes the percentage of our training dataset that has label = 0 [Fake News]\n",
        "p1 = (TRAIN_DATA['2_way_label'] == 1).mean() # Computes the percentage of our training dataset that has label = 1 [Non-Fake News]\n",
        "print(f\"{p0  * 100}% of our dataset has label = 0 and {p1  * 100}% of our dataset has label = 1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fb964ff5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fb964ff5",
        "outputId": "6c21a6e5-c132-4e8f-9e0e-c84d99aeff40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Weights: tensor([0.5537, 0.4463], device='mps:0')\n"
          ]
        }
      ],
      "source": [
        "# Define Weighted Loss Criterion\n",
        "class_weights = torch.tensor([p1, p0]).float().to(device)\n",
        "custom_criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
        "print(f\"Class Weights: {class_weights}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "af525ce6",
      "metadata": {
        "id": "af525ce6"
      },
      "outputs": [],
      "source": [
        "# Define Adam Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6bd12959",
      "metadata": {
        "id": "6bd12959"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=3):\n",
        "    model = model.to(device)\n",
        "    best_acc=0.0\n",
        "    save_dir = \"Milestone_4\"\n",
        "\n",
        "    # --- simple bookkeeping lists ---\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    update = 0  # global update counter\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 10)\n",
        "        model.train()\n",
        "        for batch_idx, (txts, imgs, labels) in enumerate(train_loader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            # ----- forward + backward -----\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(txts, imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # ----- training metrics -----\n",
        "            _, preds = outputs.max(1)\n",
        "            correct = (preds == labels).sum().item()\n",
        "            total = labels.size(0)\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            train_accuracies.append(correct / total)\n",
        "\n",
        "            print(f\"Batch {batch_idx + 1}/{len(train_loader)}, Loss: {train_losses[-1]}, Acc: {train_accuracies[-1]}\")\n",
        "\n",
        "            update += 1\n",
        "\n",
        "\n",
        "\n",
        "            # ----- every 100 updates: run validation + save -----\n",
        "            if update % 100 == 0 or update == 1:\n",
        "                model.eval()\n",
        "                v_correct = 0\n",
        "                v_total = 0\n",
        "                v_loss_total = 0.0\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for v_txts, v_imgs, v_labels in val_loader:\n",
        "                        v_imgs, v_labels = v_imgs.to(device), v_labels.to(device)\n",
        "                        v_outputs = model(v_txts, v_imgs)\n",
        "                        v_loss = criterion(v_outputs, v_labels)\n",
        "\n",
        "                        _, v_preds = v_outputs.max(1)\n",
        "                        v_correct += (v_preds == v_labels).sum().item()\n",
        "                        v_total += v_labels.size(0)\n",
        "                        v_loss_total += v_loss.item() * v_labels.size(0)\n",
        "\n",
        "                val_accuracy = v_correct / v_total\n",
        "                val_loss = v_loss_total / v_total\n",
        "\n",
        "\n",
        "                if not os.path.exists(save_dir):\n",
        "                    os.makedirs(save_dir)\n",
        "\n",
        "                # save BEST model across all training\n",
        "                if val_accuracy > best_acc:\n",
        "                    best_acc = val_accuracy\n",
        "                    torch.save(model.state_dict(), f\"{save_dir}/best_model_QKV.pt\")\n",
        "\n",
        "                # save LATEST model\n",
        "                torch.save(model.state_dict(), f\"{save_dir}/latest_model_QKV.pt\")\n",
        "\n",
        "                # bookkeeping\n",
        "                val_losses.append(val_loss)\n",
        "                val_accuracies.append(val_accuracy)\n",
        "\n",
        "                # print everything\n",
        "                print(\n",
        "                    f\"[Update {update}] \"\n",
        "                    f\"Train Loss: {loss.item():.4f}, Train Acc: {correct/total:.4f} | \"\n",
        "                    f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\"\n",
        "                )\n",
        "\n",
        "                # Put model back in training mode\n",
        "                model.train()\n",
        "\n",
        "\n",
        "\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{save_dir}/latest_model_QKV.pt\")\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "42e69594",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "42e69594",
        "outputId": "d83f13ce-5836-4b12-8ea1-6ec20f88a4b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "----------\n",
            "Batch 1/1041, Loss: 0.6936177611351013, Acc: 0.4375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Update 1] Train Loss: 0.6936, Train Acc: 0.4375 | Val Loss: 0.6960, Val Acc: 0.4456\n",
            "Batch 2/1041, Loss: 0.6916835308074951, Acc: 0.46875\n",
            "Batch 3/1041, Loss: 0.6908584237098694, Acc: 0.53125\n",
            "Batch 4/1041, Loss: 0.6915132999420166, Acc: 0.46875\n",
            "Batch 5/1041, Loss: 0.6907830834388733, Acc: 0.40625\n",
            "Batch 6/1041, Loss: 0.6904211044311523, Acc: 0.4375\n",
            "Batch 7/1041, Loss: 0.6945374608039856, Acc: 0.4375\n",
            "Batch 8/1041, Loss: 0.683294951915741, Acc: 0.5625\n",
            "Batch 9/1041, Loss: 0.6927710771560669, Acc: 0.46875\n",
            "Batch 10/1041, Loss: 0.6965214014053345, Acc: 0.40625\n",
            "Batch 11/1041, Loss: 0.6998918652534485, Acc: 0.3125\n",
            "Batch 12/1041, Loss: 0.6874505281448364, Acc: 0.4375\n",
            "Batch 13/1041, Loss: 0.6847199201583862, Acc: 0.5\n",
            "Batch 14/1041, Loss: 0.6885377764701843, Acc: 0.53125\n",
            "Batch 15/1041, Loss: 0.681018590927124, Acc: 0.5625\n",
            "Batch 16/1041, Loss: 0.6871535181999207, Acc: 0.53125\n",
            "Batch 17/1041, Loss: 0.6851873397827148, Acc: 0.59375\n",
            "Batch 18/1041, Loss: 0.6907170414924622, Acc: 0.4375\n",
            "Batch 19/1041, Loss: 0.6790137887001038, Acc: 0.625\n",
            "Batch 20/1041, Loss: 0.6883900165557861, Acc: 0.53125\n",
            "Batch 21/1041, Loss: 0.6884951591491699, Acc: 0.40625\n",
            "Batch 22/1041, Loss: 0.6832377910614014, Acc: 0.59375\n",
            "Batch 23/1041, Loss: 0.6924979090690613, Acc: 0.46875\n",
            "Batch 24/1041, Loss: 0.6858293414115906, Acc: 0.5\n",
            "Batch 25/1041, Loss: 0.6737543940544128, Acc: 0.59375\n",
            "Batch 26/1041, Loss: 0.6770384311676025, Acc: 0.5625\n",
            "Batch 27/1041, Loss: 0.6871955394744873, Acc: 0.53125\n",
            "Batch 28/1041, Loss: 0.6792757511138916, Acc: 0.46875\n",
            "Batch 29/1041, Loss: 0.686062216758728, Acc: 0.53125\n",
            "Batch 30/1041, Loss: 0.6830738186836243, Acc: 0.375\n",
            "Batch 31/1041, Loss: 0.6810771226882935, Acc: 0.5625\n",
            "Batch 32/1041, Loss: 0.6879889369010925, Acc: 0.53125\n",
            "Batch 33/1041, Loss: 0.6829810738563538, Acc: 0.53125\n",
            "Batch 34/1041, Loss: 0.6752744913101196, Acc: 0.6875\n",
            "Batch 35/1041, Loss: 0.6744403839111328, Acc: 0.65625\n",
            "Batch 36/1041, Loss: 0.6757403016090393, Acc: 0.625\n",
            "Batch 37/1041, Loss: 0.6769287586212158, Acc: 0.5625\n",
            "Batch 38/1041, Loss: 0.6770442128181458, Acc: 0.65625\n",
            "Batch 39/1041, Loss: 0.6817530393600464, Acc: 0.625\n",
            "Batch 40/1041, Loss: 0.684199333190918, Acc: 0.46875\n",
            "Batch 41/1041, Loss: 0.6694974899291992, Acc: 0.65625\n",
            "Batch 42/1041, Loss: 0.6787744760513306, Acc: 0.53125\n",
            "Batch 43/1041, Loss: 0.6647946238517761, Acc: 0.75\n",
            "Batch 44/1041, Loss: 0.671288013458252, Acc: 0.65625\n",
            "Batch 45/1041, Loss: 0.665451169013977, Acc: 0.78125\n",
            "Batch 46/1041, Loss: 0.6626793742179871, Acc: 0.6875\n",
            "Batch 47/1041, Loss: 0.6719907522201538, Acc: 0.5625\n",
            "Batch 48/1041, Loss: 0.6789363622665405, Acc: 0.59375\n",
            "Batch 49/1041, Loss: 0.6714081764221191, Acc: 0.625\n",
            "Batch 50/1041, Loss: 0.6841891407966614, Acc: 0.5625\n",
            "Batch 51/1041, Loss: 0.6658387184143066, Acc: 0.53125\n",
            "Batch 52/1041, Loss: 0.6692724823951721, Acc: 0.65625\n",
            "Batch 53/1041, Loss: 0.6720192432403564, Acc: 0.59375\n",
            "Batch 54/1041, Loss: 0.6624615788459778, Acc: 0.65625\n",
            "Batch 55/1041, Loss: 0.6656759977340698, Acc: 0.71875\n",
            "Batch 56/1041, Loss: 0.6673359274864197, Acc: 0.65625\n",
            "Batch 57/1041, Loss: 0.6687933802604675, Acc: 0.6875\n",
            "Batch 58/1041, Loss: 0.6762241125106812, Acc: 0.5625\n",
            "Batch 59/1041, Loss: 0.6650181412696838, Acc: 0.65625\n",
            "Batch 60/1041, Loss: 0.6543588638305664, Acc: 0.71875\n",
            "Batch 61/1041, Loss: 0.6562306880950928, Acc: 0.6875\n",
            "Batch 62/1041, Loss: 0.6710527539253235, Acc: 0.65625\n",
            "Batch 63/1041, Loss: 0.6528920531272888, Acc: 0.75\n",
            "Batch 64/1041, Loss: 0.6674158573150635, Acc: 0.6875\n",
            "Batch 65/1041, Loss: 0.6663904190063477, Acc: 0.71875\n",
            "Batch 66/1041, Loss: 0.6425848007202148, Acc: 0.8125\n",
            "Batch 67/1041, Loss: 0.6496776342391968, Acc: 0.75\n",
            "Batch 68/1041, Loss: 0.656609296798706, Acc: 0.65625\n",
            "Batch 69/1041, Loss: 0.6390156745910645, Acc: 0.8125\n",
            "Batch 70/1041, Loss: 0.6396205425262451, Acc: 0.75\n",
            "Batch 71/1041, Loss: 0.6526515483856201, Acc: 0.6875\n",
            "Batch 72/1041, Loss: 0.6396195292472839, Acc: 0.78125\n",
            "Batch 73/1041, Loss: 0.6498548984527588, Acc: 0.75\n",
            "Batch 74/1041, Loss: 0.631891667842865, Acc: 0.875\n",
            "Batch 75/1041, Loss: 0.6270736455917358, Acc: 0.75\n",
            "Batch 76/1041, Loss: 0.6285796761512756, Acc: 0.8125\n",
            "Batch 77/1041, Loss: 0.6359878778457642, Acc: 0.84375\n",
            "Batch 78/1041, Loss: 0.6354531645774841, Acc: 0.75\n",
            "Batch 79/1041, Loss: 0.6363168358802795, Acc: 0.71875\n",
            "Batch 80/1041, Loss: 0.6471641063690186, Acc: 0.75\n",
            "Batch 81/1041, Loss: 0.6247444748878479, Acc: 0.8125\n",
            "Batch 82/1041, Loss: 0.6382056474685669, Acc: 0.6875\n",
            "Batch 83/1041, Loss: 0.6364322900772095, Acc: 0.75\n",
            "Batch 84/1041, Loss: 0.6577805876731873, Acc: 0.625\n",
            "Batch 85/1041, Loss: 0.6258956789970398, Acc: 0.8125\n",
            "Batch 86/1041, Loss: 0.6199158430099487, Acc: 0.8125\n",
            "Batch 87/1041, Loss: 0.6195698976516724, Acc: 0.78125\n",
            "Batch 88/1041, Loss: 0.6521841287612915, Acc: 0.6875\n",
            "Batch 89/1041, Loss: 0.6394026279449463, Acc: 0.75\n",
            "Batch 90/1041, Loss: 0.6402866244316101, Acc: 0.6875\n",
            "Batch 91/1041, Loss: 0.6268326640129089, Acc: 0.75\n",
            "Batch 92/1041, Loss: 0.592207670211792, Acc: 0.84375\n",
            "Batch 93/1041, Loss: 0.6094955205917358, Acc: 0.8125\n",
            "Batch 94/1041, Loss: 0.5868839621543884, Acc: 0.84375\n",
            "Batch 95/1041, Loss: 0.6314888596534729, Acc: 0.6875\n",
            "Batch 96/1041, Loss: 0.6442040801048279, Acc: 0.75\n",
            "Batch 97/1041, Loss: 0.6298089027404785, Acc: 0.78125\n",
            "Batch 98/1041, Loss: 0.6111148595809937, Acc: 0.78125\n",
            "Batch 99/1041, Loss: 0.5952771306037903, Acc: 0.8125\n",
            "Batch 100/1041, Loss: 0.6002964973449707, Acc: 0.84375\n",
            "[Update 100] Train Loss: 0.6003, Train Acc: 0.8438 | Val Loss: 0.6023, Val Acc: 0.7661\n",
            "Batch 101/1041, Loss: 0.5732071995735168, Acc: 0.9375\n",
            "Batch 102/1041, Loss: 0.6120086312294006, Acc: 0.75\n",
            "Batch 103/1041, Loss: 0.5952814817428589, Acc: 0.71875\n",
            "Batch 104/1041, Loss: 0.5659239292144775, Acc: 0.84375\n",
            "Batch 105/1041, Loss: 0.6031765937805176, Acc: 0.6875\n",
            "Batch 106/1041, Loss: 0.5647950172424316, Acc: 0.8125\n",
            "Batch 107/1041, Loss: 0.6000293493270874, Acc: 0.78125\n",
            "Batch 108/1041, Loss: 0.5977854132652283, Acc: 0.78125\n",
            "Batch 109/1041, Loss: 0.640692412853241, Acc: 0.6875\n",
            "Batch 110/1041, Loss: 0.6412339806556702, Acc: 0.59375\n",
            "Batch 111/1041, Loss: 0.5708587765693665, Acc: 0.78125\n",
            "Batch 112/1041, Loss: 0.5843046307563782, Acc: 0.84375\n",
            "Batch 113/1041, Loss: 0.5689066648483276, Acc: 0.875\n",
            "Batch 114/1041, Loss: 0.5800856351852417, Acc: 0.78125\n",
            "Batch 115/1041, Loss: 0.5709316730499268, Acc: 0.8125\n",
            "Batch 116/1041, Loss: 0.6241582632064819, Acc: 0.78125\n",
            "Batch 117/1041, Loss: 0.5782984495162964, Acc: 0.75\n",
            "Batch 118/1041, Loss: 0.6047195196151733, Acc: 0.75\n",
            "Batch 119/1041, Loss: 0.5527312755584717, Acc: 0.84375\n",
            "Batch 120/1041, Loss: 0.5570021867752075, Acc: 0.8125\n",
            "Batch 121/1041, Loss: 0.5498936772346497, Acc: 0.875\n",
            "Batch 122/1041, Loss: 0.5800620913505554, Acc: 0.78125\n",
            "Batch 123/1041, Loss: 0.5977782011032104, Acc: 0.78125\n",
            "Batch 124/1041, Loss: 0.6043402552604675, Acc: 0.65625\n",
            "Batch 125/1041, Loss: 0.6362684965133667, Acc: 0.6875\n",
            "Batch 126/1041, Loss: 0.5795842409133911, Acc: 0.75\n",
            "Batch 127/1041, Loss: 0.5148879885673523, Acc: 0.8125\n",
            "Batch 128/1041, Loss: 0.6159719228744507, Acc: 0.75\n",
            "Batch 129/1041, Loss: 0.5606101155281067, Acc: 0.75\n",
            "Batch 130/1041, Loss: 0.5223585367202759, Acc: 0.875\n",
            "Batch 131/1041, Loss: 0.5699608325958252, Acc: 0.75\n",
            "Batch 132/1041, Loss: 0.5371618270874023, Acc: 0.78125\n",
            "Batch 133/1041, Loss: 0.5683895945549011, Acc: 0.71875\n",
            "Batch 134/1041, Loss: 0.6152196526527405, Acc: 0.75\n",
            "Batch 135/1041, Loss: 0.55147385597229, Acc: 0.8125\n",
            "Batch 136/1041, Loss: 0.5885327458381653, Acc: 0.71875\n",
            "Batch 137/1041, Loss: 0.5209664106369019, Acc: 0.8125\n",
            "Batch 138/1041, Loss: 0.5876591205596924, Acc: 0.8125\n",
            "Batch 139/1041, Loss: 0.5871383547782898, Acc: 0.71875\n",
            "Batch 140/1041, Loss: 0.5657055974006653, Acc: 0.75\n",
            "Batch 141/1041, Loss: 0.5076417922973633, Acc: 0.84375\n",
            "Batch 142/1041, Loss: 0.5230756998062134, Acc: 0.78125\n",
            "Batch 143/1041, Loss: 0.5676162242889404, Acc: 0.8125\n",
            "Batch 144/1041, Loss: 0.5456153154373169, Acc: 0.78125\n",
            "Batch 145/1041, Loss: 0.5615039467811584, Acc: 0.75\n",
            "Batch 146/1041, Loss: 0.48993656039237976, Acc: 0.875\n",
            "Batch 147/1041, Loss: 0.5593182444572449, Acc: 0.8125\n",
            "Batch 148/1041, Loss: 0.5313568115234375, Acc: 0.78125\n",
            "Batch 149/1041, Loss: 0.5323801636695862, Acc: 0.71875\n",
            "Batch 150/1041, Loss: 0.6144804358482361, Acc: 0.65625\n",
            "Batch 151/1041, Loss: 0.5800690054893494, Acc: 0.6875\n",
            "Batch 152/1041, Loss: 0.5174115896224976, Acc: 0.75\n",
            "Batch 153/1041, Loss: 0.5771420001983643, Acc: 0.75\n",
            "Batch 154/1041, Loss: 0.49890998005867004, Acc: 0.875\n",
            "Batch 155/1041, Loss: 0.5418885350227356, Acc: 0.78125\n",
            "Batch 156/1041, Loss: 0.5384365320205688, Acc: 0.8125\n",
            "Batch 157/1041, Loss: 0.55540931224823, Acc: 0.78125\n",
            "Batch 158/1041, Loss: 0.574715256690979, Acc: 0.65625\n",
            "Batch 159/1041, Loss: 0.6160150170326233, Acc: 0.65625\n",
            "Batch 160/1041, Loss: 0.5406351089477539, Acc: 0.75\n",
            "Batch 161/1041, Loss: 0.44889307022094727, Acc: 0.90625\n",
            "Batch 162/1041, Loss: 0.537765383720398, Acc: 0.6875\n",
            "Batch 163/1041, Loss: 0.5845380425453186, Acc: 0.65625\n",
            "Batch 164/1041, Loss: 0.4850253760814667, Acc: 0.90625\n",
            "Batch 165/1041, Loss: 0.6335013508796692, Acc: 0.625\n",
            "Batch 166/1041, Loss: 0.49375560879707336, Acc: 0.875\n",
            "Batch 167/1041, Loss: 0.4615200161933899, Acc: 0.875\n",
            "Batch 168/1041, Loss: 0.5361375212669373, Acc: 0.84375\n",
            "Batch 169/1041, Loss: 0.5238386988639832, Acc: 0.65625\n",
            "Batch 170/1041, Loss: 0.5058436393737793, Acc: 0.78125\n",
            "Batch 171/1041, Loss: 0.5754221677780151, Acc: 0.75\n",
            "Batch 172/1041, Loss: 0.5323460698127747, Acc: 0.75\n",
            "Batch 173/1041, Loss: 0.5364246964454651, Acc: 0.8125\n",
            "Batch 174/1041, Loss: 0.6046544313430786, Acc: 0.65625\n",
            "Batch 175/1041, Loss: 0.5871933102607727, Acc: 0.625\n",
            "Batch 176/1041, Loss: 0.5502296090126038, Acc: 0.75\n",
            "Batch 177/1041, Loss: 0.5898858904838562, Acc: 0.75\n",
            "Batch 178/1041, Loss: 0.5319291353225708, Acc: 0.6875\n",
            "Batch 179/1041, Loss: 0.5741153359413147, Acc: 0.625\n",
            "Batch 180/1041, Loss: 0.4662300646305084, Acc: 0.84375\n",
            "Batch 181/1041, Loss: 0.5472372174263, Acc: 0.75\n",
            "Batch 182/1041, Loss: 0.4502005875110626, Acc: 0.84375\n",
            "Batch 183/1041, Loss: 0.5111599564552307, Acc: 0.84375\n",
            "Batch 184/1041, Loss: 0.4785749316215515, Acc: 0.78125\n",
            "Batch 185/1041, Loss: 0.5343048572540283, Acc: 0.78125\n",
            "Batch 186/1041, Loss: 0.4974791407585144, Acc: 0.78125\n",
            "Batch 187/1041, Loss: 0.3737804591655731, Acc: 0.875\n",
            "Batch 188/1041, Loss: 0.4432642459869385, Acc: 0.84375\n",
            "Batch 189/1041, Loss: 0.4353066682815552, Acc: 0.90625\n",
            "Batch 190/1041, Loss: 0.5771951079368591, Acc: 0.6875\n",
            "Batch 191/1041, Loss: 0.5361482501029968, Acc: 0.75\n",
            "Batch 192/1041, Loss: 0.5111165642738342, Acc: 0.71875\n",
            "Batch 193/1041, Loss: 0.4746728539466858, Acc: 0.78125\n",
            "Batch 194/1041, Loss: 0.5468506217002869, Acc: 0.78125\n",
            "Batch 195/1041, Loss: 0.5926228761672974, Acc: 0.71875\n",
            "Batch 196/1041, Loss: 0.5427518486976624, Acc: 0.78125\n",
            "Batch 197/1041, Loss: 0.4812929332256317, Acc: 0.75\n",
            "Batch 198/1041, Loss: 0.41051292419433594, Acc: 0.84375\n",
            "Batch 199/1041, Loss: 0.5820634365081787, Acc: 0.6875\n",
            "Batch 200/1041, Loss: 0.5925107002258301, Acc: 0.75\n",
            "[Update 200] Train Loss: 0.5925, Train Acc: 0.7500 | Val Loss: 0.4673, Val Acc: 0.8021\n",
            "Batch 201/1041, Loss: 0.4573204815387726, Acc: 0.84375\n",
            "Batch 202/1041, Loss: 0.48995816707611084, Acc: 0.8125\n",
            "Batch 203/1041, Loss: 0.5240375399589539, Acc: 0.78125\n",
            "Batch 204/1041, Loss: 0.4794864058494568, Acc: 0.875\n",
            "Batch 205/1041, Loss: 0.44917744398117065, Acc: 0.875\n",
            "Batch 206/1041, Loss: 0.43068477511405945, Acc: 0.90625\n",
            "Batch 207/1041, Loss: 0.4878814220428467, Acc: 0.78125\n",
            "Batch 208/1041, Loss: 0.44666576385498047, Acc: 0.84375\n",
            "Batch 209/1041, Loss: 0.49140939116477966, Acc: 0.8125\n",
            "Batch 210/1041, Loss: 0.5421685576438904, Acc: 0.75\n",
            "Batch 211/1041, Loss: 0.41362464427948, Acc: 0.84375\n",
            "Batch 212/1041, Loss: 0.5973063111305237, Acc: 0.65625\n",
            "Batch 213/1041, Loss: 0.5057733058929443, Acc: 0.78125\n",
            "Batch 214/1041, Loss: 0.47588005661964417, Acc: 0.8125\n",
            "Batch 215/1041, Loss: 0.4420054852962494, Acc: 0.84375\n",
            "Batch 216/1041, Loss: 0.4699009656906128, Acc: 0.75\n",
            "Batch 217/1041, Loss: 0.47471854090690613, Acc: 0.78125\n",
            "Batch 218/1041, Loss: 0.4007514417171478, Acc: 0.84375\n",
            "Batch 219/1041, Loss: 0.40158528089523315, Acc: 0.8125\n",
            "Batch 220/1041, Loss: 0.5220797061920166, Acc: 0.75\n",
            "Batch 221/1041, Loss: 0.5066693425178528, Acc: 0.75\n",
            "Batch 222/1041, Loss: 0.5929200649261475, Acc: 0.78125\n",
            "Batch 223/1041, Loss: 0.5077360272407532, Acc: 0.71875\n",
            "Batch 224/1041, Loss: 0.5479410886764526, Acc: 0.78125\n",
            "Batch 225/1041, Loss: 0.5429723262786865, Acc: 0.6875\n",
            "Batch 226/1041, Loss: 0.4570342004299164, Acc: 0.75\n",
            "Batch 227/1041, Loss: 0.4085387885570526, Acc: 0.8125\n",
            "Batch 228/1041, Loss: 0.5743445754051208, Acc: 0.65625\n",
            "Batch 229/1041, Loss: 0.44424307346343994, Acc: 0.8125\n",
            "Batch 230/1041, Loss: 0.4755617380142212, Acc: 0.8125\n",
            "Batch 231/1041, Loss: 0.4656805098056793, Acc: 0.71875\n",
            "Batch 232/1041, Loss: 0.6158663034439087, Acc: 0.75\n",
            "Batch 233/1041, Loss: 0.5858887434005737, Acc: 0.65625\n",
            "Batch 234/1041, Loss: 0.46137911081314087, Acc: 0.84375\n",
            "Batch 235/1041, Loss: 0.5587096214294434, Acc: 0.6875\n",
            "Batch 236/1041, Loss: 0.46505075693130493, Acc: 0.8125\n",
            "Batch 237/1041, Loss: 0.4504322409629822, Acc: 0.8125\n",
            "Batch 238/1041, Loss: 0.5040375590324402, Acc: 0.78125\n",
            "Batch 239/1041, Loss: 0.4090369641780853, Acc: 0.84375\n",
            "Batch 240/1041, Loss: 0.49537932872772217, Acc: 0.75\n",
            "Batch 241/1041, Loss: 0.4761563539505005, Acc: 0.71875\n",
            "Batch 242/1041, Loss: 0.4933377802371979, Acc: 0.84375\n",
            "Batch 243/1041, Loss: 0.44463104009628296, Acc: 0.8125\n",
            "Batch 244/1041, Loss: 0.49029627442359924, Acc: 0.78125\n",
            "Batch 245/1041, Loss: 0.5030031204223633, Acc: 0.75\n",
            "Batch 246/1041, Loss: 0.4991788864135742, Acc: 0.8125\n",
            "Batch 247/1041, Loss: 0.47915923595428467, Acc: 0.75\n",
            "Batch 248/1041, Loss: 0.5205122828483582, Acc: 0.71875\n",
            "Batch 249/1041, Loss: 0.3890496790409088, Acc: 0.875\n",
            "Batch 250/1041, Loss: 0.36541885137557983, Acc: 0.90625\n",
            "Batch 251/1041, Loss: 0.3072825074195862, Acc: 1.0\n",
            "Batch 252/1041, Loss: 0.41372862458229065, Acc: 0.90625\n",
            "Batch 253/1041, Loss: 0.4524172842502594, Acc: 0.75\n",
            "Batch 254/1041, Loss: 0.4717063307762146, Acc: 0.8125\n",
            "Batch 255/1041, Loss: 0.3602572977542877, Acc: 0.90625\n",
            "Batch 256/1041, Loss: 0.5071879625320435, Acc: 0.75\n",
            "Batch 257/1041, Loss: 0.3589426875114441, Acc: 0.875\n",
            "Batch 258/1041, Loss: 0.5089762210845947, Acc: 0.75\n",
            "Batch 259/1041, Loss: 0.5427333116531372, Acc: 0.65625\n",
            "Batch 260/1041, Loss: 0.5650873780250549, Acc: 0.71875\n",
            "Batch 261/1041, Loss: 0.45702701807022095, Acc: 0.75\n",
            "Batch 262/1041, Loss: 0.4364440441131592, Acc: 0.78125\n",
            "Batch 263/1041, Loss: 0.41410595178604126, Acc: 0.8125\n",
            "Batch 264/1041, Loss: 0.38383549451828003, Acc: 0.8125\n",
            "Batch 265/1041, Loss: 0.38760319352149963, Acc: 0.8125\n",
            "Batch 266/1041, Loss: 0.5187211632728577, Acc: 0.78125\n",
            "Batch 267/1041, Loss: 0.41582027077674866, Acc: 0.875\n",
            "Batch 268/1041, Loss: 0.47922569513320923, Acc: 0.78125\n",
            "Batch 269/1041, Loss: 0.41941267251968384, Acc: 0.84375\n",
            "Batch 270/1041, Loss: 0.394426554441452, Acc: 0.875\n",
            "Batch 271/1041, Loss: 0.3511265814304352, Acc: 0.84375\n",
            "Batch 272/1041, Loss: 0.32148900628089905, Acc: 0.90625\n",
            "Batch 273/1041, Loss: 0.3924139440059662, Acc: 0.875\n",
            "Batch 274/1041, Loss: 0.42950624227523804, Acc: 0.78125\n",
            "Batch 275/1041, Loss: 0.4159010648727417, Acc: 0.8125\n",
            "Batch 276/1041, Loss: 0.44432491064071655, Acc: 0.84375\n",
            "Batch 277/1041, Loss: 0.5691207051277161, Acc: 0.75\n",
            "Batch 278/1041, Loss: 0.4513154625892639, Acc: 0.8125\n",
            "Batch 279/1041, Loss: 0.46232184767723083, Acc: 0.75\n",
            "Batch 280/1041, Loss: 0.48048174381256104, Acc: 0.78125\n",
            "Batch 281/1041, Loss: 0.388663649559021, Acc: 0.78125\n",
            "Batch 282/1041, Loss: 0.400452584028244, Acc: 0.84375\n",
            "Batch 283/1041, Loss: 0.26916956901550293, Acc: 0.9375\n",
            "Batch 284/1041, Loss: 0.44148966670036316, Acc: 0.8125\n",
            "Batch 285/1041, Loss: 0.47250309586524963, Acc: 0.78125\n",
            "Batch 286/1041, Loss: 0.3540593981742859, Acc: 0.84375\n",
            "Batch 287/1041, Loss: 0.3702011704444885, Acc: 0.8125\n",
            "Batch 288/1041, Loss: 0.4075298309326172, Acc: 0.78125\n",
            "Batch 289/1041, Loss: 0.4323379397392273, Acc: 0.8125\n",
            "Batch 290/1041, Loss: 0.4774610698223114, Acc: 0.8125\n",
            "Batch 291/1041, Loss: 0.44301638007164, Acc: 0.75\n",
            "Batch 292/1041, Loss: 0.4392460882663727, Acc: 0.78125\n",
            "Batch 293/1041, Loss: 0.32445716857910156, Acc: 0.875\n",
            "Batch 294/1041, Loss: 0.31771260499954224, Acc: 0.84375\n",
            "Batch 295/1041, Loss: 0.46614909172058105, Acc: 0.8125\n",
            "Batch 296/1041, Loss: 0.2934746742248535, Acc: 0.9375\n",
            "Batch 297/1041, Loss: 0.5136302709579468, Acc: 0.6875\n",
            "Batch 298/1041, Loss: 0.49655473232269287, Acc: 0.78125\n",
            "Batch 299/1041, Loss: 0.294938862323761, Acc: 0.90625\n",
            "Batch 300/1041, Loss: 0.4739739000797272, Acc: 0.75\n",
            "[Update 300] Train Loss: 0.4740, Train Acc: 0.7500 | Val Loss: 0.4059, Val Acc: 0.8225\n",
            "Batch 301/1041, Loss: 0.511902928352356, Acc: 0.8125\n",
            "Batch 302/1041, Loss: 0.4194001853466034, Acc: 0.78125\n",
            "Batch 303/1041, Loss: 0.4560198187828064, Acc: 0.78125\n",
            "Batch 304/1041, Loss: 0.2956923842430115, Acc: 0.875\n",
            "Batch 305/1041, Loss: 0.41572073101997375, Acc: 0.8125\n",
            "Batch 306/1041, Loss: 0.49178430438041687, Acc: 0.875\n",
            "Batch 307/1041, Loss: 0.5840209722518921, Acc: 0.75\n",
            "Batch 308/1041, Loss: 0.5584520697593689, Acc: 0.6875\n",
            "Batch 309/1041, Loss: 0.3519933521747589, Acc: 0.875\n",
            "Batch 310/1041, Loss: 0.5553421974182129, Acc: 0.78125\n",
            "Batch 311/1041, Loss: 0.3402840197086334, Acc: 0.84375\n",
            "Batch 312/1041, Loss: 0.5177539587020874, Acc: 0.6875\n",
            "Batch 313/1041, Loss: 0.3436819314956665, Acc: 0.875\n",
            "Batch 314/1041, Loss: 0.420803040266037, Acc: 0.84375\n",
            "Batch 315/1041, Loss: 0.4319436848163605, Acc: 0.78125\n",
            "Batch 316/1041, Loss: 0.44628584384918213, Acc: 0.75\n",
            "Batch 317/1041, Loss: 0.3552819788455963, Acc: 0.78125\n",
            "Batch 318/1041, Loss: 0.39758726954460144, Acc: 0.75\n",
            "Batch 319/1041, Loss: 0.5612581968307495, Acc: 0.78125\n",
            "Batch 320/1041, Loss: 0.3419789969921112, Acc: 0.78125\n",
            "Batch 321/1041, Loss: 0.4153974652290344, Acc: 0.8125\n",
            "Batch 322/1041, Loss: 0.49510759115219116, Acc: 0.84375\n",
            "Batch 323/1041, Loss: 0.46174317598342896, Acc: 0.8125\n",
            "Batch 324/1041, Loss: 0.5184869766235352, Acc: 0.71875\n",
            "Batch 325/1041, Loss: 0.6197250485420227, Acc: 0.65625\n",
            "Batch 326/1041, Loss: 0.6026010513305664, Acc: 0.71875\n",
            "Batch 327/1041, Loss: 0.5105774402618408, Acc: 0.71875\n",
            "Batch 328/1041, Loss: 0.44765278697013855, Acc: 0.78125\n",
            "Batch 329/1041, Loss: 0.4766629934310913, Acc: 0.84375\n",
            "Batch 330/1041, Loss: 0.5554991960525513, Acc: 0.6875\n",
            "Batch 331/1041, Loss: 0.47206947207450867, Acc: 0.84375\n",
            "Batch 332/1041, Loss: 0.474575936794281, Acc: 0.78125\n",
            "Batch 333/1041, Loss: 0.619809627532959, Acc: 0.75\n",
            "Batch 334/1041, Loss: 0.4141758680343628, Acc: 0.8125\n",
            "Batch 335/1041, Loss: 0.4643392264842987, Acc: 0.84375\n",
            "Batch 336/1041, Loss: 0.4419699013233185, Acc: 0.78125\n",
            "Batch 337/1041, Loss: 0.2995922565460205, Acc: 0.90625\n",
            "Batch 338/1041, Loss: 0.35958242416381836, Acc: 0.8125\n",
            "Batch 339/1041, Loss: 0.40000417828559875, Acc: 0.84375\n",
            "Batch 340/1041, Loss: 0.4073912501335144, Acc: 0.8125\n",
            "Batch 341/1041, Loss: 0.4401208162307739, Acc: 0.84375\n",
            "Batch 342/1041, Loss: 0.3741961121559143, Acc: 0.84375\n",
            "Batch 343/1041, Loss: 0.47072944045066833, Acc: 0.75\n",
            "Batch 344/1041, Loss: 0.39542731642723083, Acc: 0.875\n",
            "Batch 345/1041, Loss: 0.44823479652404785, Acc: 0.8125\n",
            "Batch 346/1041, Loss: 0.4354398250579834, Acc: 0.875\n",
            "Batch 347/1041, Loss: 0.4034828543663025, Acc: 0.8125\n",
            "Batch 348/1041, Loss: 0.4443003535270691, Acc: 0.78125\n",
            "Batch 349/1041, Loss: 0.4338380992412567, Acc: 0.78125\n",
            "Batch 350/1041, Loss: 0.4000001549720764, Acc: 0.875\n",
            "Batch 351/1041, Loss: 0.3394085466861725, Acc: 0.875\n",
            "Batch 352/1041, Loss: 0.29249322414398193, Acc: 0.875\n",
            "Batch 353/1041, Loss: 0.37556058168411255, Acc: 0.84375\n",
            "Batch 354/1041, Loss: 0.43315836787223816, Acc: 0.78125\n",
            "Batch 355/1041, Loss: 0.37789106369018555, Acc: 0.84375\n",
            "Batch 356/1041, Loss: 0.29491958022117615, Acc: 0.9375\n",
            "Batch 357/1041, Loss: 0.5027350783348083, Acc: 0.84375\n",
            "Batch 358/1041, Loss: 0.3503316044807434, Acc: 0.90625\n",
            "Batch 359/1041, Loss: 0.36343955993652344, Acc: 0.84375\n",
            "Batch 360/1041, Loss: 0.282272607088089, Acc: 0.9375\n",
            "Batch 361/1041, Loss: 0.3451208770275116, Acc: 0.8125\n",
            "Batch 362/1041, Loss: 0.3309180736541748, Acc: 0.875\n",
            "Batch 363/1041, Loss: 0.6095291972160339, Acc: 0.71875\n",
            "Batch 364/1041, Loss: 0.38266822695732117, Acc: 0.8125\n",
            "Batch 365/1041, Loss: 0.5478858947753906, Acc: 0.6875\n",
            "Batch 366/1041, Loss: 0.3764972686767578, Acc: 0.8125\n",
            "Batch 367/1041, Loss: 0.5537614226341248, Acc: 0.75\n",
            "Batch 368/1041, Loss: 0.29638105630874634, Acc: 0.9375\n",
            "Batch 369/1041, Loss: 0.2483990341424942, Acc: 0.90625\n",
            "Batch 370/1041, Loss: 0.373983770608902, Acc: 0.84375\n",
            "Batch 371/1041, Loss: 0.26358267664909363, Acc: 0.9375\n",
            "Batch 372/1041, Loss: 0.280299574136734, Acc: 0.90625\n",
            "Batch 373/1041, Loss: 0.4259272813796997, Acc: 0.84375\n",
            "Batch 374/1041, Loss: 0.46591916680336, Acc: 0.71875\n",
            "Batch 375/1041, Loss: 0.4325445294380188, Acc: 0.84375\n",
            "Batch 376/1041, Loss: 0.33395227789878845, Acc: 0.84375\n",
            "Batch 377/1041, Loss: 0.5695260167121887, Acc: 0.6875\n",
            "Batch 378/1041, Loss: 0.3620733618736267, Acc: 0.875\n",
            "Batch 379/1041, Loss: 0.4010569453239441, Acc: 0.78125\n",
            "Batch 380/1041, Loss: 0.38934317231178284, Acc: 0.84375\n",
            "Batch 381/1041, Loss: 0.3249879777431488, Acc: 0.84375\n",
            "Batch 382/1041, Loss: 0.4005330502986908, Acc: 0.8125\n",
            "Batch 383/1041, Loss: 0.4328705370426178, Acc: 0.875\n",
            "Batch 384/1041, Loss: 0.3410385251045227, Acc: 0.78125\n",
            "Batch 385/1041, Loss: 0.4198705554008484, Acc: 0.84375\n",
            "Batch 386/1041, Loss: 0.4672112762928009, Acc: 0.875\n",
            "Batch 387/1041, Loss: 0.2397502064704895, Acc: 0.96875\n",
            "Batch 388/1041, Loss: 0.23628473281860352, Acc: 0.90625\n",
            "Batch 389/1041, Loss: 0.4960024952888489, Acc: 0.71875\n",
            "Batch 390/1041, Loss: 0.51244056224823, Acc: 0.75\n",
            "Batch 391/1041, Loss: 0.4016452431678772, Acc: 0.84375\n",
            "Batch 392/1041, Loss: 0.45636704564094543, Acc: 0.8125\n",
            "Batch 393/1041, Loss: 0.3136413097381592, Acc: 0.875\n",
            "Batch 394/1041, Loss: 0.3334633708000183, Acc: 0.84375\n",
            "Batch 395/1041, Loss: 0.24923521280288696, Acc: 0.9375\n",
            "Batch 396/1041, Loss: 0.29487890005111694, Acc: 0.875\n",
            "Batch 397/1041, Loss: 0.49313393235206604, Acc: 0.71875\n",
            "Batch 398/1041, Loss: 0.3693585693836212, Acc: 0.90625\n",
            "Batch 399/1041, Loss: 0.480596661567688, Acc: 0.78125\n",
            "Batch 400/1041, Loss: 0.4817449748516083, Acc: 0.78125\n",
            "[Update 400] Train Loss: 0.4817, Train Acc: 0.7812 | Val Loss: 0.3836, Val Acc: 0.8311\n",
            "Batch 401/1041, Loss: 0.42667123675346375, Acc: 0.78125\n",
            "Batch 402/1041, Loss: 0.4289477467536926, Acc: 0.78125\n",
            "Batch 403/1041, Loss: 0.509804368019104, Acc: 0.78125\n",
            "Batch 404/1041, Loss: 0.30114269256591797, Acc: 0.90625\n",
            "Batch 405/1041, Loss: 0.4273054003715515, Acc: 0.75\n",
            "Batch 406/1041, Loss: 0.5997649431228638, Acc: 0.75\n",
            "Batch 407/1041, Loss: 0.4417025148868561, Acc: 0.78125\n",
            "Batch 408/1041, Loss: 0.3853047490119934, Acc: 0.84375\n",
            "Batch 409/1041, Loss: 0.26806777715682983, Acc: 0.875\n",
            "Batch 410/1041, Loss: 0.5325949788093567, Acc: 0.75\n",
            "Batch 411/1041, Loss: 0.6055945754051208, Acc: 0.75\n",
            "Batch 412/1041, Loss: 0.3893946409225464, Acc: 0.8125\n",
            "Batch 413/1041, Loss: 0.5979873538017273, Acc: 0.75\n",
            "Batch 414/1041, Loss: 0.3564006984233856, Acc: 0.84375\n",
            "Batch 415/1041, Loss: 0.6105883717536926, Acc: 0.71875\n",
            "Batch 416/1041, Loss: 0.3951837122440338, Acc: 0.8125\n",
            "Batch 417/1041, Loss: 0.404710978269577, Acc: 0.78125\n",
            "Batch 418/1041, Loss: 0.3095659613609314, Acc: 0.875\n",
            "Batch 419/1041, Loss: 0.49897775053977966, Acc: 0.65625\n",
            "Batch 420/1041, Loss: 0.3574828505516052, Acc: 0.875\n",
            "Batch 421/1041, Loss: 0.4967659115791321, Acc: 0.78125\n",
            "Batch 422/1041, Loss: 0.3949342668056488, Acc: 0.875\n",
            "Batch 423/1041, Loss: 0.33788472414016724, Acc: 0.84375\n",
            "Batch 424/1041, Loss: 0.3806706666946411, Acc: 0.8125\n",
            "Batch 425/1041, Loss: 0.3228544592857361, Acc: 0.84375\n",
            "Batch 426/1041, Loss: 0.42855533957481384, Acc: 0.75\n",
            "Batch 427/1041, Loss: 0.47867900133132935, Acc: 0.8125\n",
            "Batch 428/1041, Loss: 0.4623667299747467, Acc: 0.78125\n",
            "Batch 429/1041, Loss: 0.4249661862850189, Acc: 0.78125\n",
            "Batch 430/1041, Loss: 0.5545082092285156, Acc: 0.6875\n",
            "Batch 431/1041, Loss: 0.31509098410606384, Acc: 0.84375\n",
            "Batch 432/1041, Loss: 0.27466440200805664, Acc: 0.9375\n",
            "Batch 433/1041, Loss: 0.38487640023231506, Acc: 0.8125\n",
            "Batch 434/1041, Loss: 0.3542218804359436, Acc: 0.8125\n",
            "Batch 435/1041, Loss: 0.42882677912712097, Acc: 0.84375\n",
            "Batch 436/1041, Loss: 0.6582711338996887, Acc: 0.65625\n",
            "Batch 437/1041, Loss: 0.4282885491847992, Acc: 0.78125\n",
            "Batch 438/1041, Loss: 0.49695202708244324, Acc: 0.6875\n",
            "Batch 439/1041, Loss: 0.5610654950141907, Acc: 0.71875\n",
            "Batch 440/1041, Loss: 0.44013550877571106, Acc: 0.71875\n",
            "Batch 441/1041, Loss: 0.45676395297050476, Acc: 0.78125\n",
            "Batch 442/1041, Loss: 0.4477527141571045, Acc: 0.78125\n",
            "Batch 443/1041, Loss: 0.563297688961029, Acc: 0.71875\n",
            "Batch 444/1041, Loss: 0.380695641040802, Acc: 0.8125\n",
            "Batch 445/1041, Loss: 0.4528754949569702, Acc: 0.875\n",
            "Batch 446/1041, Loss: 0.592731773853302, Acc: 0.71875\n",
            "Batch 447/1041, Loss: 0.3634486794471741, Acc: 0.84375\n",
            "Batch 448/1041, Loss: 0.43343567848205566, Acc: 0.8125\n",
            "Batch 449/1041, Loss: 0.5064102411270142, Acc: 0.75\n",
            "Batch 450/1041, Loss: 0.3383488059043884, Acc: 0.8125\n",
            "Batch 451/1041, Loss: 0.378839910030365, Acc: 0.875\n",
            "Batch 452/1041, Loss: 0.427787184715271, Acc: 0.8125\n",
            "Batch 453/1041, Loss: 0.34211891889572144, Acc: 0.84375\n",
            "Batch 454/1041, Loss: 0.40636417269706726, Acc: 0.8125\n",
            "Batch 455/1041, Loss: 0.5542110204696655, Acc: 0.75\n",
            "Batch 456/1041, Loss: 0.4060594141483307, Acc: 0.75\n",
            "Batch 457/1041, Loss: 0.3451566696166992, Acc: 0.84375\n",
            "Batch 458/1041, Loss: 0.5009056329727173, Acc: 0.75\n",
            "Batch 459/1041, Loss: 0.4465802013874054, Acc: 0.78125\n",
            "Batch 460/1041, Loss: 0.5979160666465759, Acc: 0.71875\n",
            "Batch 461/1041, Loss: 0.3688751757144928, Acc: 0.84375\n",
            "Batch 462/1041, Loss: 0.35266873240470886, Acc: 0.84375\n",
            "Batch 463/1041, Loss: 0.34259912371635437, Acc: 0.875\n",
            "Batch 464/1041, Loss: 0.5725288391113281, Acc: 0.75\n",
            "Batch 465/1041, Loss: 0.30842262506484985, Acc: 0.90625\n",
            "Batch 466/1041, Loss: 0.21357589960098267, Acc: 1.0\n",
            "Batch 467/1041, Loss: 0.3759305477142334, Acc: 0.78125\n",
            "Batch 468/1041, Loss: 0.5312675833702087, Acc: 0.78125\n",
            "Batch 469/1041, Loss: 0.2872113585472107, Acc: 0.875\n",
            "Batch 470/1041, Loss: 0.3319084346294403, Acc: 0.875\n",
            "Batch 471/1041, Loss: 0.3644550144672394, Acc: 0.875\n",
            "Batch 472/1041, Loss: 0.35420480370521545, Acc: 0.875\n",
            "Batch 473/1041, Loss: 0.41427698731422424, Acc: 0.78125\n",
            "Batch 474/1041, Loss: 0.5070768594741821, Acc: 0.75\n",
            "Batch 475/1041, Loss: 0.47827979922294617, Acc: 0.84375\n",
            "Batch 476/1041, Loss: 0.428744375705719, Acc: 0.78125\n",
            "Batch 477/1041, Loss: 0.3500139117240906, Acc: 0.8125\n",
            "Batch 478/1041, Loss: 0.39167389273643494, Acc: 0.78125\n",
            "Batch 479/1041, Loss: 0.5530173182487488, Acc: 0.71875\n",
            "Batch 480/1041, Loss: 0.43718981742858887, Acc: 0.78125\n",
            "Batch 481/1041, Loss: 0.2701917588710785, Acc: 0.875\n",
            "Batch 482/1041, Loss: 0.46208351850509644, Acc: 0.84375\n",
            "Batch 483/1041, Loss: 0.4678783416748047, Acc: 0.8125\n",
            "Batch 484/1041, Loss: 0.2857673764228821, Acc: 0.9375\n",
            "Batch 485/1041, Loss: 0.4556443691253662, Acc: 0.71875\n",
            "Batch 486/1041, Loss: 0.38505759835243225, Acc: 0.78125\n",
            "Batch 487/1041, Loss: 0.3218877613544464, Acc: 0.875\n",
            "Batch 488/1041, Loss: 0.4383927881717682, Acc: 0.8125\n",
            "Batch 489/1041, Loss: 0.5598750710487366, Acc: 0.75\n",
            "Batch 490/1041, Loss: 0.5834125876426697, Acc: 0.71875\n",
            "Batch 491/1041, Loss: 0.4104134142398834, Acc: 0.8125\n",
            "Batch 492/1041, Loss: 0.49727198481559753, Acc: 0.78125\n",
            "Batch 493/1041, Loss: 0.2509631812572479, Acc: 0.90625\n",
            "Batch 494/1041, Loss: 0.37422946095466614, Acc: 0.8125\n",
            "Batch 495/1041, Loss: 0.42426565289497375, Acc: 0.84375\n",
            "Batch 496/1041, Loss: 0.29235488176345825, Acc: 0.9375\n",
            "Batch 497/1041, Loss: 0.6915207505226135, Acc: 0.65625\n",
            "Batch 498/1041, Loss: 0.39540526270866394, Acc: 0.84375\n",
            "Batch 499/1041, Loss: 0.4560566246509552, Acc: 0.8125\n",
            "Batch 500/1041, Loss: 0.334613174200058, Acc: 0.9375\n",
            "[Update 500] Train Loss: 0.3346, Train Acc: 0.9375 | Val Loss: 0.3866, Val Acc: 0.8379\n",
            "Batch 501/1041, Loss: 0.6022800803184509, Acc: 0.71875\n",
            "Batch 502/1041, Loss: 0.5465372800827026, Acc: 0.78125\n",
            "Batch 503/1041, Loss: 0.3874490559101105, Acc: 0.90625\n",
            "Batch 504/1041, Loss: 0.4221729338169098, Acc: 0.875\n",
            "Batch 505/1041, Loss: 0.5242736339569092, Acc: 0.71875\n",
            "Batch 506/1041, Loss: 0.3707118034362793, Acc: 0.75\n",
            "Batch 507/1041, Loss: 0.5718228816986084, Acc: 0.71875\n",
            "Batch 508/1041, Loss: 0.3890070617198944, Acc: 0.8125\n",
            "Batch 509/1041, Loss: 0.31621915102005005, Acc: 0.90625\n",
            "Batch 510/1041, Loss: 0.386709600687027, Acc: 0.71875\n",
            "Batch 511/1041, Loss: 0.6589280962944031, Acc: 0.5625\n",
            "Batch 512/1041, Loss: 0.6150745749473572, Acc: 0.8125\n",
            "Batch 513/1041, Loss: 0.19099584221839905, Acc: 1.0\n",
            "Batch 514/1041, Loss: 0.3983682692050934, Acc: 0.8125\n",
            "Batch 515/1041, Loss: 0.435733824968338, Acc: 0.78125\n",
            "Batch 516/1041, Loss: 0.6891126036643982, Acc: 0.75\n",
            "Batch 517/1041, Loss: 0.26168563961982727, Acc: 0.90625\n",
            "Batch 518/1041, Loss: 0.3590760827064514, Acc: 0.875\n",
            "Batch 519/1041, Loss: 0.31441259384155273, Acc: 0.84375\n",
            "Batch 520/1041, Loss: 0.44240278005599976, Acc: 0.84375\n",
            "Batch 521/1041, Loss: 0.4065181016921997, Acc: 0.8125\n",
            "Batch 522/1041, Loss: 0.3471836745738983, Acc: 0.90625\n",
            "Batch 523/1041, Loss: 0.38007768988609314, Acc: 0.875\n",
            "Batch 524/1041, Loss: 0.5334009528160095, Acc: 0.75\n",
            "Batch 525/1041, Loss: 0.26159363985061646, Acc: 0.9375\n",
            "Batch 526/1041, Loss: 0.3503202497959137, Acc: 0.90625\n",
            "Batch 527/1041, Loss: 0.5172916650772095, Acc: 0.71875\n",
            "Batch 528/1041, Loss: 0.44276300072669983, Acc: 0.78125\n",
            "Batch 529/1041, Loss: 0.5299464464187622, Acc: 0.78125\n",
            "Batch 530/1041, Loss: 0.4755171537399292, Acc: 0.78125\n",
            "Batch 531/1041, Loss: 0.40865230560302734, Acc: 0.78125\n",
            "Batch 532/1041, Loss: 0.5442584753036499, Acc: 0.75\n",
            "Batch 533/1041, Loss: 0.3118870258331299, Acc: 0.84375\n",
            "Batch 534/1041, Loss: 0.47411420941352844, Acc: 0.78125\n",
            "Batch 535/1041, Loss: 0.4267299771308899, Acc: 0.78125\n",
            "Batch 536/1041, Loss: 0.28444504737854004, Acc: 0.84375\n",
            "Batch 537/1041, Loss: 0.4456273913383484, Acc: 0.75\n",
            "Batch 538/1041, Loss: 0.3745758533477783, Acc: 0.84375\n",
            "Batch 539/1041, Loss: 0.3293818235397339, Acc: 0.84375\n",
            "Batch 540/1041, Loss: 0.4388248324394226, Acc: 0.78125\n",
            "Batch 541/1041, Loss: 0.3999672830104828, Acc: 0.8125\n",
            "Batch 542/1041, Loss: 0.3567039668560028, Acc: 0.78125\n",
            "Batch 543/1041, Loss: 0.45085224509239197, Acc: 0.78125\n",
            "Batch 544/1041, Loss: 0.3184136152267456, Acc: 0.84375\n",
            "Batch 545/1041, Loss: 0.3277033865451813, Acc: 0.8125\n",
            "Batch 546/1041, Loss: 0.4461926519870758, Acc: 0.84375\n",
            "Batch 547/1041, Loss: 0.3109816014766693, Acc: 0.90625\n",
            "Batch 548/1041, Loss: 0.4650207459926605, Acc: 0.84375\n",
            "Batch 549/1041, Loss: 0.2686862349510193, Acc: 0.84375\n",
            "Batch 550/1041, Loss: 0.4583531618118286, Acc: 0.84375\n",
            "Batch 551/1041, Loss: 0.4159744679927826, Acc: 0.84375\n",
            "Batch 552/1041, Loss: 0.3356262445449829, Acc: 0.875\n",
            "Batch 553/1041, Loss: 0.34363850951194763, Acc: 0.84375\n",
            "Batch 554/1041, Loss: 0.4022209644317627, Acc: 0.8125\n",
            "Batch 555/1041, Loss: 0.5290688872337341, Acc: 0.75\n",
            "Batch 556/1041, Loss: 0.46828362345695496, Acc: 0.75\n",
            "Batch 557/1041, Loss: 0.3499007523059845, Acc: 0.84375\n",
            "Batch 558/1041, Loss: 0.24979759752750397, Acc: 0.90625\n",
            "Batch 559/1041, Loss: 0.30975955724716187, Acc: 0.9375\n",
            "Batch 560/1041, Loss: 0.5299476981163025, Acc: 0.71875\n",
            "Batch 561/1041, Loss: 0.3385874032974243, Acc: 0.84375\n",
            "Batch 562/1041, Loss: 0.5460079908370972, Acc: 0.75\n",
            "Batch 563/1041, Loss: 0.47520002722740173, Acc: 0.78125\n",
            "Batch 564/1041, Loss: 0.30287978053092957, Acc: 0.90625\n",
            "Batch 565/1041, Loss: 0.255115807056427, Acc: 0.96875\n",
            "Batch 566/1041, Loss: 0.29411378502845764, Acc: 0.90625\n",
            "Batch 567/1041, Loss: 0.27177760004997253, Acc: 0.875\n",
            "Batch 568/1041, Loss: 0.3810911178588867, Acc: 0.78125\n",
            "Batch 569/1041, Loss: 0.41932931542396545, Acc: 0.84375\n",
            "Batch 570/1041, Loss: 0.4263227880001068, Acc: 0.75\n",
            "Batch 571/1041, Loss: 0.44889432191848755, Acc: 0.78125\n",
            "Batch 572/1041, Loss: 0.48574188351631165, Acc: 0.75\n",
            "Batch 573/1041, Loss: 0.3167053163051605, Acc: 0.84375\n",
            "Batch 574/1041, Loss: 0.38147175312042236, Acc: 0.84375\n",
            "Batch 575/1041, Loss: 0.2546718716621399, Acc: 0.9375\n",
            "Batch 576/1041, Loss: 0.617392897605896, Acc: 0.6875\n",
            "Batch 577/1041, Loss: 0.3394072651863098, Acc: 0.875\n",
            "Batch 578/1041, Loss: 0.47852447628974915, Acc: 0.75\n",
            "Batch 579/1041, Loss: 0.3816828429698944, Acc: 0.78125\n",
            "Batch 580/1041, Loss: 0.19375979900360107, Acc: 0.96875\n",
            "Batch 581/1041, Loss: 0.35830676555633545, Acc: 0.84375\n",
            "Batch 582/1041, Loss: 0.36330854892730713, Acc: 0.78125\n",
            "Batch 583/1041, Loss: 0.4593832194805145, Acc: 0.84375\n",
            "Batch 584/1041, Loss: 0.4828174114227295, Acc: 0.84375\n",
            "Batch 585/1041, Loss: 0.41072341799736023, Acc: 0.78125\n",
            "Batch 586/1041, Loss: 0.2997865676879883, Acc: 0.84375\n",
            "Batch 587/1041, Loss: 0.2788909673690796, Acc: 0.875\n",
            "Batch 588/1041, Loss: 0.41918593645095825, Acc: 0.8125\n",
            "Batch 589/1041, Loss: 0.571381688117981, Acc: 0.6875\n",
            "Batch 590/1041, Loss: 0.37634411454200745, Acc: 0.78125\n",
            "Batch 591/1041, Loss: 0.45471471548080444, Acc: 0.78125\n",
            "Batch 592/1041, Loss: 0.3255678415298462, Acc: 0.84375\n",
            "Batch 593/1041, Loss: 0.4040497839450836, Acc: 0.84375\n",
            "Batch 594/1041, Loss: 0.42857030034065247, Acc: 0.78125\n",
            "Batch 595/1041, Loss: 0.5532228946685791, Acc: 0.78125\n",
            "Batch 596/1041, Loss: 0.38470783829689026, Acc: 0.84375\n",
            "Batch 597/1041, Loss: 0.5678585767745972, Acc: 0.71875\n",
            "Batch 598/1041, Loss: 0.31701311469078064, Acc: 0.90625\n",
            "Batch 599/1041, Loss: 0.36611372232437134, Acc: 0.84375\n",
            "Batch 600/1041, Loss: 0.45817065238952637, Acc: 0.75\n",
            "[Update 600] Train Loss: 0.4582, Train Acc: 0.7500 | Val Loss: 0.3588, Val Acc: 0.8509\n",
            "Batch 601/1041, Loss: 0.3017582297325134, Acc: 0.84375\n",
            "Batch 602/1041, Loss: 0.35438475012779236, Acc: 0.875\n",
            "Batch 603/1041, Loss: 0.3804815113544464, Acc: 0.8125\n",
            "Batch 604/1041, Loss: 0.5196502208709717, Acc: 0.78125\n",
            "Batch 605/1041, Loss: 0.3785734176635742, Acc: 0.84375\n",
            "Batch 606/1041, Loss: 0.30564799904823303, Acc: 0.90625\n",
            "Batch 607/1041, Loss: 0.34040382504463196, Acc: 0.84375\n",
            "Batch 608/1041, Loss: 0.4447619616985321, Acc: 0.78125\n",
            "Batch 609/1041, Loss: 0.43926799297332764, Acc: 0.75\n",
            "Batch 610/1041, Loss: 0.41511034965515137, Acc: 0.8125\n",
            "Batch 611/1041, Loss: 0.24385568499565125, Acc: 0.96875\n",
            "Batch 612/1041, Loss: 0.5258644819259644, Acc: 0.6875\n",
            "Batch 613/1041, Loss: 0.3260054290294647, Acc: 0.875\n",
            "Batch 614/1041, Loss: 0.38535645604133606, Acc: 0.8125\n",
            "Batch 615/1041, Loss: 0.3228371739387512, Acc: 0.875\n",
            "Batch 616/1041, Loss: 0.34555667638778687, Acc: 0.875\n",
            "Batch 617/1041, Loss: 0.4050477147102356, Acc: 0.875\n",
            "Batch 618/1041, Loss: 0.2763229310512543, Acc: 0.90625\n",
            "Batch 619/1041, Loss: 0.32695773243904114, Acc: 0.875\n",
            "Batch 620/1041, Loss: 0.5622908473014832, Acc: 0.71875\n",
            "Batch 621/1041, Loss: 0.3962979316711426, Acc: 0.9375\n",
            "Batch 622/1041, Loss: 0.4601614773273468, Acc: 0.8125\n",
            "Batch 623/1041, Loss: 0.2919130325317383, Acc: 0.9375\n",
            "Batch 624/1041, Loss: 0.42684754729270935, Acc: 0.75\n",
            "Batch 625/1041, Loss: 0.32677188515663147, Acc: 0.875\n",
            "Batch 626/1041, Loss: 0.47761833667755127, Acc: 0.75\n",
            "Batch 627/1041, Loss: 0.32296013832092285, Acc: 0.8125\n",
            "Batch 628/1041, Loss: 0.49172231554985046, Acc: 0.8125\n",
            "Batch 629/1041, Loss: 0.3904021084308624, Acc: 0.8125\n",
            "Batch 630/1041, Loss: 0.29569655656814575, Acc: 0.84375\n",
            "Batch 631/1041, Loss: 0.45642945170402527, Acc: 0.71875\n",
            "Batch 632/1041, Loss: 0.43632689118385315, Acc: 0.8125\n",
            "Batch 633/1041, Loss: 0.33180978894233704, Acc: 0.9375\n",
            "Batch 634/1041, Loss: 0.35363149642944336, Acc: 0.875\n",
            "Batch 635/1041, Loss: 0.594843864440918, Acc: 0.65625\n",
            "Batch 636/1041, Loss: 0.301851361989975, Acc: 0.875\n",
            "Batch 637/1041, Loss: 0.3031379282474518, Acc: 0.8125\n",
            "Batch 638/1041, Loss: 0.42427048087120056, Acc: 0.75\n",
            "Batch 639/1041, Loss: 0.4131772816181183, Acc: 0.8125\n",
            "Batch 640/1041, Loss: 0.4981853663921356, Acc: 0.71875\n",
            "Batch 641/1041, Loss: 0.32016900181770325, Acc: 0.875\n",
            "Batch 642/1041, Loss: 0.5223934054374695, Acc: 0.71875\n",
            "Batch 643/1041, Loss: 0.40990155935287476, Acc: 0.78125\n",
            "Batch 644/1041, Loss: 0.46005019545555115, Acc: 0.84375\n",
            "Batch 645/1041, Loss: 0.49639439582824707, Acc: 0.71875\n",
            "Batch 646/1041, Loss: 0.4389655888080597, Acc: 0.8125\n",
            "Batch 647/1041, Loss: 0.22824373841285706, Acc: 0.90625\n",
            "Batch 648/1041, Loss: 0.4175220727920532, Acc: 0.75\n",
            "Batch 649/1041, Loss: 0.318852037191391, Acc: 0.875\n",
            "Batch 650/1041, Loss: 0.4560641646385193, Acc: 0.8125\n",
            "Batch 651/1041, Loss: 0.37041690945625305, Acc: 0.8125\n",
            "Batch 652/1041, Loss: 0.448263943195343, Acc: 0.6875\n",
            "Batch 653/1041, Loss: 0.37836456298828125, Acc: 0.84375\n",
            "Batch 654/1041, Loss: 0.32528823614120483, Acc: 0.84375\n",
            "Batch 655/1041, Loss: 0.2998720109462738, Acc: 0.875\n",
            "Batch 656/1041, Loss: 0.24051210284233093, Acc: 0.9375\n",
            "Batch 657/1041, Loss: 0.3627937138080597, Acc: 0.84375\n",
            "Batch 658/1041, Loss: 0.5341150164604187, Acc: 0.625\n",
            "Batch 659/1041, Loss: 0.30720895528793335, Acc: 0.84375\n",
            "Batch 660/1041, Loss: 0.3326506018638611, Acc: 0.875\n",
            "Batch 661/1041, Loss: 0.4082237482070923, Acc: 0.8125\n",
            "Batch 662/1041, Loss: 0.4378991723060608, Acc: 0.8125\n",
            "Batch 663/1041, Loss: 0.48918259143829346, Acc: 0.75\n",
            "Batch 664/1041, Loss: 0.5460922718048096, Acc: 0.75\n",
            "Batch 665/1041, Loss: 0.4680134952068329, Acc: 0.84375\n",
            "Batch 666/1041, Loss: 0.511555552482605, Acc: 0.78125\n",
            "Batch 667/1041, Loss: 0.2670782208442688, Acc: 0.90625\n",
            "Batch 668/1041, Loss: 0.3613576889038086, Acc: 0.90625\n",
            "Batch 669/1041, Loss: 0.4236157536506653, Acc: 0.8125\n",
            "Batch 670/1041, Loss: 0.25439390540122986, Acc: 0.90625\n",
            "Batch 671/1041, Loss: 0.4727184474468231, Acc: 0.75\n",
            "Batch 672/1041, Loss: 0.327394038438797, Acc: 0.90625\n",
            "Batch 673/1041, Loss: 0.29181143641471863, Acc: 0.875\n",
            "Batch 674/1041, Loss: 0.39636069536209106, Acc: 0.8125\n",
            "Batch 675/1041, Loss: 0.36804357171058655, Acc: 0.90625\n",
            "Batch 676/1041, Loss: 0.40248313546180725, Acc: 0.8125\n",
            "Batch 677/1041, Loss: 0.37184786796569824, Acc: 0.8125\n",
            "Batch 678/1041, Loss: 0.48593661189079285, Acc: 0.78125\n",
            "Batch 679/1041, Loss: 0.4985472559928894, Acc: 0.8125\n",
            "Batch 680/1041, Loss: 0.3651660680770874, Acc: 0.84375\n",
            "Batch 681/1041, Loss: 0.3908330202102661, Acc: 0.8125\n",
            "Batch 682/1041, Loss: 0.28404539823532104, Acc: 0.84375\n",
            "Batch 683/1041, Loss: 0.3458866477012634, Acc: 0.84375\n",
            "Batch 684/1041, Loss: 0.2607363760471344, Acc: 0.9375\n",
            "Batch 685/1041, Loss: 0.4134019613265991, Acc: 0.71875\n",
            "Batch 686/1041, Loss: 0.37719404697418213, Acc: 0.84375\n",
            "Batch 687/1041, Loss: 0.3650953769683838, Acc: 0.84375\n",
            "Batch 688/1041, Loss: 0.36837995052337646, Acc: 0.8125\n",
            "Batch 689/1041, Loss: 0.13097716867923737, Acc: 1.0\n",
            "Batch 690/1041, Loss: 0.3307783007621765, Acc: 0.8125\n",
            "Batch 691/1041, Loss: 0.3596791625022888, Acc: 0.8125\n",
            "Batch 692/1041, Loss: 0.3609219789505005, Acc: 0.875\n",
            "Batch 693/1041, Loss: 0.18683969974517822, Acc: 0.9375\n",
            "Batch 694/1041, Loss: 0.36699050664901733, Acc: 0.875\n",
            "Batch 695/1041, Loss: 0.5570293664932251, Acc: 0.75\n",
            "Batch 696/1041, Loss: 0.34798505902290344, Acc: 0.84375\n",
            "Batch 697/1041, Loss: 0.3864898979663849, Acc: 0.78125\n",
            "Batch 698/1041, Loss: 0.33263644576072693, Acc: 0.875\n",
            "Batch 699/1041, Loss: 0.464254230260849, Acc: 0.8125\n",
            "Batch 700/1041, Loss: 0.3597938120365143, Acc: 0.8125\n",
            "[Update 700] Train Loss: 0.3598, Train Acc: 0.8125 | Val Loss: 0.3519, Val Acc: 0.8503\n",
            "Batch 701/1041, Loss: 0.3776072859764099, Acc: 0.78125\n",
            "Batch 702/1041, Loss: 0.3177196979522705, Acc: 0.875\n",
            "Batch 703/1041, Loss: 0.24038539826869965, Acc: 0.90625\n",
            "Batch 704/1041, Loss: 0.38539785146713257, Acc: 0.875\n",
            "Batch 705/1041, Loss: 0.34030744433403015, Acc: 0.8125\n",
            "Batch 706/1041, Loss: 0.4420897364616394, Acc: 0.71875\n",
            "Batch 707/1041, Loss: 0.2856684625148773, Acc: 0.90625\n",
            "Batch 708/1041, Loss: 0.3698483109474182, Acc: 0.875\n",
            "Batch 709/1041, Loss: 0.4175117313861847, Acc: 0.8125\n",
            "Batch 710/1041, Loss: 0.5099597573280334, Acc: 0.8125\n",
            "Batch 711/1041, Loss: 0.402704656124115, Acc: 0.8125\n",
            "Batch 712/1041, Loss: 0.3089001774787903, Acc: 0.9375\n",
            "Batch 713/1041, Loss: 0.4893887937068939, Acc: 0.71875\n",
            "Batch 714/1041, Loss: 0.4500284492969513, Acc: 0.75\n",
            "Batch 715/1041, Loss: 0.23164770007133484, Acc: 0.90625\n",
            "Batch 716/1041, Loss: 0.3539971709251404, Acc: 0.78125\n",
            "Batch 717/1041, Loss: 0.5160523653030396, Acc: 0.6875\n",
            "Batch 718/1041, Loss: 0.3902443051338196, Acc: 0.78125\n",
            "Batch 719/1041, Loss: 0.4087514579296112, Acc: 0.75\n",
            "Batch 720/1041, Loss: 0.6659702658653259, Acc: 0.71875\n",
            "Batch 721/1041, Loss: 0.3530644178390503, Acc: 0.8125\n",
            "Batch 722/1041, Loss: 0.4077364206314087, Acc: 0.84375\n",
            "Batch 723/1041, Loss: 0.3926682770252228, Acc: 0.8125\n",
            "Batch 724/1041, Loss: 0.34876635670661926, Acc: 0.84375\n",
            "Batch 725/1041, Loss: 0.25546184182167053, Acc: 0.90625\n",
            "Batch 726/1041, Loss: 0.4431924819946289, Acc: 0.84375\n",
            "Batch 727/1041, Loss: 0.3195274770259857, Acc: 0.875\n",
            "Batch 728/1041, Loss: 0.23637613654136658, Acc: 0.9375\n",
            "Batch 729/1041, Loss: 0.4956049621105194, Acc: 0.8125\n",
            "Batch 730/1041, Loss: 0.2902594804763794, Acc: 0.875\n",
            "Batch 731/1041, Loss: 0.6198145151138306, Acc: 0.75\n",
            "Batch 732/1041, Loss: 0.37976130843162537, Acc: 0.84375\n",
            "Batch 733/1041, Loss: 0.2646263837814331, Acc: 0.90625\n",
            "Batch 734/1041, Loss: 0.3108411729335785, Acc: 0.875\n",
            "Batch 735/1041, Loss: 0.619830846786499, Acc: 0.71875\n",
            "Batch 736/1041, Loss: 0.31118905544281006, Acc: 0.90625\n",
            "Batch 737/1041, Loss: 0.6795378923416138, Acc: 0.6875\n",
            "Batch 738/1041, Loss: 0.2889423668384552, Acc: 0.84375\n",
            "Batch 739/1041, Loss: 0.580919086933136, Acc: 0.8125\n",
            "Batch 740/1041, Loss: 0.3358358144760132, Acc: 0.8125\n",
            "Batch 741/1041, Loss: 0.3551817238330841, Acc: 0.84375\n",
            "Batch 742/1041, Loss: 0.42127493023872375, Acc: 0.75\n",
            "Batch 743/1041, Loss: 0.3271859288215637, Acc: 0.875\n",
            "Batch 744/1041, Loss: 0.6951169967651367, Acc: 0.71875\n",
            "Batch 745/1041, Loss: 0.30537813901901245, Acc: 0.875\n",
            "Batch 746/1041, Loss: 0.37543272972106934, Acc: 0.84375\n",
            "Batch 747/1041, Loss: 0.3301127552986145, Acc: 0.8125\n",
            "Batch 748/1041, Loss: 0.47866716980934143, Acc: 0.8125\n",
            "Batch 749/1041, Loss: 0.25599002838134766, Acc: 0.90625\n",
            "Batch 750/1041, Loss: 0.3891523480415344, Acc: 0.78125\n",
            "Batch 751/1041, Loss: 0.4489407539367676, Acc: 0.78125\n",
            "Batch 752/1041, Loss: 0.47956031560897827, Acc: 0.8125\n",
            "Batch 753/1041, Loss: 0.378196120262146, Acc: 0.8125\n",
            "Batch 754/1041, Loss: 0.1840182989835739, Acc: 0.96875\n",
            "Batch 755/1041, Loss: 0.39980730414390564, Acc: 0.8125\n",
            "Batch 756/1041, Loss: 0.28156858682632446, Acc: 0.9375\n",
            "Batch 757/1041, Loss: 0.3071211278438568, Acc: 0.875\n",
            "Batch 758/1041, Loss: 0.46024996042251587, Acc: 0.78125\n",
            "Batch 759/1041, Loss: 0.4562595784664154, Acc: 0.78125\n",
            "Batch 760/1041, Loss: 0.4038650691509247, Acc: 0.8125\n",
            "Batch 761/1041, Loss: 0.39167237281799316, Acc: 0.8125\n",
            "Batch 762/1041, Loss: 0.43990159034729004, Acc: 0.78125\n",
            "Batch 763/1041, Loss: 0.29407817125320435, Acc: 0.9375\n",
            "Batch 764/1041, Loss: 0.4998144805431366, Acc: 0.78125\n",
            "Batch 765/1041, Loss: 0.4094611704349518, Acc: 0.84375\n",
            "Batch 766/1041, Loss: 0.5402936935424805, Acc: 0.6875\n",
            "Batch 767/1041, Loss: 0.348054975271225, Acc: 0.875\n",
            "Batch 768/1041, Loss: 0.24130946397781372, Acc: 0.9375\n",
            "Batch 769/1041, Loss: 0.3293387293815613, Acc: 0.875\n",
            "Batch 770/1041, Loss: 0.48914530873298645, Acc: 0.8125\n",
            "Batch 771/1041, Loss: 0.437633752822876, Acc: 0.78125\n",
            "Batch 772/1041, Loss: 0.41302698850631714, Acc: 0.78125\n",
            "Batch 773/1041, Loss: 0.3136572241783142, Acc: 0.84375\n",
            "Batch 774/1041, Loss: 0.4278905391693115, Acc: 0.78125\n",
            "Batch 775/1041, Loss: 0.3671899437904358, Acc: 0.78125\n",
            "Batch 776/1041, Loss: 0.49741119146347046, Acc: 0.78125\n",
            "Batch 777/1041, Loss: 0.3878057599067688, Acc: 0.84375\n",
            "Batch 778/1041, Loss: 0.3102649748325348, Acc: 0.84375\n",
            "Batch 779/1041, Loss: 0.3277878761291504, Acc: 0.84375\n",
            "Batch 780/1041, Loss: 0.4065742790699005, Acc: 0.875\n",
            "Batch 781/1041, Loss: 0.649905800819397, Acc: 0.75\n",
            "Batch 782/1041, Loss: 0.43126681447029114, Acc: 0.75\n",
            "Batch 783/1041, Loss: 0.5394104719161987, Acc: 0.71875\n",
            "Batch 784/1041, Loss: 0.4584676921367645, Acc: 0.6875\n",
            "Batch 785/1041, Loss: 0.35304826498031616, Acc: 0.84375\n",
            "Batch 786/1041, Loss: 0.4726071357727051, Acc: 0.78125\n",
            "Batch 787/1041, Loss: 0.2904193699359894, Acc: 0.90625\n",
            "Batch 788/1041, Loss: 0.43561938405036926, Acc: 0.78125\n",
            "Batch 789/1041, Loss: 0.27173712849617004, Acc: 0.9375\n",
            "Batch 790/1041, Loss: 0.2455512285232544, Acc: 0.9375\n",
            "Batch 791/1041, Loss: 0.2955991327762604, Acc: 0.875\n",
            "Batch 792/1041, Loss: 0.2804199755191803, Acc: 0.90625\n",
            "Batch 793/1041, Loss: 0.35083505511283875, Acc: 0.8125\n",
            "Batch 794/1041, Loss: 0.3319430947303772, Acc: 0.78125\n",
            "Batch 795/1041, Loss: 0.3401094079017639, Acc: 0.90625\n",
            "Batch 796/1041, Loss: 0.389326810836792, Acc: 0.84375\n",
            "Batch 797/1041, Loss: 0.24878132343292236, Acc: 0.90625\n",
            "Batch 798/1041, Loss: 0.41986140608787537, Acc: 0.78125\n",
            "Batch 799/1041, Loss: 0.5393790602684021, Acc: 0.8125\n",
            "Batch 800/1041, Loss: 0.3197365403175354, Acc: 0.875\n",
            "[Update 800] Train Loss: 0.3197, Train Acc: 0.8750 | Val Loss: 0.3602, Val Acc: 0.8451\n",
            "Batch 801/1041, Loss: 0.2705785036087036, Acc: 0.90625\n",
            "Batch 802/1041, Loss: 0.46468019485473633, Acc: 0.8125\n",
            "Batch 803/1041, Loss: 0.398691862821579, Acc: 0.84375\n",
            "Batch 804/1041, Loss: 0.28426194190979004, Acc: 0.90625\n",
            "Batch 805/1041, Loss: 0.3802187144756317, Acc: 0.78125\n",
            "Batch 806/1041, Loss: 0.240134596824646, Acc: 0.9375\n",
            "Batch 807/1041, Loss: 0.4457874894142151, Acc: 0.71875\n",
            "Batch 808/1041, Loss: 0.2984742820262909, Acc: 0.90625\n",
            "Batch 809/1041, Loss: 0.5398973226547241, Acc: 0.78125\n",
            "Batch 810/1041, Loss: 0.5102770328521729, Acc: 0.8125\n",
            "Batch 811/1041, Loss: 0.18625479936599731, Acc: 0.96875\n",
            "Batch 812/1041, Loss: 0.33096498250961304, Acc: 0.90625\n",
            "Batch 813/1041, Loss: 0.34145453572273254, Acc: 0.875\n",
            "Batch 814/1041, Loss: 0.5232396721839905, Acc: 0.71875\n",
            "Batch 815/1041, Loss: 0.3808785080909729, Acc: 0.875\n",
            "Batch 816/1041, Loss: 0.4793747365474701, Acc: 0.78125\n",
            "Batch 817/1041, Loss: 0.428132027387619, Acc: 0.84375\n",
            "Batch 818/1041, Loss: 0.32640141248703003, Acc: 0.90625\n",
            "Batch 819/1041, Loss: 0.3249482810497284, Acc: 0.90625\n",
            "Batch 820/1041, Loss: 0.33659452199935913, Acc: 0.84375\n",
            "Batch 821/1041, Loss: 0.3481098711490631, Acc: 0.78125\n",
            "Batch 822/1041, Loss: 0.35408732295036316, Acc: 0.875\n",
            "Batch 823/1041, Loss: 0.44893765449523926, Acc: 0.8125\n",
            "Batch 824/1041, Loss: 0.20871062576770782, Acc: 0.9375\n",
            "Batch 825/1041, Loss: 0.4012965261936188, Acc: 0.78125\n",
            "Batch 826/1041, Loss: 0.2817234992980957, Acc: 0.90625\n",
            "Batch 827/1041, Loss: 0.30611997842788696, Acc: 0.90625\n",
            "Batch 828/1041, Loss: 0.4348532259464264, Acc: 0.8125\n",
            "Batch 829/1041, Loss: 0.5193889737129211, Acc: 0.78125\n",
            "Batch 830/1041, Loss: 0.3448500335216522, Acc: 0.875\n",
            "Batch 831/1041, Loss: 0.37434515357017517, Acc: 0.84375\n",
            "Batch 832/1041, Loss: 0.30019474029541016, Acc: 0.90625\n",
            "Batch 833/1041, Loss: 0.5339756608009338, Acc: 0.78125\n",
            "Batch 834/1041, Loss: 0.3928235173225403, Acc: 0.84375\n",
            "Batch 835/1041, Loss: 0.6577996015548706, Acc: 0.65625\n",
            "Batch 836/1041, Loss: 0.3868404030799866, Acc: 0.75\n",
            "Batch 837/1041, Loss: 0.32316482067108154, Acc: 0.875\n",
            "Batch 838/1041, Loss: 0.3400900065898895, Acc: 0.8125\n",
            "Batch 839/1041, Loss: 0.2067151963710785, Acc: 0.9375\n",
            "Batch 840/1041, Loss: 0.33199837803840637, Acc: 0.875\n",
            "Batch 841/1041, Loss: 0.42696696519851685, Acc: 0.78125\n",
            "Batch 842/1041, Loss: 0.5690062046051025, Acc: 0.6875\n",
            "Batch 843/1041, Loss: 0.3352128267288208, Acc: 0.84375\n",
            "Batch 844/1041, Loss: 0.2595456540584564, Acc: 0.9375\n",
            "Batch 845/1041, Loss: 0.4480167627334595, Acc: 0.84375\n",
            "Batch 846/1041, Loss: 0.3006564676761627, Acc: 0.875\n",
            "Batch 847/1041, Loss: 0.4242841899394989, Acc: 0.78125\n",
            "Batch 848/1041, Loss: 0.34505507349967957, Acc: 0.84375\n",
            "Batch 849/1041, Loss: 0.22457821667194366, Acc: 0.9375\n",
            "Batch 850/1041, Loss: 0.25236350297927856, Acc: 0.90625\n",
            "Batch 851/1041, Loss: 0.3525966703891754, Acc: 0.84375\n",
            "Batch 852/1041, Loss: 0.2966417968273163, Acc: 0.90625\n",
            "Batch 853/1041, Loss: 0.34486475586891174, Acc: 0.84375\n",
            "Batch 854/1041, Loss: 0.42041999101638794, Acc: 0.8125\n",
            "Batch 855/1041, Loss: 0.34088224172592163, Acc: 0.90625\n",
            "Batch 856/1041, Loss: 0.5447943806648254, Acc: 0.71875\n",
            "Batch 857/1041, Loss: 0.4977605938911438, Acc: 0.6875\n",
            "Batch 858/1041, Loss: 0.497274249792099, Acc: 0.8125\n",
            "Batch 859/1041, Loss: 0.2908874750137329, Acc: 0.9375\n",
            "Batch 860/1041, Loss: 0.5916930437088013, Acc: 0.8125\n",
            "Batch 861/1041, Loss: 0.3262823522090912, Acc: 0.875\n",
            "Batch 862/1041, Loss: 0.4396669268608093, Acc: 0.78125\n",
            "Batch 863/1041, Loss: 0.40230491757392883, Acc: 0.8125\n",
            "Batch 864/1041, Loss: 0.3593601882457733, Acc: 0.8125\n",
            "Batch 865/1041, Loss: 0.4506209194660187, Acc: 0.84375\n",
            "Batch 866/1041, Loss: 0.32584843039512634, Acc: 0.875\n",
            "Batch 867/1041, Loss: 0.21973839402198792, Acc: 0.9375\n",
            "Batch 868/1041, Loss: 0.5828564167022705, Acc: 0.75\n",
            "Batch 869/1041, Loss: 0.39757660031318665, Acc: 0.84375\n",
            "Batch 870/1041, Loss: 0.24424538016319275, Acc: 0.90625\n",
            "Batch 871/1041, Loss: 0.4371702969074249, Acc: 0.84375\n",
            "Batch 872/1041, Loss: 0.4338423013687134, Acc: 0.78125\n",
            "Batch 873/1041, Loss: 0.4973621368408203, Acc: 0.78125\n",
            "Batch 874/1041, Loss: 0.38209787011146545, Acc: 0.875\n",
            "Batch 875/1041, Loss: 0.5518642067909241, Acc: 0.8125\n",
            "Batch 876/1041, Loss: 0.3533971309661865, Acc: 0.875\n",
            "Batch 877/1041, Loss: 0.35444632172584534, Acc: 0.84375\n",
            "Batch 878/1041, Loss: 0.35227373242378235, Acc: 0.8125\n",
            "Batch 879/1041, Loss: 0.3608066141605377, Acc: 0.78125\n",
            "Batch 880/1041, Loss: 0.37055298686027527, Acc: 0.84375\n",
            "Batch 881/1041, Loss: 0.33699363470077515, Acc: 0.84375\n",
            "Batch 882/1041, Loss: 0.3797849416732788, Acc: 0.84375\n",
            "Batch 883/1041, Loss: 0.4816422760486603, Acc: 0.8125\n",
            "Batch 884/1041, Loss: 0.30226853489875793, Acc: 0.875\n",
            "Batch 885/1041, Loss: 0.3684854209423065, Acc: 0.875\n",
            "Batch 886/1041, Loss: 0.23549525439739227, Acc: 0.90625\n",
            "Batch 887/1041, Loss: 0.2684376537799835, Acc: 0.9375\n",
            "Batch 888/1041, Loss: 0.3888135254383087, Acc: 0.84375\n",
            "Batch 889/1041, Loss: 0.36499544978141785, Acc: 0.84375\n",
            "Batch 890/1041, Loss: 0.40022552013397217, Acc: 0.8125\n",
            "Batch 891/1041, Loss: 0.6418886184692383, Acc: 0.625\n",
            "Batch 892/1041, Loss: 0.4106387495994568, Acc: 0.8125\n",
            "Batch 893/1041, Loss: 0.5328333377838135, Acc: 0.84375\n",
            "Batch 894/1041, Loss: 0.27953457832336426, Acc: 0.84375\n",
            "Batch 895/1041, Loss: 0.4758870601654053, Acc: 0.78125\n",
            "Batch 896/1041, Loss: 0.454558402299881, Acc: 0.8125\n",
            "Batch 897/1041, Loss: 0.5147526264190674, Acc: 0.84375\n",
            "Batch 898/1041, Loss: 0.2791592478752136, Acc: 0.84375\n",
            "Batch 899/1041, Loss: 0.29845181107521057, Acc: 0.9375\n",
            "Batch 900/1041, Loss: 0.39007359743118286, Acc: 0.84375\n",
            "[Update 900] Train Loss: 0.3901, Train Acc: 0.8438 | Val Loss: 0.3508, Val Acc: 0.8493\n",
            "Batch 901/1041, Loss: 0.3481898903846741, Acc: 0.8125\n",
            "Batch 902/1041, Loss: 0.36916545033454895, Acc: 0.8125\n",
            "Batch 903/1041, Loss: 0.37670451402664185, Acc: 0.875\n",
            "Batch 904/1041, Loss: 0.39942190051078796, Acc: 0.8125\n",
            "Batch 905/1041, Loss: 0.33879417181015015, Acc: 0.84375\n",
            "Batch 906/1041, Loss: 0.3036114275455475, Acc: 0.875\n",
            "Batch 907/1041, Loss: 0.36297938227653503, Acc: 0.8125\n",
            "Batch 908/1041, Loss: 0.34326204657554626, Acc: 0.90625\n",
            "Batch 909/1041, Loss: 0.4165172576904297, Acc: 0.84375\n",
            "Batch 910/1041, Loss: 0.33218491077423096, Acc: 0.875\n",
            "Batch 911/1041, Loss: 0.4640398919582367, Acc: 0.78125\n",
            "Batch 912/1041, Loss: 0.31324347853660583, Acc: 0.84375\n",
            "Batch 913/1041, Loss: 0.46932679414749146, Acc: 0.8125\n",
            "Batch 914/1041, Loss: 0.1983044445514679, Acc: 0.9375\n",
            "Batch 915/1041, Loss: 0.646340548992157, Acc: 0.65625\n",
            "Batch 916/1041, Loss: 0.4166952967643738, Acc: 0.84375\n",
            "Batch 917/1041, Loss: 0.367747962474823, Acc: 0.8125\n",
            "Batch 918/1041, Loss: 0.264484703540802, Acc: 0.90625\n",
            "Batch 919/1041, Loss: 0.5453504323959351, Acc: 0.78125\n",
            "Batch 920/1041, Loss: 0.45990386605262756, Acc: 0.84375\n",
            "Batch 921/1041, Loss: 0.3999481499195099, Acc: 0.84375\n",
            "Batch 922/1041, Loss: 0.4902549684047699, Acc: 0.78125\n",
            "Batch 923/1041, Loss: 0.404350608587265, Acc: 0.78125\n",
            "Batch 924/1041, Loss: 0.2663560211658478, Acc: 0.84375\n",
            "Batch 925/1041, Loss: 0.6300749778747559, Acc: 0.75\n",
            "Batch 926/1041, Loss: 0.355243444442749, Acc: 0.875\n",
            "Batch 927/1041, Loss: 0.21704258024692535, Acc: 0.9375\n",
            "Batch 928/1041, Loss: 0.3430974781513214, Acc: 0.90625\n",
            "Batch 929/1041, Loss: 0.29737210273742676, Acc: 0.90625\n",
            "Batch 930/1041, Loss: 0.3723081946372986, Acc: 0.78125\n",
            "Batch 931/1041, Loss: 0.392177015542984, Acc: 0.75\n",
            "Batch 932/1041, Loss: 0.49563899636268616, Acc: 0.78125\n",
            "Batch 933/1041, Loss: 0.38766175508499146, Acc: 0.78125\n",
            "Batch 934/1041, Loss: 0.489330530166626, Acc: 0.75\n",
            "Batch 935/1041, Loss: 0.3774251639842987, Acc: 0.875\n",
            "Batch 936/1041, Loss: 0.5231863260269165, Acc: 0.71875\n",
            "Batch 937/1041, Loss: 0.2770129144191742, Acc: 0.84375\n",
            "Batch 938/1041, Loss: 0.3355969190597534, Acc: 0.90625\n",
            "Batch 939/1041, Loss: 0.4051244556903839, Acc: 0.84375\n",
            "Batch 940/1041, Loss: 0.23882891237735748, Acc: 1.0\n",
            "Batch 941/1041, Loss: 0.26173779368400574, Acc: 0.875\n",
            "Batch 942/1041, Loss: 0.4921000599861145, Acc: 0.78125\n",
            "Batch 943/1041, Loss: 0.36785027384757996, Acc: 0.8125\n",
            "Batch 944/1041, Loss: 0.4574934244155884, Acc: 0.8125\n",
            "Batch 945/1041, Loss: 0.42282232642173767, Acc: 0.8125\n",
            "Batch 946/1041, Loss: 0.2996043562889099, Acc: 0.875\n",
            "Batch 947/1041, Loss: 0.24711182713508606, Acc: 0.9375\n",
            "Batch 948/1041, Loss: 0.3503795266151428, Acc: 0.875\n",
            "Batch 949/1041, Loss: 0.3852948844432831, Acc: 0.78125\n",
            "Batch 950/1041, Loss: 0.4292256236076355, Acc: 0.8125\n",
            "Batch 951/1041, Loss: 0.34801608324050903, Acc: 0.84375\n",
            "Batch 952/1041, Loss: 0.3367980122566223, Acc: 0.84375\n",
            "Batch 953/1041, Loss: 0.4469272792339325, Acc: 0.8125\n",
            "Batch 954/1041, Loss: 0.3198164105415344, Acc: 0.84375\n",
            "Batch 955/1041, Loss: 0.2660706639289856, Acc: 0.90625\n",
            "Batch 956/1041, Loss: 0.4916951656341553, Acc: 0.75\n",
            "Batch 957/1041, Loss: 0.4581301510334015, Acc: 0.78125\n",
            "Batch 958/1041, Loss: 0.4203478693962097, Acc: 0.8125\n",
            "Batch 959/1041, Loss: 0.303888738155365, Acc: 0.875\n",
            "Batch 960/1041, Loss: 0.4599268138408661, Acc: 0.8125\n",
            "Batch 961/1041, Loss: 0.4940575361251831, Acc: 0.75\n",
            "Batch 962/1041, Loss: 0.3421752452850342, Acc: 0.84375\n",
            "Batch 963/1041, Loss: 0.421417236328125, Acc: 0.875\n",
            "Batch 964/1041, Loss: 0.3165895938873291, Acc: 0.875\n",
            "Batch 965/1041, Loss: 0.3217121958732605, Acc: 0.84375\n",
            "Batch 966/1041, Loss: 0.28024980425834656, Acc: 0.875\n",
            "Batch 967/1041, Loss: 0.35003331303596497, Acc: 0.8125\n",
            "Batch 968/1041, Loss: 0.39426055550575256, Acc: 0.84375\n",
            "Batch 969/1041, Loss: 0.5739588141441345, Acc: 0.71875\n",
            "Batch 970/1041, Loss: 0.34942498803138733, Acc: 0.875\n",
            "Batch 971/1041, Loss: 0.2993635833263397, Acc: 0.875\n",
            "Batch 972/1041, Loss: 0.34704357385635376, Acc: 0.875\n",
            "Batch 973/1041, Loss: 0.29291656613349915, Acc: 0.90625\n",
            "Batch 974/1041, Loss: 0.24668090045452118, Acc: 0.875\n",
            "Batch 975/1041, Loss: 0.3343190848827362, Acc: 0.84375\n",
            "Batch 976/1041, Loss: 0.31962552666664124, Acc: 0.875\n",
            "Batch 977/1041, Loss: 0.26788195967674255, Acc: 0.875\n",
            "Batch 978/1041, Loss: 0.2887484133243561, Acc: 0.9375\n",
            "Batch 979/1041, Loss: 0.373593807220459, Acc: 0.78125\n",
            "Batch 980/1041, Loss: 0.2520714998245239, Acc: 0.90625\n",
            "Batch 981/1041, Loss: 0.29675450921058655, Acc: 0.84375\n",
            "Batch 982/1041, Loss: 0.19902881979942322, Acc: 0.90625\n",
            "Batch 983/1041, Loss: 0.4591168165206909, Acc: 0.8125\n",
            "Batch 984/1041, Loss: 0.49404117465019226, Acc: 0.84375\n",
            "Batch 985/1041, Loss: 0.45556050539016724, Acc: 0.8125\n",
            "Batch 986/1041, Loss: 0.43700385093688965, Acc: 0.84375\n",
            "Batch 987/1041, Loss: 0.3667342960834503, Acc: 0.875\n",
            "Batch 988/1041, Loss: 0.46373578906059265, Acc: 0.78125\n",
            "Batch 989/1041, Loss: 0.2002669870853424, Acc: 0.90625\n",
            "Batch 990/1041, Loss: 0.38258108496665955, Acc: 0.75\n",
            "Batch 991/1041, Loss: 0.3642168641090393, Acc: 0.875\n",
            "Batch 992/1041, Loss: 0.33393362164497375, Acc: 0.84375\n",
            "Batch 993/1041, Loss: 0.42310047149658203, Acc: 0.8125\n",
            "Batch 994/1041, Loss: 0.1654461771249771, Acc: 0.96875\n",
            "Batch 995/1041, Loss: 0.3197977542877197, Acc: 0.9375\n",
            "Batch 996/1041, Loss: 0.6066479682922363, Acc: 0.75\n",
            "Batch 997/1041, Loss: 0.36828774213790894, Acc: 0.8125\n",
            "Batch 998/1041, Loss: 0.24573998153209686, Acc: 0.90625\n",
            "Batch 999/1041, Loss: 0.3748880624771118, Acc: 0.8125\n",
            "Batch 1000/1041, Loss: 0.3803517818450928, Acc: 0.71875\n",
            "[Update 1000] Train Loss: 0.3804, Train Acc: 0.7188 | Val Loss: 0.3371, Val Acc: 0.8559\n",
            "Batch 1001/1041, Loss: 0.39660510420799255, Acc: 0.875\n",
            "Batch 1002/1041, Loss: 0.24530115723609924, Acc: 0.90625\n",
            "Batch 1003/1041, Loss: 0.4358322322368622, Acc: 0.84375\n",
            "Batch 1004/1041, Loss: 0.5387004017829895, Acc: 0.78125\n",
            "Batch 1005/1041, Loss: 0.4216551184654236, Acc: 0.8125\n",
            "Batch 1006/1041, Loss: 0.6515501737594604, Acc: 0.75\n",
            "Batch 1007/1041, Loss: 0.3286266326904297, Acc: 0.875\n",
            "Batch 1008/1041, Loss: 0.5548772215843201, Acc: 0.75\n",
            "Batch 1009/1041, Loss: 0.5161547660827637, Acc: 0.78125\n",
            "Batch 1010/1041, Loss: 0.3643967807292938, Acc: 0.875\n",
            "Batch 1011/1041, Loss: 0.37861883640289307, Acc: 0.84375\n",
            "Batch 1012/1041, Loss: 0.3804030418395996, Acc: 0.8125\n",
            "Batch 1013/1041, Loss: 0.45467638969421387, Acc: 0.8125\n",
            "Batch 1014/1041, Loss: 0.3639205992221832, Acc: 0.84375\n",
            "Batch 1015/1041, Loss: 0.8947550654411316, Acc: 0.5\n",
            "Batch 1016/1041, Loss: 0.3864579200744629, Acc: 0.875\n",
            "Batch 1017/1041, Loss: 0.37318673729896545, Acc: 0.84375\n",
            "Batch 1018/1041, Loss: 0.47205162048339844, Acc: 0.75\n",
            "Batch 1019/1041, Loss: 0.5845659971237183, Acc: 0.75\n",
            "Batch 1020/1041, Loss: 0.2736883759498596, Acc: 0.96875\n",
            "Batch 1021/1041, Loss: 0.3589400351047516, Acc: 0.875\n",
            "Batch 1022/1041, Loss: 0.44421038031578064, Acc: 0.8125\n",
            "Batch 1023/1041, Loss: 0.39679908752441406, Acc: 0.84375\n",
            "Batch 1024/1041, Loss: 0.4835290312767029, Acc: 0.78125\n",
            "Batch 1025/1041, Loss: 0.27777111530303955, Acc: 0.90625\n",
            "Batch 1026/1041, Loss: 0.3162175416946411, Acc: 0.875\n",
            "Batch 1027/1041, Loss: 0.4333604872226715, Acc: 0.8125\n",
            "Batch 1028/1041, Loss: 0.5111688375473022, Acc: 0.71875\n",
            "Batch 1029/1041, Loss: 0.32828259468078613, Acc: 0.84375\n",
            "Batch 1030/1041, Loss: 0.31055134534835815, Acc: 0.84375\n",
            "Batch 1031/1041, Loss: 0.46435630321502686, Acc: 0.875\n",
            "Batch 1032/1041, Loss: 0.3822307586669922, Acc: 0.84375\n",
            "Batch 1033/1041, Loss: 0.3264296054840088, Acc: 0.90625\n",
            "Batch 1034/1041, Loss: 0.4218597412109375, Acc: 0.8125\n",
            "Batch 1035/1041, Loss: 0.4257378876209259, Acc: 0.75\n",
            "Batch 1036/1041, Loss: 0.4044268727302551, Acc: 0.8125\n",
            "Batch 1037/1041, Loss: 0.24161717295646667, Acc: 0.90625\n",
            "Batch 1038/1041, Loss: 0.27860674262046814, Acc: 0.875\n",
            "Batch 1039/1041, Loss: 0.2860672175884247, Acc: 0.875\n",
            "Batch 1040/1041, Loss: 0.3780773878097534, Acc: 0.78125\n",
            "Batch 1041/1041, Loss: 0.33485719561576843, Acc: 0.8260869565217391\n",
            "Epoch 2/3\n",
            "----------\n",
            "Batch 1/1041, Loss: 0.4577001631259918, Acc: 0.78125\n",
            "Batch 2/1041, Loss: 0.34636086225509644, Acc: 0.875\n",
            "Batch 3/1041, Loss: 0.3263474404811859, Acc: 0.84375\n",
            "Batch 4/1041, Loss: 0.26890501379966736, Acc: 0.9375\n",
            "Batch 5/1041, Loss: 0.48714596033096313, Acc: 0.8125\n",
            "Batch 6/1041, Loss: 0.353633850812912, Acc: 0.875\n",
            "Batch 7/1041, Loss: 0.29339271783828735, Acc: 0.90625\n",
            "Batch 8/1041, Loss: 0.36554908752441406, Acc: 0.875\n",
            "Batch 9/1041, Loss: 0.3829953670501709, Acc: 0.75\n",
            "Batch 10/1041, Loss: 0.21593208611011505, Acc: 0.96875\n",
            "Batch 11/1041, Loss: 0.31908470392227173, Acc: 0.84375\n",
            "Batch 12/1041, Loss: 0.4148816466331482, Acc: 0.875\n",
            "Batch 13/1041, Loss: 0.26607972383499146, Acc: 0.9375\n",
            "Batch 14/1041, Loss: 0.3576630651950836, Acc: 0.84375\n",
            "Batch 15/1041, Loss: 0.2596970200538635, Acc: 0.875\n",
            "Batch 16/1041, Loss: 0.3060665726661682, Acc: 0.875\n",
            "Batch 17/1041, Loss: 0.46086928248405457, Acc: 0.75\n",
            "Batch 18/1041, Loss: 0.34940850734710693, Acc: 0.84375\n",
            "Batch 19/1041, Loss: 0.6898385882377625, Acc: 0.71875\n",
            "Batch 20/1041, Loss: 0.42277035117149353, Acc: 0.78125\n",
            "Batch 21/1041, Loss: 0.4139866530895233, Acc: 0.8125\n",
            "Batch 22/1041, Loss: 0.2375793159008026, Acc: 0.9375\n",
            "Batch 23/1041, Loss: 0.3063772916793823, Acc: 0.84375\n",
            "Batch 24/1041, Loss: 0.2874118983745575, Acc: 0.875\n",
            "Batch 25/1041, Loss: 0.5763143301010132, Acc: 0.6875\n",
            "Batch 26/1041, Loss: 0.252817839384079, Acc: 0.90625\n",
            "Batch 27/1041, Loss: 0.29377323389053345, Acc: 0.84375\n",
            "Batch 28/1041, Loss: 0.31180092692375183, Acc: 0.875\n",
            "Batch 29/1041, Loss: 0.305011123418808, Acc: 0.90625\n",
            "Batch 30/1041, Loss: 0.34704843163490295, Acc: 0.8125\n",
            "Batch 31/1041, Loss: 0.19360972940921783, Acc: 0.9375\n",
            "Batch 32/1041, Loss: 0.2664162814617157, Acc: 0.875\n",
            "Batch 33/1041, Loss: 0.32301539182662964, Acc: 0.84375\n",
            "Batch 34/1041, Loss: 0.4060514271259308, Acc: 0.8125\n",
            "Batch 35/1041, Loss: 0.34509971737861633, Acc: 0.90625\n",
            "Batch 36/1041, Loss: 0.40383219718933105, Acc: 0.84375\n",
            "Batch 37/1041, Loss: 0.3744214177131653, Acc: 0.84375\n",
            "Batch 38/1041, Loss: 0.49000871181488037, Acc: 0.75\n",
            "Batch 39/1041, Loss: 0.3034810423851013, Acc: 0.84375\n",
            "Batch 40/1041, Loss: 0.22710232436656952, Acc: 0.9375\n",
            "Batch 41/1041, Loss: 0.48332056403160095, Acc: 0.78125\n",
            "Batch 42/1041, Loss: 0.35941141843795776, Acc: 0.875\n",
            "Batch 43/1041, Loss: 0.6106589436531067, Acc: 0.65625\n",
            "Batch 44/1041, Loss: 0.4432904124259949, Acc: 0.84375\n",
            "Batch 45/1041, Loss: 0.44525521993637085, Acc: 0.78125\n",
            "Batch 46/1041, Loss: 0.29917725920677185, Acc: 0.84375\n",
            "Batch 47/1041, Loss: 0.19690510630607605, Acc: 0.96875\n",
            "Batch 48/1041, Loss: 0.28480762243270874, Acc: 0.90625\n",
            "Batch 49/1041, Loss: 0.24180924892425537, Acc: 0.90625\n",
            "Batch 50/1041, Loss: 0.2437487095594406, Acc: 0.90625\n",
            "Batch 51/1041, Loss: 0.2930223345756531, Acc: 0.875\n",
            "Batch 52/1041, Loss: 0.32973340153694153, Acc: 0.8125\n",
            "Batch 53/1041, Loss: 0.3388521373271942, Acc: 0.78125\n",
            "Batch 54/1041, Loss: 0.514161229133606, Acc: 0.8125\n",
            "Batch 55/1041, Loss: 0.310485303401947, Acc: 0.875\n",
            "Batch 56/1041, Loss: 0.3219926357269287, Acc: 0.8125\n",
            "Batch 57/1041, Loss: 0.28714224696159363, Acc: 0.90625\n",
            "Batch 58/1041, Loss: 0.44725582003593445, Acc: 0.8125\n",
            "Batch 59/1041, Loss: 0.27367013692855835, Acc: 0.875\n",
            "[Update 1100] Train Loss: 0.2737, Train Acc: 0.8750 | Val Loss: 0.3392, Val Acc: 0.8565\n",
            "Batch 60/1041, Loss: 0.2635461390018463, Acc: 0.90625\n",
            "Batch 61/1041, Loss: 0.5450876355171204, Acc: 0.75\n",
            "Batch 62/1041, Loss: 0.2899235486984253, Acc: 0.90625\n",
            "Batch 63/1041, Loss: 0.3187364637851715, Acc: 0.8125\n",
            "Batch 64/1041, Loss: 0.2403624951839447, Acc: 0.875\n",
            "Batch 65/1041, Loss: 0.3749901056289673, Acc: 0.875\n",
            "Batch 66/1041, Loss: 0.39680731296539307, Acc: 0.8125\n",
            "Batch 67/1041, Loss: 0.3147519826889038, Acc: 0.875\n",
            "Batch 68/1041, Loss: 0.2983455955982208, Acc: 0.84375\n",
            "Batch 69/1041, Loss: 0.33334487676620483, Acc: 0.8125\n",
            "Batch 70/1041, Loss: 0.4616110026836395, Acc: 0.8125\n",
            "Batch 71/1041, Loss: 0.27114975452423096, Acc: 0.90625\n",
            "Batch 72/1041, Loss: 0.48269179463386536, Acc: 0.8125\n",
            "Batch 73/1041, Loss: 0.28343895077705383, Acc: 0.84375\n",
            "Batch 74/1041, Loss: 0.28659406304359436, Acc: 0.9375\n",
            "Batch 75/1041, Loss: 0.36953312158584595, Acc: 0.84375\n",
            "Batch 76/1041, Loss: 0.2551489770412445, Acc: 0.875\n",
            "Batch 77/1041, Loss: 0.42617082595825195, Acc: 0.8125\n",
            "Batch 78/1041, Loss: 0.4108632206916809, Acc: 0.90625\n",
            "Batch 79/1041, Loss: 0.2930346727371216, Acc: 0.875\n",
            "Batch 80/1041, Loss: 0.4164775311946869, Acc: 0.8125\n",
            "Batch 81/1041, Loss: 0.28247499465942383, Acc: 0.84375\n",
            "Batch 82/1041, Loss: 0.31094321608543396, Acc: 0.875\n",
            "Batch 83/1041, Loss: 0.4798464775085449, Acc: 0.71875\n",
            "Batch 84/1041, Loss: 0.36551254987716675, Acc: 0.78125\n",
            "Batch 85/1041, Loss: 0.33234143257141113, Acc: 0.875\n",
            "Batch 86/1041, Loss: 0.4744003415107727, Acc: 0.8125\n",
            "Batch 87/1041, Loss: 0.2841571867465973, Acc: 0.875\n",
            "Batch 88/1041, Loss: 0.23120222985744476, Acc: 0.90625\n",
            "Batch 89/1041, Loss: 0.38558584451675415, Acc: 0.8125\n",
            "Batch 90/1041, Loss: 0.5420109629631042, Acc: 0.8125\n",
            "Batch 91/1041, Loss: 0.5435158014297485, Acc: 0.71875\n",
            "Batch 92/1041, Loss: 0.36726364493370056, Acc: 0.84375\n",
            "Batch 93/1041, Loss: 0.3291120231151581, Acc: 0.84375\n",
            "Batch 94/1041, Loss: 0.5539364814758301, Acc: 0.75\n",
            "Batch 95/1041, Loss: 0.3562966287136078, Acc: 0.875\n",
            "Batch 96/1041, Loss: 0.4626196026802063, Acc: 0.71875\n",
            "Batch 97/1041, Loss: 0.32113972306251526, Acc: 0.90625\n",
            "Batch 98/1041, Loss: 0.36370646953582764, Acc: 0.90625\n",
            "Batch 99/1041, Loss: 0.27635809779167175, Acc: 0.9375\n",
            "Batch 100/1041, Loss: 0.33332860469818115, Acc: 0.90625\n",
            "Batch 101/1041, Loss: 0.3583778738975525, Acc: 0.78125\n",
            "Batch 102/1041, Loss: 0.3779234290122986, Acc: 0.84375\n",
            "Batch 103/1041, Loss: 0.23638823628425598, Acc: 0.875\n",
            "Batch 104/1041, Loss: 0.23675411939620972, Acc: 0.96875\n",
            "Batch 105/1041, Loss: 0.19589705765247345, Acc: 0.96875\n",
            "Batch 106/1041, Loss: 0.35656091570854187, Acc: 0.84375\n",
            "Batch 107/1041, Loss: 0.2632794976234436, Acc: 0.9375\n",
            "Batch 108/1041, Loss: 0.2565554082393646, Acc: 0.9375\n",
            "Batch 109/1041, Loss: 0.3537822663784027, Acc: 0.84375\n",
            "Batch 110/1041, Loss: 0.3348132371902466, Acc: 0.78125\n",
            "Batch 111/1041, Loss: 0.3577927350997925, Acc: 0.8125\n",
            "Batch 112/1041, Loss: 0.30590617656707764, Acc: 0.84375\n",
            "Batch 113/1041, Loss: 0.34603774547576904, Acc: 0.84375\n",
            "Batch 114/1041, Loss: 0.2956329882144928, Acc: 0.9375\n",
            "Batch 115/1041, Loss: 0.23239688575267792, Acc: 0.90625\n",
            "Batch 116/1041, Loss: 0.22435925900936127, Acc: 0.90625\n",
            "Batch 117/1041, Loss: 0.29769739508628845, Acc: 0.875\n",
            "Batch 118/1041, Loss: 0.32832759618759155, Acc: 0.8125\n",
            "Batch 119/1041, Loss: 0.22671400010585785, Acc: 0.90625\n",
            "Batch 120/1041, Loss: 0.26715829968452454, Acc: 0.90625\n",
            "Batch 121/1041, Loss: 0.26165249943733215, Acc: 0.84375\n",
            "Batch 122/1041, Loss: 0.30946147441864014, Acc: 0.84375\n",
            "Batch 123/1041, Loss: 0.3071874976158142, Acc: 0.8125\n",
            "Batch 124/1041, Loss: 0.23115260899066925, Acc: 0.875\n",
            "Batch 125/1041, Loss: 0.3061298131942749, Acc: 0.84375\n",
            "Batch 126/1041, Loss: 0.3944007158279419, Acc: 0.84375\n",
            "Batch 127/1041, Loss: 0.39404428005218506, Acc: 0.90625\n",
            "Batch 128/1041, Loss: 0.24845068156719208, Acc: 0.90625\n",
            "Batch 129/1041, Loss: 0.3511560559272766, Acc: 0.875\n",
            "Batch 130/1041, Loss: 0.3589465916156769, Acc: 0.8125\n",
            "Batch 131/1041, Loss: 0.28025081753730774, Acc: 0.90625\n",
            "Batch 132/1041, Loss: 0.3155914545059204, Acc: 0.84375\n",
            "Batch 133/1041, Loss: 0.22712484002113342, Acc: 0.9375\n",
            "Batch 134/1041, Loss: 0.35267746448516846, Acc: 0.875\n",
            "Batch 135/1041, Loss: 0.25828051567077637, Acc: 0.90625\n",
            "Batch 136/1041, Loss: 0.45519760251045227, Acc: 0.75\n",
            "Batch 137/1041, Loss: 0.4920741319656372, Acc: 0.84375\n",
            "Batch 138/1041, Loss: 0.2139563113451004, Acc: 0.9375\n",
            "Batch 139/1041, Loss: 0.5481100082397461, Acc: 0.78125\n",
            "Batch 140/1041, Loss: 0.2692853808403015, Acc: 0.84375\n",
            "Batch 141/1041, Loss: 0.485504150390625, Acc: 0.8125\n",
            "Batch 142/1041, Loss: 0.4946463108062744, Acc: 0.875\n",
            "Batch 143/1041, Loss: 0.19533807039260864, Acc: 0.9375\n",
            "Batch 144/1041, Loss: 0.19901306927204132, Acc: 0.9375\n",
            "Batch 145/1041, Loss: 0.5184019207954407, Acc: 0.78125\n",
            "Batch 146/1041, Loss: 0.2889544665813446, Acc: 0.90625\n",
            "Batch 147/1041, Loss: 0.38717782497406006, Acc: 0.84375\n",
            "Batch 148/1041, Loss: 0.26611968874931335, Acc: 0.90625\n",
            "Batch 149/1041, Loss: 0.2429381012916565, Acc: 0.9375\n",
            "Batch 150/1041, Loss: 0.306050181388855, Acc: 0.875\n",
            "Batch 151/1041, Loss: 0.3177788257598877, Acc: 0.84375\n",
            "Batch 152/1041, Loss: 0.411760538816452, Acc: 0.8125\n",
            "Batch 153/1041, Loss: 0.4364115595817566, Acc: 0.90625\n",
            "Batch 154/1041, Loss: 0.27068889141082764, Acc: 0.875\n",
            "Batch 155/1041, Loss: 0.5999529957771301, Acc: 0.78125\n",
            "Batch 156/1041, Loss: 0.21536728739738464, Acc: 0.90625\n",
            "Batch 157/1041, Loss: 0.24909727275371552, Acc: 0.96875\n",
            "Batch 158/1041, Loss: 0.3656143844127655, Acc: 0.78125\n",
            "Batch 159/1041, Loss: 0.54658442735672, Acc: 0.8125\n",
            "[Update 1200] Train Loss: 0.5466, Train Acc: 0.8125 | Val Loss: 0.3319, Val Acc: 0.8621\n",
            "Batch 160/1041, Loss: 0.3245898187160492, Acc: 0.875\n",
            "Batch 161/1041, Loss: 0.2849633991718292, Acc: 0.875\n",
            "Batch 162/1041, Loss: 0.2412707805633545, Acc: 0.875\n",
            "Batch 163/1041, Loss: 0.18696290254592896, Acc: 0.9375\n",
            "Batch 164/1041, Loss: 0.4692583382129669, Acc: 0.71875\n",
            "Batch 165/1041, Loss: 0.5540885329246521, Acc: 0.75\n",
            "Batch 166/1041, Loss: 0.45233941078186035, Acc: 0.84375\n",
            "Batch 167/1041, Loss: 0.542069673538208, Acc: 0.8125\n",
            "Batch 168/1041, Loss: 0.40621262788772583, Acc: 0.78125\n",
            "Batch 169/1041, Loss: 0.49189797043800354, Acc: 0.75\n",
            "Batch 170/1041, Loss: 0.561859667301178, Acc: 0.8125\n",
            "Batch 171/1041, Loss: 0.3093092143535614, Acc: 0.84375\n",
            "Batch 172/1041, Loss: 0.24772848188877106, Acc: 0.90625\n",
            "Batch 173/1041, Loss: 0.1539144665002823, Acc: 0.96875\n",
            "Batch 174/1041, Loss: 0.38517647981643677, Acc: 0.8125\n",
            "Batch 175/1041, Loss: 0.5864800810813904, Acc: 0.71875\n",
            "Batch 176/1041, Loss: 0.38259318470954895, Acc: 0.78125\n",
            "Batch 177/1041, Loss: 0.2024577409029007, Acc: 0.9375\n",
            "Batch 178/1041, Loss: 0.5133818984031677, Acc: 0.78125\n",
            "Batch 179/1041, Loss: 0.4511452913284302, Acc: 0.75\n",
            "Batch 180/1041, Loss: 0.2771623432636261, Acc: 0.875\n",
            "Batch 181/1041, Loss: 0.2721281349658966, Acc: 0.875\n",
            "Batch 182/1041, Loss: 0.3897424638271332, Acc: 0.78125\n",
            "Batch 183/1041, Loss: 0.3332747220993042, Acc: 0.8125\n",
            "Batch 184/1041, Loss: 0.4806639552116394, Acc: 0.78125\n",
            "Batch 185/1041, Loss: 0.19192375242710114, Acc: 0.96875\n",
            "Batch 186/1041, Loss: 0.5164494514465332, Acc: 0.75\n",
            "Batch 187/1041, Loss: 0.3926522135734558, Acc: 0.84375\n",
            "Batch 188/1041, Loss: 0.45233580470085144, Acc: 0.8125\n",
            "Batch 189/1041, Loss: 0.42270851135253906, Acc: 0.8125\n",
            "Batch 190/1041, Loss: 0.24266360700130463, Acc: 0.875\n",
            "Batch 191/1041, Loss: 0.2907871901988983, Acc: 0.9375\n",
            "Batch 192/1041, Loss: 0.30224373936653137, Acc: 0.875\n",
            "Batch 193/1041, Loss: 0.28430837392807007, Acc: 0.84375\n",
            "Batch 194/1041, Loss: 0.4383678734302521, Acc: 0.75\n",
            "Batch 195/1041, Loss: 0.3178779184818268, Acc: 0.875\n",
            "Batch 196/1041, Loss: 0.2602125406265259, Acc: 0.84375\n",
            "Batch 197/1041, Loss: 0.2612529695034027, Acc: 0.90625\n",
            "Batch 198/1041, Loss: 0.2380146086215973, Acc: 0.875\n",
            "Batch 199/1041, Loss: 0.3474072515964508, Acc: 0.8125\n",
            "Batch 200/1041, Loss: 0.3451829254627228, Acc: 0.84375\n",
            "Batch 201/1041, Loss: 0.3095301389694214, Acc: 0.84375\n",
            "Batch 202/1041, Loss: 0.1943248063325882, Acc: 0.875\n",
            "Batch 203/1041, Loss: 0.1463584452867508, Acc: 0.96875\n",
            "Batch 204/1041, Loss: 0.2689662277698517, Acc: 0.875\n",
            "Batch 205/1041, Loss: 0.21567969024181366, Acc: 0.875\n",
            "Batch 206/1041, Loss: 0.28815436363220215, Acc: 0.84375\n",
            "Batch 207/1041, Loss: 0.4493996798992157, Acc: 0.75\n",
            "Batch 208/1041, Loss: 0.3145139515399933, Acc: 0.84375\n",
            "Batch 209/1041, Loss: 0.3609011769294739, Acc: 0.84375\n",
            "Batch 210/1041, Loss: 0.18314990401268005, Acc: 0.9375\n",
            "Batch 211/1041, Loss: 0.36491450667381287, Acc: 0.84375\n",
            "Batch 212/1041, Loss: 0.3391559422016144, Acc: 0.875\n",
            "Batch 213/1041, Loss: 0.41077321767807007, Acc: 0.8125\n",
            "Batch 214/1041, Loss: 0.35500529408454895, Acc: 0.84375\n",
            "Batch 215/1041, Loss: 0.27968403697013855, Acc: 0.875\n",
            "Batch 216/1041, Loss: 0.4187701344490051, Acc: 0.71875\n",
            "Batch 217/1041, Loss: 0.5629076957702637, Acc: 0.75\n",
            "Batch 218/1041, Loss: 0.3593021333217621, Acc: 0.84375\n",
            "Batch 219/1041, Loss: 0.20801351964473724, Acc: 0.9375\n",
            "Batch 220/1041, Loss: 0.32818326354026794, Acc: 0.90625\n",
            "Batch 221/1041, Loss: 0.19164760410785675, Acc: 0.9375\n",
            "Batch 222/1041, Loss: 0.3452572226524353, Acc: 0.875\n",
            "Batch 223/1041, Loss: 0.2992023527622223, Acc: 0.875\n",
            "Batch 224/1041, Loss: 0.40719008445739746, Acc: 0.84375\n",
            "Batch 225/1041, Loss: 0.279168039560318, Acc: 0.84375\n",
            "Batch 226/1041, Loss: 0.4706389605998993, Acc: 0.78125\n",
            "Batch 227/1041, Loss: 0.44152069091796875, Acc: 0.75\n",
            "Batch 228/1041, Loss: 0.29481998085975647, Acc: 0.875\n",
            "Batch 229/1041, Loss: 0.2685472369194031, Acc: 0.9375\n",
            "Batch 230/1041, Loss: 0.20222939550876617, Acc: 0.96875\n",
            "Batch 231/1041, Loss: 0.3620471954345703, Acc: 0.84375\n",
            "Batch 232/1041, Loss: 0.1270889937877655, Acc: 0.96875\n",
            "Batch 233/1041, Loss: 0.36592063307762146, Acc: 0.84375\n",
            "Batch 234/1041, Loss: 0.3854318857192993, Acc: 0.78125\n",
            "Batch 235/1041, Loss: 0.3856876492500305, Acc: 0.75\n",
            "Batch 236/1041, Loss: 0.29608675837516785, Acc: 0.875\n",
            "Batch 237/1041, Loss: 0.2461552917957306, Acc: 0.9375\n",
            "Batch 238/1041, Loss: 0.22932565212249756, Acc: 0.9375\n",
            "Batch 239/1041, Loss: 0.20454677939414978, Acc: 0.9375\n",
            "Batch 240/1041, Loss: 0.5104554891586304, Acc: 0.71875\n",
            "Batch 241/1041, Loss: 0.5208752751350403, Acc: 0.78125\n",
            "Batch 242/1041, Loss: 0.3234364688396454, Acc: 0.875\n",
            "Batch 243/1041, Loss: 0.30236107110977173, Acc: 0.84375\n",
            "Batch 244/1041, Loss: 0.30138692259788513, Acc: 0.90625\n",
            "Batch 245/1041, Loss: 0.2295088917016983, Acc: 0.875\n",
            "Batch 246/1041, Loss: 0.4141148626804352, Acc: 0.78125\n",
            "Batch 247/1041, Loss: 0.21703489124774933, Acc: 0.875\n",
            "Batch 248/1041, Loss: 0.4413703382015228, Acc: 0.75\n",
            "Batch 249/1041, Loss: 0.6078301072120667, Acc: 0.75\n",
            "Batch 250/1041, Loss: 0.3474598824977875, Acc: 0.84375\n",
            "Batch 251/1041, Loss: 0.21770188212394714, Acc: 0.9375\n",
            "Batch 252/1041, Loss: 0.32217955589294434, Acc: 0.8125\n",
            "Batch 253/1041, Loss: 0.49057820439338684, Acc: 0.78125\n",
            "Batch 254/1041, Loss: 0.24788668751716614, Acc: 0.875\n",
            "Batch 255/1041, Loss: 0.2537623643875122, Acc: 0.9375\n",
            "Batch 256/1041, Loss: 0.3922061622142792, Acc: 0.8125\n",
            "Batch 257/1041, Loss: 0.3726341724395752, Acc: 0.84375\n",
            "Batch 258/1041, Loss: 0.39133864641189575, Acc: 0.78125\n",
            "Batch 259/1041, Loss: 0.2950435280799866, Acc: 0.84375\n",
            "[Update 1300] Train Loss: 0.2950, Train Acc: 0.8438 | Val Loss: 0.3340, Val Acc: 0.8631\n",
            "Batch 260/1041, Loss: 0.5858411192893982, Acc: 0.75\n",
            "Batch 261/1041, Loss: 0.25164109468460083, Acc: 0.90625\n",
            "Batch 262/1041, Loss: 0.3225913941860199, Acc: 0.875\n",
            "Batch 263/1041, Loss: 0.37999626994132996, Acc: 0.84375\n",
            "Batch 264/1041, Loss: 0.29237547516822815, Acc: 0.90625\n",
            "Batch 265/1041, Loss: 0.21302759647369385, Acc: 0.90625\n",
            "Batch 266/1041, Loss: 0.25429657101631165, Acc: 0.84375\n",
            "Batch 267/1041, Loss: 0.2795751690864563, Acc: 0.875\n",
            "Batch 268/1041, Loss: 0.5360042452812195, Acc: 0.71875\n",
            "Batch 269/1041, Loss: 0.3333157002925873, Acc: 0.84375\n",
            "Batch 270/1041, Loss: 0.26438108086586, Acc: 0.875\n",
            "Batch 271/1041, Loss: 0.2641296982765198, Acc: 0.84375\n",
            "Batch 272/1041, Loss: 0.3674420714378357, Acc: 0.8125\n",
            "Batch 273/1041, Loss: 0.24237217009067535, Acc: 0.875\n",
            "Batch 274/1041, Loss: 0.2019176483154297, Acc: 0.96875\n",
            "Batch 275/1041, Loss: 0.45540761947631836, Acc: 0.78125\n",
            "Batch 276/1041, Loss: 0.37247928977012634, Acc: 0.90625\n",
            "Batch 277/1041, Loss: 0.42070093750953674, Acc: 0.8125\n",
            "Batch 278/1041, Loss: 0.44625410437583923, Acc: 0.75\n",
            "Batch 279/1041, Loss: 0.22536598145961761, Acc: 0.90625\n",
            "Batch 280/1041, Loss: 0.38405218720436096, Acc: 0.875\n",
            "Batch 281/1041, Loss: 0.4090237021446228, Acc: 0.8125\n",
            "Batch 282/1041, Loss: 0.3186199367046356, Acc: 0.90625\n",
            "Batch 283/1041, Loss: 0.3471066355705261, Acc: 0.875\n",
            "Batch 284/1041, Loss: 0.16347141563892365, Acc: 0.96875\n",
            "Batch 285/1041, Loss: 0.21366959810256958, Acc: 0.9375\n",
            "Batch 286/1041, Loss: 0.20852556824684143, Acc: 0.96875\n",
            "Batch 287/1041, Loss: 0.2854522466659546, Acc: 0.90625\n",
            "Batch 288/1041, Loss: 0.3036978542804718, Acc: 0.875\n",
            "Batch 289/1041, Loss: 0.17329996824264526, Acc: 0.9375\n",
            "Batch 290/1041, Loss: 0.30281782150268555, Acc: 0.875\n",
            "Batch 291/1041, Loss: 0.27114343643188477, Acc: 0.875\n",
            "Batch 292/1041, Loss: 0.40470731258392334, Acc: 0.8125\n",
            "Batch 293/1041, Loss: 0.3280541002750397, Acc: 0.84375\n",
            "Batch 294/1041, Loss: 0.4476928412914276, Acc: 0.8125\n",
            "Batch 295/1041, Loss: 0.318876713514328, Acc: 0.90625\n",
            "Batch 296/1041, Loss: 0.33740007877349854, Acc: 0.84375\n",
            "Batch 297/1041, Loss: 0.31121668219566345, Acc: 0.84375\n",
            "Batch 298/1041, Loss: 0.30099958181381226, Acc: 0.8125\n",
            "Batch 299/1041, Loss: 0.2127836048603058, Acc: 0.90625\n",
            "Batch 300/1041, Loss: 0.5929268598556519, Acc: 0.6875\n",
            "Batch 301/1041, Loss: 0.19673490524291992, Acc: 0.90625\n",
            "Batch 302/1041, Loss: 0.37037643790245056, Acc: 0.90625\n",
            "Batch 303/1041, Loss: 0.2830727696418762, Acc: 0.90625\n",
            "Batch 304/1041, Loss: 0.30597350001335144, Acc: 0.875\n",
            "Batch 305/1041, Loss: 0.4898498058319092, Acc: 0.78125\n",
            "Batch 306/1041, Loss: 0.36320140957832336, Acc: 0.78125\n",
            "Batch 307/1041, Loss: 0.20063617825508118, Acc: 0.96875\n",
            "Batch 308/1041, Loss: 0.1334908902645111, Acc: 0.96875\n",
            "Batch 309/1041, Loss: 0.36227181553840637, Acc: 0.84375\n",
            "Batch 310/1041, Loss: 0.3239545226097107, Acc: 0.84375\n",
            "Batch 311/1041, Loss: 0.2980342209339142, Acc: 0.875\n",
            "Batch 312/1041, Loss: 0.3284493386745453, Acc: 0.875\n",
            "Batch 313/1041, Loss: 0.325835645198822, Acc: 0.90625\n",
            "Batch 314/1041, Loss: 0.5253371596336365, Acc: 0.8125\n",
            "Batch 315/1041, Loss: 0.3407987654209137, Acc: 0.84375\n",
            "Batch 316/1041, Loss: 0.6234657764434814, Acc: 0.71875\n",
            "Batch 317/1041, Loss: 0.42441487312316895, Acc: 0.8125\n",
            "Batch 318/1041, Loss: 0.3226759731769562, Acc: 0.875\n",
            "Batch 319/1041, Loss: 0.2510156035423279, Acc: 0.9375\n",
            "Batch 320/1041, Loss: 0.423869252204895, Acc: 0.78125\n",
            "Batch 321/1041, Loss: 0.31017786264419556, Acc: 0.8125\n",
            "Batch 322/1041, Loss: 0.2542623281478882, Acc: 0.84375\n",
            "Batch 323/1041, Loss: 0.2909240424633026, Acc: 0.84375\n",
            "Batch 324/1041, Loss: 0.32426977157592773, Acc: 0.90625\n",
            "Batch 325/1041, Loss: 0.3066844940185547, Acc: 0.9375\n",
            "Batch 326/1041, Loss: 0.3546082079410553, Acc: 0.84375\n",
            "Batch 327/1041, Loss: 0.44873446226119995, Acc: 0.8125\n",
            "Batch 328/1041, Loss: 0.3917321562767029, Acc: 0.84375\n",
            "Batch 329/1041, Loss: 0.35842499136924744, Acc: 0.8125\n",
            "Batch 330/1041, Loss: 0.3246248662471771, Acc: 0.8125\n",
            "Batch 331/1041, Loss: 0.2382505089044571, Acc: 0.875\n",
            "Batch 332/1041, Loss: 0.2971833050251007, Acc: 0.90625\n",
            "Batch 333/1041, Loss: 0.23190191388130188, Acc: 0.9375\n",
            "Batch 334/1041, Loss: 0.3082897663116455, Acc: 0.84375\n",
            "Batch 335/1041, Loss: 0.585166335105896, Acc: 0.8125\n",
            "Batch 336/1041, Loss: 0.47182497382164, Acc: 0.84375\n",
            "Batch 337/1041, Loss: 0.2146826833486557, Acc: 0.90625\n",
            "Batch 338/1041, Loss: 0.28417307138442993, Acc: 0.875\n",
            "Batch 339/1041, Loss: 0.22225826978683472, Acc: 0.9375\n",
            "Batch 340/1041, Loss: 0.21253013610839844, Acc: 0.875\n",
            "Batch 341/1041, Loss: 0.29566800594329834, Acc: 0.90625\n",
            "Batch 342/1041, Loss: 0.3325812518596649, Acc: 0.84375\n",
            "Batch 343/1041, Loss: 0.5172138810157776, Acc: 0.8125\n",
            "Batch 344/1041, Loss: 0.22514404356479645, Acc: 0.9375\n",
            "Batch 345/1041, Loss: 0.2492755800485611, Acc: 0.84375\n",
            "Batch 346/1041, Loss: 0.376383900642395, Acc: 0.875\n",
            "Batch 347/1041, Loss: 0.45653095841407776, Acc: 0.71875\n",
            "Batch 348/1041, Loss: 0.36337122321128845, Acc: 0.8125\n",
            "Batch 349/1041, Loss: 0.2988215684890747, Acc: 0.8125\n",
            "Batch 350/1041, Loss: 0.34639987349510193, Acc: 0.84375\n",
            "Batch 351/1041, Loss: 0.4241657853126526, Acc: 0.8125\n",
            "Batch 352/1041, Loss: 0.26051265001296997, Acc: 0.90625\n",
            "Batch 353/1041, Loss: 0.2449398934841156, Acc: 0.90625\n",
            "Batch 354/1041, Loss: 0.20865139365196228, Acc: 0.90625\n",
            "Batch 355/1041, Loss: 0.40523090958595276, Acc: 0.71875\n",
            "Batch 356/1041, Loss: 0.28652453422546387, Acc: 0.875\n",
            "Batch 357/1041, Loss: 0.39975857734680176, Acc: 0.84375\n",
            "Batch 358/1041, Loss: 0.5004251599311829, Acc: 0.75\n",
            "Batch 359/1041, Loss: 0.6029646992683411, Acc: 0.71875\n",
            "[Update 1400] Train Loss: 0.6030, Train Acc: 0.7188 | Val Loss: 0.3345, Val Acc: 0.8551\n",
            "Batch 360/1041, Loss: 0.1965431272983551, Acc: 0.96875\n",
            "Batch 361/1041, Loss: 0.3947872221469879, Acc: 0.8125\n",
            "Batch 362/1041, Loss: 0.26920220255851746, Acc: 0.875\n",
            "Batch 363/1041, Loss: 0.29785358905792236, Acc: 0.90625\n",
            "Batch 364/1041, Loss: 0.359274297952652, Acc: 0.8125\n",
            "Batch 365/1041, Loss: 0.18464788794517517, Acc: 0.90625\n",
            "Batch 366/1041, Loss: 0.4380285441875458, Acc: 0.875\n",
            "Batch 367/1041, Loss: 0.436520516872406, Acc: 0.8125\n",
            "Batch 368/1041, Loss: 0.39262962341308594, Acc: 0.875\n",
            "Batch 369/1041, Loss: 0.2843122184276581, Acc: 0.875\n",
            "Batch 370/1041, Loss: 0.506364643573761, Acc: 0.78125\n",
            "Batch 371/1041, Loss: 0.4524267315864563, Acc: 0.84375\n",
            "Batch 372/1041, Loss: 0.22402915358543396, Acc: 0.90625\n",
            "Batch 373/1041, Loss: 0.43687283992767334, Acc: 0.84375\n",
            "Batch 374/1041, Loss: 0.3276095390319824, Acc: 0.875\n",
            "Batch 375/1041, Loss: 0.27381443977355957, Acc: 0.90625\n",
            "Batch 376/1041, Loss: 0.28156763315200806, Acc: 0.9375\n",
            "Batch 377/1041, Loss: 0.3043719530105591, Acc: 0.90625\n",
            "Batch 378/1041, Loss: 0.3104102909564972, Acc: 0.875\n",
            "Batch 379/1041, Loss: 0.30589526891708374, Acc: 0.84375\n",
            "Batch 380/1041, Loss: 0.39669105410575867, Acc: 0.8125\n",
            "Batch 381/1041, Loss: 0.2804493308067322, Acc: 0.84375\n",
            "Batch 382/1041, Loss: 0.33063042163848877, Acc: 0.875\n",
            "Batch 383/1041, Loss: 0.5718380808830261, Acc: 0.78125\n",
            "Batch 384/1041, Loss: 0.36714980006217957, Acc: 0.875\n",
            "Batch 385/1041, Loss: 0.3554893136024475, Acc: 0.875\n",
            "Batch 386/1041, Loss: 0.5198632478713989, Acc: 0.84375\n",
            "Batch 387/1041, Loss: 0.25239700078964233, Acc: 0.875\n",
            "Batch 388/1041, Loss: 0.24574708938598633, Acc: 0.875\n",
            "Batch 389/1041, Loss: 0.26566722989082336, Acc: 0.9375\n",
            "Batch 390/1041, Loss: 0.26029160618782043, Acc: 0.96875\n",
            "Batch 391/1041, Loss: 0.44312697649002075, Acc: 0.84375\n",
            "Batch 392/1041, Loss: 0.35113173723220825, Acc: 0.875\n",
            "Batch 393/1041, Loss: 0.5187819004058838, Acc: 0.84375\n",
            "Batch 394/1041, Loss: 0.3970392346382141, Acc: 0.84375\n",
            "Batch 395/1041, Loss: 0.305226594209671, Acc: 0.875\n",
            "Batch 396/1041, Loss: 0.4962556064128876, Acc: 0.78125\n",
            "Batch 397/1041, Loss: 0.2568957805633545, Acc: 0.9375\n",
            "Batch 398/1041, Loss: 0.34276625514030457, Acc: 0.84375\n",
            "Batch 399/1041, Loss: 0.49789589643478394, Acc: 0.875\n",
            "Batch 400/1041, Loss: 0.3536129295825958, Acc: 0.84375\n",
            "Batch 401/1041, Loss: 0.5122262835502625, Acc: 0.84375\n",
            "Batch 402/1041, Loss: 0.3269661068916321, Acc: 0.8125\n",
            "Batch 403/1041, Loss: 0.15097828209400177, Acc: 0.96875\n",
            "Batch 404/1041, Loss: 0.4581534266471863, Acc: 0.78125\n",
            "Batch 405/1041, Loss: 0.46058371663093567, Acc: 0.71875\n",
            "Batch 406/1041, Loss: 0.25478681921958923, Acc: 0.90625\n",
            "Batch 407/1041, Loss: 0.27180397510528564, Acc: 0.90625\n",
            "Batch 408/1041, Loss: 0.24097484350204468, Acc: 0.9375\n",
            "Batch 409/1041, Loss: 0.2163751870393753, Acc: 0.9375\n",
            "Batch 410/1041, Loss: 0.21778617799282074, Acc: 0.9375\n",
            "Batch 411/1041, Loss: 0.44098860025405884, Acc: 0.875\n",
            "Batch 412/1041, Loss: 0.27877891063690186, Acc: 0.90625\n",
            "Batch 413/1041, Loss: 0.34847283363342285, Acc: 0.8125\n",
            "Batch 414/1041, Loss: 0.2855503559112549, Acc: 0.90625\n",
            "Batch 415/1041, Loss: 0.3694216012954712, Acc: 0.875\n",
            "Batch 416/1041, Loss: 0.5260363221168518, Acc: 0.71875\n",
            "Batch 417/1041, Loss: 0.479984849691391, Acc: 0.8125\n",
            "Batch 418/1041, Loss: 0.3611691892147064, Acc: 0.90625\n",
            "Batch 419/1041, Loss: 0.23390239477157593, Acc: 0.9375\n",
            "Batch 420/1041, Loss: 0.39100170135498047, Acc: 0.84375\n",
            "Batch 421/1041, Loss: 0.27746421098709106, Acc: 0.875\n",
            "Batch 422/1041, Loss: 0.2627856135368347, Acc: 0.875\n",
            "Batch 423/1041, Loss: 0.36980322003364563, Acc: 0.8125\n",
            "Batch 424/1041, Loss: 0.48529180884361267, Acc: 0.71875\n",
            "Batch 425/1041, Loss: 0.242639422416687, Acc: 0.90625\n",
            "Batch 426/1041, Loss: 0.17802360653877258, Acc: 0.9375\n",
            "Batch 427/1041, Loss: 0.34570932388305664, Acc: 0.875\n",
            "Batch 428/1041, Loss: 0.28714311122894287, Acc: 0.84375\n",
            "Batch 429/1041, Loss: 0.23642461001873016, Acc: 0.90625\n",
            "Batch 430/1041, Loss: 0.41751527786254883, Acc: 0.84375\n",
            "Batch 431/1041, Loss: 0.42280101776123047, Acc: 0.84375\n",
            "Batch 432/1041, Loss: 0.2859409749507904, Acc: 0.84375\n",
            "Batch 433/1041, Loss: 0.4020096957683563, Acc: 0.71875\n",
            "Batch 434/1041, Loss: 0.19186833500862122, Acc: 0.9375\n",
            "Batch 435/1041, Loss: 0.25726813077926636, Acc: 0.875\n",
            "Batch 436/1041, Loss: 0.3119506537914276, Acc: 0.84375\n",
            "Batch 437/1041, Loss: 0.1923229992389679, Acc: 0.96875\n",
            "Batch 438/1041, Loss: 0.38376110792160034, Acc: 0.84375\n",
            "Batch 439/1041, Loss: 0.3596208989620209, Acc: 0.8125\n",
            "Batch 440/1041, Loss: 0.4270646572113037, Acc: 0.875\n",
            "Batch 441/1041, Loss: 0.21828576922416687, Acc: 0.9375\n",
            "Batch 442/1041, Loss: 0.4103015959262848, Acc: 0.71875\n",
            "Batch 443/1041, Loss: 0.2265641689300537, Acc: 0.9375\n",
            "Batch 444/1041, Loss: 0.5478708148002625, Acc: 0.71875\n",
            "Batch 445/1041, Loss: 0.25850531458854675, Acc: 0.90625\n",
            "Batch 446/1041, Loss: 0.6365524530410767, Acc: 0.71875\n",
            "Batch 447/1041, Loss: 0.38246360421180725, Acc: 0.75\n",
            "Batch 448/1041, Loss: 0.46053266525268555, Acc: 0.78125\n",
            "Batch 449/1041, Loss: 0.1491919308900833, Acc: 0.96875\n",
            "Batch 450/1041, Loss: 0.1912536770105362, Acc: 0.96875\n",
            "Batch 451/1041, Loss: 0.3226231336593628, Acc: 0.84375\n",
            "Batch 452/1041, Loss: 0.30651339888572693, Acc: 0.9375\n",
            "Batch 453/1041, Loss: 0.33531564474105835, Acc: 0.84375\n",
            "Batch 454/1041, Loss: 0.3458329141139984, Acc: 0.8125\n",
            "Batch 455/1041, Loss: 0.2427597939968109, Acc: 0.875\n",
            "Batch 456/1041, Loss: 0.4428758919239044, Acc: 0.78125\n",
            "Batch 457/1041, Loss: 0.4635262191295624, Acc: 0.8125\n",
            "Batch 458/1041, Loss: 0.21951737999916077, Acc: 0.9375\n",
            "Batch 459/1041, Loss: 0.5369281768798828, Acc: 0.78125\n",
            "[Update 1500] Train Loss: 0.5369, Train Acc: 0.7812 | Val Loss: 0.3533, Val Acc: 0.8501\n",
            "Batch 460/1041, Loss: 0.29153430461883545, Acc: 0.84375\n",
            "Batch 461/1041, Loss: 0.22164641320705414, Acc: 0.875\n",
            "Batch 462/1041, Loss: 0.4326264262199402, Acc: 0.84375\n",
            "Batch 463/1041, Loss: 0.21021169424057007, Acc: 0.9375\n",
            "Batch 464/1041, Loss: 0.44773855805397034, Acc: 0.78125\n",
            "Batch 465/1041, Loss: 0.4230620861053467, Acc: 0.78125\n",
            "Batch 466/1041, Loss: 0.36171507835388184, Acc: 0.875\n",
            "Batch 467/1041, Loss: 0.3928648829460144, Acc: 0.8125\n",
            "Batch 468/1041, Loss: 0.5214290618896484, Acc: 0.8125\n",
            "Batch 469/1041, Loss: 0.3313271701335907, Acc: 0.84375\n",
            "Batch 470/1041, Loss: 0.2301676720380783, Acc: 0.90625\n",
            "Batch 471/1041, Loss: 0.4027700424194336, Acc: 0.8125\n",
            "Batch 472/1041, Loss: 0.2777184545993805, Acc: 0.875\n",
            "Batch 473/1041, Loss: 0.5158843994140625, Acc: 0.75\n",
            "Batch 474/1041, Loss: 0.33946776390075684, Acc: 0.84375\n",
            "Batch 475/1041, Loss: 0.31870853900909424, Acc: 0.84375\n",
            "Batch 476/1041, Loss: 0.3456438183784485, Acc: 0.875\n",
            "Batch 477/1041, Loss: 0.28705233335494995, Acc: 0.9375\n",
            "Batch 478/1041, Loss: 0.4177513122558594, Acc: 0.8125\n",
            "Batch 479/1041, Loss: 0.37038835883140564, Acc: 0.8125\n",
            "Batch 480/1041, Loss: 0.338545024394989, Acc: 0.84375\n",
            "Batch 481/1041, Loss: 0.3396012783050537, Acc: 0.875\n",
            "Batch 482/1041, Loss: 0.20763535797595978, Acc: 0.9375\n",
            "Batch 483/1041, Loss: 0.4753577411174774, Acc: 0.8125\n",
            "Batch 484/1041, Loss: 0.34840628504753113, Acc: 0.78125\n",
            "Batch 485/1041, Loss: 0.3102589547634125, Acc: 0.90625\n",
            "Batch 486/1041, Loss: 0.3726343810558319, Acc: 0.8125\n",
            "Batch 487/1041, Loss: 0.37019339203834534, Acc: 0.84375\n",
            "Batch 488/1041, Loss: 0.28618666529655457, Acc: 0.90625\n",
            "Batch 489/1041, Loss: 0.3452131748199463, Acc: 0.84375\n",
            "Batch 490/1041, Loss: 0.35158753395080566, Acc: 0.75\n",
            "Batch 491/1041, Loss: 0.3161875605583191, Acc: 0.875\n",
            "Batch 492/1041, Loss: 0.1641804724931717, Acc: 0.9375\n",
            "Batch 493/1041, Loss: 0.370527982711792, Acc: 0.875\n",
            "Batch 494/1041, Loss: 0.5519271492958069, Acc: 0.78125\n",
            "Batch 495/1041, Loss: 0.28776830434799194, Acc: 0.84375\n",
            "Batch 496/1041, Loss: 0.2508823573589325, Acc: 0.9375\n",
            "Batch 497/1041, Loss: 0.44294458627700806, Acc: 0.8125\n",
            "Batch 498/1041, Loss: 0.31090909242630005, Acc: 0.90625\n",
            "Batch 499/1041, Loss: 0.4447447657585144, Acc: 0.78125\n",
            "Batch 500/1041, Loss: 0.3438161611557007, Acc: 0.9375\n",
            "Batch 501/1041, Loss: 0.304239958524704, Acc: 0.84375\n",
            "Batch 502/1041, Loss: 0.2594302296638489, Acc: 0.90625\n",
            "Batch 503/1041, Loss: 0.35101887583732605, Acc: 0.84375\n",
            "Batch 504/1041, Loss: 0.16647827625274658, Acc: 0.96875\n",
            "Batch 505/1041, Loss: 0.21026188135147095, Acc: 0.9375\n",
            "Batch 506/1041, Loss: 0.2897803783416748, Acc: 0.875\n",
            "Batch 507/1041, Loss: 0.30479034781455994, Acc: 0.78125\n",
            "Batch 508/1041, Loss: 0.47664889693260193, Acc: 0.75\n",
            "Batch 509/1041, Loss: 0.26988139748573303, Acc: 0.84375\n",
            "Batch 510/1041, Loss: 0.21660694479942322, Acc: 0.9375\n",
            "Batch 511/1041, Loss: 0.3188014626502991, Acc: 0.875\n",
            "Batch 512/1041, Loss: 0.447435587644577, Acc: 0.8125\n",
            "Batch 513/1041, Loss: 0.5861456990242004, Acc: 0.75\n",
            "Batch 514/1041, Loss: 0.34436067938804626, Acc: 0.78125\n",
            "Batch 515/1041, Loss: 0.2851940095424652, Acc: 0.90625\n",
            "Batch 516/1041, Loss: 0.27247384190559387, Acc: 0.875\n",
            "Batch 517/1041, Loss: 0.32565736770629883, Acc: 0.84375\n",
            "Batch 518/1041, Loss: 0.26168292760849, Acc: 0.8125\n",
            "Batch 519/1041, Loss: 0.39446884393692017, Acc: 0.875\n",
            "Batch 520/1041, Loss: 0.35362401604652405, Acc: 0.875\n",
            "Batch 521/1041, Loss: 0.2388773113489151, Acc: 0.875\n",
            "Batch 522/1041, Loss: 0.33537667989730835, Acc: 0.8125\n",
            "Batch 523/1041, Loss: 0.2513622045516968, Acc: 0.875\n",
            "Batch 524/1041, Loss: 0.2072722464799881, Acc: 0.9375\n",
            "Batch 525/1041, Loss: 0.24505531787872314, Acc: 0.90625\n",
            "Batch 526/1041, Loss: 0.5968763828277588, Acc: 0.78125\n",
            "Batch 527/1041, Loss: 0.17921026051044464, Acc: 0.9375\n",
            "Batch 528/1041, Loss: 0.3265596330165863, Acc: 0.875\n",
            "Batch 529/1041, Loss: 0.39832034707069397, Acc: 0.84375\n",
            "Batch 530/1041, Loss: 0.2448078691959381, Acc: 0.90625\n",
            "Batch 531/1041, Loss: 0.41919735074043274, Acc: 0.78125\n",
            "Batch 532/1041, Loss: 0.35871097445487976, Acc: 0.78125\n",
            "Batch 533/1041, Loss: 0.27455076575279236, Acc: 0.875\n",
            "Batch 534/1041, Loss: 0.2672833502292633, Acc: 0.875\n",
            "Batch 535/1041, Loss: 0.3110526204109192, Acc: 0.84375\n",
            "Batch 536/1041, Loss: 0.3291894197463989, Acc: 0.90625\n",
            "Batch 537/1041, Loss: 0.2737736999988556, Acc: 0.875\n",
            "Batch 538/1041, Loss: 0.2693493068218231, Acc: 0.90625\n",
            "Batch 539/1041, Loss: 0.29419010877609253, Acc: 0.90625\n",
            "Batch 540/1041, Loss: 0.49442628026008606, Acc: 0.71875\n",
            "Batch 541/1041, Loss: 0.31703516840934753, Acc: 0.875\n",
            "Batch 542/1041, Loss: 0.3725808262825012, Acc: 0.875\n",
            "Batch 543/1041, Loss: 0.4570479094982147, Acc: 0.75\n",
            "Batch 544/1041, Loss: 0.4834837317466736, Acc: 0.8125\n",
            "Batch 545/1041, Loss: 0.28971701860427856, Acc: 0.875\n",
            "Batch 546/1041, Loss: 0.5153440237045288, Acc: 0.8125\n",
            "Batch 547/1041, Loss: 0.24052734673023224, Acc: 0.9375\n",
            "Batch 548/1041, Loss: 0.640857994556427, Acc: 0.65625\n",
            "Batch 549/1041, Loss: 0.28142258524894714, Acc: 0.875\n",
            "Batch 550/1041, Loss: 0.43034273386001587, Acc: 0.84375\n",
            "Batch 551/1041, Loss: 0.17073103785514832, Acc: 0.96875\n",
            "Batch 552/1041, Loss: 0.43081364035606384, Acc: 0.78125\n",
            "Batch 553/1041, Loss: 0.33581778407096863, Acc: 0.78125\n",
            "Batch 554/1041, Loss: 0.47549325227737427, Acc: 0.8125\n",
            "Batch 555/1041, Loss: 0.3270811438560486, Acc: 0.90625\n",
            "Batch 556/1041, Loss: 0.1645989716053009, Acc: 0.96875\n",
            "Batch 557/1041, Loss: 0.22909227013587952, Acc: 0.875\n",
            "Batch 558/1041, Loss: 0.17145207524299622, Acc: 0.9375\n",
            "Batch 559/1041, Loss: 0.2928447425365448, Acc: 0.875\n",
            "[Update 1600] Train Loss: 0.2928, Train Acc: 0.8750 | Val Loss: 0.3254, Val Acc: 0.8591\n",
            "Batch 560/1041, Loss: 0.3248704671859741, Acc: 0.84375\n",
            "Batch 561/1041, Loss: 0.31249523162841797, Acc: 0.84375\n",
            "Batch 562/1041, Loss: 0.26469263434410095, Acc: 0.9375\n",
            "Batch 563/1041, Loss: 0.27303194999694824, Acc: 0.875\n",
            "Batch 564/1041, Loss: 0.4191585183143616, Acc: 0.8125\n",
            "Batch 565/1041, Loss: 0.3190825283527374, Acc: 0.875\n",
            "Batch 566/1041, Loss: 0.22817176580429077, Acc: 0.90625\n",
            "Batch 567/1041, Loss: 0.5538795590400696, Acc: 0.75\n",
            "Batch 568/1041, Loss: 0.3867671489715576, Acc: 0.8125\n",
            "Batch 569/1041, Loss: 0.22670623660087585, Acc: 0.96875\n",
            "Batch 570/1041, Loss: 0.27589860558509827, Acc: 0.90625\n",
            "Batch 571/1041, Loss: 0.34470343589782715, Acc: 0.84375\n",
            "Batch 572/1041, Loss: 0.4942500591278076, Acc: 0.8125\n",
            "Batch 573/1041, Loss: 0.18890833854675293, Acc: 0.9375\n",
            "Batch 574/1041, Loss: 0.5146725177764893, Acc: 0.78125\n",
            "Batch 575/1041, Loss: 0.460456520318985, Acc: 0.75\n",
            "Batch 576/1041, Loss: 0.2751789391040802, Acc: 0.875\n",
            "Batch 577/1041, Loss: 0.42542868852615356, Acc: 0.84375\n",
            "Batch 578/1041, Loss: 0.3884175419807434, Acc: 0.875\n",
            "Batch 579/1041, Loss: 0.39592111110687256, Acc: 0.8125\n",
            "Batch 580/1041, Loss: 0.3414248526096344, Acc: 0.875\n",
            "Batch 581/1041, Loss: 0.509216845035553, Acc: 0.75\n",
            "Batch 582/1041, Loss: 0.2763880491256714, Acc: 0.90625\n",
            "Batch 583/1041, Loss: 0.2719753086566925, Acc: 0.84375\n",
            "Batch 584/1041, Loss: 0.2572476267814636, Acc: 0.9375\n",
            "Batch 585/1041, Loss: 0.4212460517883301, Acc: 0.84375\n",
            "Batch 586/1041, Loss: 0.46098390221595764, Acc: 0.84375\n",
            "Batch 587/1041, Loss: 0.34146445989608765, Acc: 0.8125\n",
            "Batch 588/1041, Loss: 0.5015043020248413, Acc: 0.75\n",
            "Batch 589/1041, Loss: 0.191288024187088, Acc: 0.9375\n",
            "Batch 590/1041, Loss: 0.20371675491333008, Acc: 0.875\n",
            "Batch 591/1041, Loss: 0.3554159700870514, Acc: 0.8125\n",
            "Batch 592/1041, Loss: 0.3364909887313843, Acc: 0.8125\n",
            "Batch 593/1041, Loss: 0.23638564348220825, Acc: 0.90625\n",
            "Batch 594/1041, Loss: 0.23298688232898712, Acc: 0.90625\n",
            "Batch 595/1041, Loss: 0.2175193727016449, Acc: 0.9375\n",
            "Batch 596/1041, Loss: 0.329397976398468, Acc: 0.84375\n",
            "Batch 597/1041, Loss: 0.40661486983299255, Acc: 0.8125\n",
            "Batch 598/1041, Loss: 0.24135272204875946, Acc: 0.9375\n",
            "Batch 599/1041, Loss: 0.5316149592399597, Acc: 0.78125\n",
            "Batch 600/1041, Loss: 0.5333154201507568, Acc: 0.71875\n",
            "Batch 601/1041, Loss: 0.3279687762260437, Acc: 0.875\n",
            "Batch 602/1041, Loss: 0.2550415098667145, Acc: 0.90625\n",
            "Batch 603/1041, Loss: 0.22158244252204895, Acc: 0.9375\n",
            "Batch 604/1041, Loss: 0.4654574692249298, Acc: 0.8125\n",
            "Batch 605/1041, Loss: 0.3198425769805908, Acc: 0.875\n",
            "Batch 606/1041, Loss: 0.3359605073928833, Acc: 0.84375\n",
            "Batch 607/1041, Loss: 0.5013784766197205, Acc: 0.78125\n",
            "Batch 608/1041, Loss: 0.3673264682292938, Acc: 0.78125\n",
            "Batch 609/1041, Loss: 0.4785497784614563, Acc: 0.71875\n",
            "Batch 610/1041, Loss: 0.25779983401298523, Acc: 0.9375\n",
            "Batch 611/1041, Loss: 0.3042660355567932, Acc: 0.875\n",
            "Batch 612/1041, Loss: 0.24744372069835663, Acc: 0.875\n",
            "Batch 613/1041, Loss: 0.1282522976398468, Acc: 1.0\n",
            "Batch 614/1041, Loss: 0.22916486859321594, Acc: 0.9375\n",
            "Batch 615/1041, Loss: 0.48530855774879456, Acc: 0.71875\n",
            "Batch 616/1041, Loss: 0.3535730838775635, Acc: 0.84375\n",
            "Batch 617/1041, Loss: 0.3591515123844147, Acc: 0.875\n",
            "Batch 618/1041, Loss: 0.3743148446083069, Acc: 0.8125\n",
            "Batch 619/1041, Loss: 0.35034069418907166, Acc: 0.84375\n",
            "Batch 620/1041, Loss: 0.3843618929386139, Acc: 0.8125\n",
            "Batch 621/1041, Loss: 0.32257163524627686, Acc: 0.8125\n",
            "Batch 622/1041, Loss: 0.3328206241130829, Acc: 0.84375\n",
            "Batch 623/1041, Loss: 0.2456526905298233, Acc: 0.90625\n",
            "Batch 624/1041, Loss: 0.30707916617393494, Acc: 0.8125\n",
            "Batch 625/1041, Loss: 0.27556005120277405, Acc: 0.875\n",
            "Batch 626/1041, Loss: 0.2513740658760071, Acc: 0.90625\n",
            "Batch 627/1041, Loss: 0.19699512422084808, Acc: 0.96875\n",
            "Batch 628/1041, Loss: 0.2616429626941681, Acc: 0.90625\n",
            "Batch 629/1041, Loss: 0.3575049638748169, Acc: 0.8125\n",
            "Batch 630/1041, Loss: 0.331387460231781, Acc: 0.8125\n",
            "Batch 631/1041, Loss: 0.5375768542289734, Acc: 0.78125\n",
            "Batch 632/1041, Loss: 0.3210269510746002, Acc: 0.875\n",
            "Batch 633/1041, Loss: 0.2746005356311798, Acc: 0.90625\n",
            "Batch 634/1041, Loss: 0.4750834107398987, Acc: 0.78125\n",
            "Batch 635/1041, Loss: 0.28544872999191284, Acc: 0.84375\n",
            "Batch 636/1041, Loss: 0.21359778940677643, Acc: 0.9375\n",
            "Batch 637/1041, Loss: 0.39722737669944763, Acc: 0.8125\n",
            "Batch 638/1041, Loss: 0.24292245507240295, Acc: 0.90625\n",
            "Batch 639/1041, Loss: 0.4548322856426239, Acc: 0.8125\n",
            "Batch 640/1041, Loss: 0.3397318124771118, Acc: 0.875\n",
            "Batch 641/1041, Loss: 0.3989448845386505, Acc: 0.8125\n",
            "Batch 642/1041, Loss: 0.16988688707351685, Acc: 0.9375\n",
            "Batch 643/1041, Loss: 0.25611013174057007, Acc: 0.9375\n",
            "Batch 644/1041, Loss: 0.2293619066476822, Acc: 0.9375\n",
            "Batch 645/1041, Loss: 0.19483596086502075, Acc: 0.9375\n",
            "Batch 646/1041, Loss: 0.23472078144550323, Acc: 0.9375\n",
            "Batch 647/1041, Loss: 0.34607863426208496, Acc: 0.875\n",
            "Batch 648/1041, Loss: 0.3471281826496124, Acc: 0.84375\n",
            "Batch 649/1041, Loss: 0.3458958566188812, Acc: 0.875\n",
            "Batch 650/1041, Loss: 0.2733030915260315, Acc: 0.875\n",
            "Batch 651/1041, Loss: 0.2783615291118622, Acc: 0.875\n",
            "Batch 652/1041, Loss: 0.2683922052383423, Acc: 0.875\n",
            "Batch 653/1041, Loss: 0.2185981720685959, Acc: 0.90625\n",
            "Batch 654/1041, Loss: 0.382500022649765, Acc: 0.84375\n",
            "Batch 655/1041, Loss: 0.34737759828567505, Acc: 0.84375\n",
            "Batch 656/1041, Loss: 0.26714175939559937, Acc: 0.875\n",
            "Batch 657/1041, Loss: 0.2599967122077942, Acc: 0.90625\n",
            "Batch 658/1041, Loss: 0.3185220956802368, Acc: 0.875\n",
            "Batch 659/1041, Loss: 0.2793926000595093, Acc: 0.90625\n",
            "[Update 1700] Train Loss: 0.2794, Train Acc: 0.9062 | Val Loss: 0.3182, Val Acc: 0.8679\n",
            "Batch 660/1041, Loss: 0.19871102273464203, Acc: 0.96875\n",
            "Batch 661/1041, Loss: 0.3918274939060211, Acc: 0.875\n",
            "Batch 662/1041, Loss: 0.5588175654411316, Acc: 0.75\n",
            "Batch 663/1041, Loss: 0.14801348745822906, Acc: 0.9375\n",
            "Batch 664/1041, Loss: 0.37490618228912354, Acc: 0.8125\n",
            "Batch 665/1041, Loss: 0.44212689995765686, Acc: 0.8125\n",
            "Batch 666/1041, Loss: 0.4091328978538513, Acc: 0.8125\n",
            "Batch 667/1041, Loss: 0.39993610978126526, Acc: 0.8125\n",
            "Batch 668/1041, Loss: 0.35749682784080505, Acc: 0.78125\n",
            "Batch 669/1041, Loss: 0.3293732702732086, Acc: 0.84375\n",
            "Batch 670/1041, Loss: 0.5340415835380554, Acc: 0.78125\n",
            "Batch 671/1041, Loss: 0.35698401927948, Acc: 0.84375\n",
            "Batch 672/1041, Loss: 0.354510098695755, Acc: 0.875\n",
            "Batch 673/1041, Loss: 0.23540493845939636, Acc: 0.8125\n",
            "Batch 674/1041, Loss: 0.4357353448867798, Acc: 0.8125\n",
            "Batch 675/1041, Loss: 0.45601218938827515, Acc: 0.78125\n",
            "Batch 676/1041, Loss: 0.3010074496269226, Acc: 0.875\n",
            "Batch 677/1041, Loss: 0.4507162868976593, Acc: 0.84375\n",
            "Batch 678/1041, Loss: 0.4116758406162262, Acc: 0.875\n",
            "Batch 679/1041, Loss: 0.4320793151855469, Acc: 0.8125\n",
            "Batch 680/1041, Loss: 0.3158065974712372, Acc: 0.84375\n",
            "Batch 681/1041, Loss: 0.27505162358283997, Acc: 0.875\n",
            "Batch 682/1041, Loss: 0.3510482609272003, Acc: 0.84375\n",
            "Batch 683/1041, Loss: 0.4651855230331421, Acc: 0.75\n",
            "Batch 684/1041, Loss: 0.34173983335494995, Acc: 0.84375\n",
            "Batch 685/1041, Loss: 0.498850017786026, Acc: 0.84375\n",
            "Batch 686/1041, Loss: 0.44471225142478943, Acc: 0.78125\n",
            "Batch 687/1041, Loss: 0.1638084352016449, Acc: 0.96875\n",
            "Batch 688/1041, Loss: 0.3880053162574768, Acc: 0.875\n",
            "Batch 689/1041, Loss: 0.4474678337574005, Acc: 0.84375\n",
            "Batch 690/1041, Loss: 0.3784559965133667, Acc: 0.84375\n",
            "Batch 691/1041, Loss: 0.398896723985672, Acc: 0.78125\n",
            "Batch 692/1041, Loss: 0.3055020570755005, Acc: 0.84375\n",
            "Batch 693/1041, Loss: 0.30622240900993347, Acc: 0.875\n",
            "Batch 694/1041, Loss: 0.2671114206314087, Acc: 0.90625\n",
            "Batch 695/1041, Loss: 0.36675214767456055, Acc: 0.8125\n",
            "Batch 696/1041, Loss: 0.26074349880218506, Acc: 0.875\n",
            "Batch 697/1041, Loss: 0.5619329214096069, Acc: 0.71875\n",
            "Batch 698/1041, Loss: 0.3531136214733124, Acc: 0.875\n",
            "Batch 699/1041, Loss: 0.3234485685825348, Acc: 0.84375\n",
            "Batch 700/1041, Loss: 0.28215816617012024, Acc: 0.9375\n",
            "Batch 701/1041, Loss: 0.4339783489704132, Acc: 0.8125\n",
            "Batch 702/1041, Loss: 0.27321723103523254, Acc: 0.90625\n",
            "Batch 703/1041, Loss: 0.2930545508861542, Acc: 0.90625\n",
            "Batch 704/1041, Loss: 0.1952866166830063, Acc: 0.9375\n",
            "Batch 705/1041, Loss: 0.265928715467453, Acc: 0.90625\n",
            "Batch 706/1041, Loss: 0.406024694442749, Acc: 0.78125\n",
            "Batch 707/1041, Loss: 0.3180643320083618, Acc: 0.84375\n",
            "Batch 708/1041, Loss: 0.3093720078468323, Acc: 0.875\n",
            "Batch 709/1041, Loss: 0.40698131918907166, Acc: 0.8125\n",
            "Batch 710/1041, Loss: 0.18126632273197174, Acc: 0.9375\n",
            "Batch 711/1041, Loss: 0.5125223398208618, Acc: 0.84375\n",
            "Batch 712/1041, Loss: 0.58487868309021, Acc: 0.78125\n",
            "Batch 713/1041, Loss: 0.43838977813720703, Acc: 0.78125\n",
            "Batch 714/1041, Loss: 0.4167957901954651, Acc: 0.8125\n",
            "Batch 715/1041, Loss: 0.39725247025489807, Acc: 0.75\n",
            "Batch 716/1041, Loss: 0.17326202988624573, Acc: 0.9375\n",
            "Batch 717/1041, Loss: 0.4126415252685547, Acc: 0.84375\n",
            "Batch 718/1041, Loss: 0.408978670835495, Acc: 0.8125\n",
            "Batch 719/1041, Loss: 0.3688889443874359, Acc: 0.84375\n",
            "Batch 720/1041, Loss: 0.30869221687316895, Acc: 0.875\n",
            "Batch 721/1041, Loss: 0.21900874376296997, Acc: 0.90625\n",
            "Batch 722/1041, Loss: 0.27780207991600037, Acc: 0.875\n",
            "Batch 723/1041, Loss: 0.35647571086883545, Acc: 0.84375\n",
            "Batch 724/1041, Loss: 0.19253017008304596, Acc: 0.96875\n",
            "Batch 725/1041, Loss: 0.3045699894428253, Acc: 0.875\n",
            "Batch 726/1041, Loss: 0.3238069713115692, Acc: 0.875\n",
            "Batch 727/1041, Loss: 0.30631113052368164, Acc: 0.8125\n",
            "Batch 728/1041, Loss: 0.40390756726264954, Acc: 0.8125\n",
            "Batch 729/1041, Loss: 0.39752599596977234, Acc: 0.84375\n",
            "Batch 730/1041, Loss: 0.4520741105079651, Acc: 0.875\n",
            "Batch 731/1041, Loss: 0.3024241328239441, Acc: 0.875\n",
            "Batch 732/1041, Loss: 0.2750045657157898, Acc: 0.875\n",
            "Batch 733/1041, Loss: 0.42382267117500305, Acc: 0.8125\n",
            "Batch 734/1041, Loss: 0.4033331871032715, Acc: 0.84375\n",
            "Batch 735/1041, Loss: 0.35961398482322693, Acc: 0.78125\n",
            "Batch 736/1041, Loss: 0.48730626702308655, Acc: 0.75\n",
            "Batch 737/1041, Loss: 0.39747506380081177, Acc: 0.8125\n",
            "Batch 738/1041, Loss: 0.3032444715499878, Acc: 0.875\n",
            "Batch 739/1041, Loss: 0.5223032236099243, Acc: 0.84375\n",
            "Batch 740/1041, Loss: 0.2366732507944107, Acc: 0.875\n",
            "Batch 741/1041, Loss: 0.31714537739753723, Acc: 0.84375\n",
            "Batch 742/1041, Loss: 0.41194528341293335, Acc: 0.84375\n",
            "Batch 743/1041, Loss: 0.3597835302352905, Acc: 0.84375\n",
            "Batch 744/1041, Loss: 0.32880160212516785, Acc: 0.84375\n",
            "Batch 745/1041, Loss: 0.5343495607376099, Acc: 0.75\n",
            "Batch 746/1041, Loss: 0.19185449182987213, Acc: 0.9375\n",
            "Batch 747/1041, Loss: 0.5007228255271912, Acc: 0.78125\n",
            "Batch 748/1041, Loss: 0.3217601776123047, Acc: 0.84375\n",
            "Batch 749/1041, Loss: 0.29077044129371643, Acc: 0.90625\n",
            "Batch 750/1041, Loss: 0.28436580300331116, Acc: 0.84375\n",
            "Batch 751/1041, Loss: 0.3774292469024658, Acc: 0.875\n",
            "Batch 752/1041, Loss: 0.17828810214996338, Acc: 0.96875\n",
            "Batch 753/1041, Loss: 0.3845005929470062, Acc: 0.8125\n",
            "Batch 754/1041, Loss: 0.31008076667785645, Acc: 0.875\n",
            "Batch 755/1041, Loss: 0.21339678764343262, Acc: 0.90625\n",
            "Batch 756/1041, Loss: 0.3733929693698883, Acc: 0.84375\n",
            "Batch 757/1041, Loss: 0.41685593128204346, Acc: 0.75\n",
            "Batch 758/1041, Loss: 0.3512851297855377, Acc: 0.875\n",
            "Batch 759/1041, Loss: 0.4576590061187744, Acc: 0.875\n",
            "[Update 1800] Train Loss: 0.4577, Train Acc: 0.8750 | Val Loss: 0.3217, Val Acc: 0.8663\n",
            "Batch 760/1041, Loss: 0.2470426708459854, Acc: 0.875\n",
            "Batch 761/1041, Loss: 0.29482436180114746, Acc: 0.84375\n",
            "Batch 762/1041, Loss: 0.24972693622112274, Acc: 0.90625\n",
            "Batch 763/1041, Loss: 0.13966335356235504, Acc: 0.96875\n",
            "Batch 764/1041, Loss: 0.5029570460319519, Acc: 0.78125\n",
            "Batch 765/1041, Loss: 0.24686874449253082, Acc: 0.90625\n",
            "Batch 766/1041, Loss: 0.23297688364982605, Acc: 0.90625\n",
            "Batch 767/1041, Loss: 0.2154376208782196, Acc: 0.90625\n",
            "Batch 768/1041, Loss: 0.3427892029285431, Acc: 0.84375\n",
            "Batch 769/1041, Loss: 0.36843299865722656, Acc: 0.78125\n",
            "Batch 770/1041, Loss: 0.42607182264328003, Acc: 0.78125\n",
            "Batch 771/1041, Loss: 0.22868359088897705, Acc: 0.9375\n",
            "Batch 772/1041, Loss: 0.3041847050189972, Acc: 0.84375\n",
            "Batch 773/1041, Loss: 0.4335710406303406, Acc: 0.71875\n",
            "Batch 774/1041, Loss: 0.15307281911373138, Acc: 0.96875\n",
            "Batch 775/1041, Loss: 0.31709593534469604, Acc: 0.84375\n",
            "Batch 776/1041, Loss: 0.43812933564186096, Acc: 0.84375\n",
            "Batch 777/1041, Loss: 0.5147044658660889, Acc: 0.71875\n",
            "Batch 778/1041, Loss: 0.3671340346336365, Acc: 0.90625\n",
            "Batch 779/1041, Loss: 0.29907160997390747, Acc: 0.90625\n",
            "Batch 780/1041, Loss: 0.2489156723022461, Acc: 0.84375\n",
            "Batch 781/1041, Loss: 0.26171228289604187, Acc: 0.96875\n",
            "Batch 782/1041, Loss: 0.4332582950592041, Acc: 0.8125\n",
            "Batch 783/1041, Loss: 0.37292924523353577, Acc: 0.84375\n",
            "Batch 784/1041, Loss: 0.23999576270580292, Acc: 0.90625\n",
            "Batch 785/1041, Loss: 0.2837967574596405, Acc: 0.84375\n",
            "Batch 786/1041, Loss: 0.4862070381641388, Acc: 0.8125\n",
            "Batch 787/1041, Loss: 0.49070554971694946, Acc: 0.84375\n",
            "Batch 788/1041, Loss: 0.14081373810768127, Acc: 0.96875\n",
            "Batch 789/1041, Loss: 0.36740708351135254, Acc: 0.8125\n",
            "Batch 790/1041, Loss: 0.49675723910331726, Acc: 0.78125\n",
            "Batch 791/1041, Loss: 0.3711165487766266, Acc: 0.8125\n",
            "Batch 792/1041, Loss: 0.19533975422382355, Acc: 0.9375\n",
            "Batch 793/1041, Loss: 0.38641685247421265, Acc: 0.78125\n",
            "Batch 794/1041, Loss: 0.36009809374809265, Acc: 0.8125\n",
            "Batch 795/1041, Loss: 0.23835241794586182, Acc: 0.90625\n",
            "Batch 796/1041, Loss: 0.3531583547592163, Acc: 0.78125\n",
            "Batch 797/1041, Loss: 0.31173813343048096, Acc: 0.84375\n",
            "Batch 798/1041, Loss: 0.4580264687538147, Acc: 0.71875\n",
            "Batch 799/1041, Loss: 0.5024581551551819, Acc: 0.6875\n",
            "Batch 800/1041, Loss: 0.29342329502105713, Acc: 0.875\n",
            "Batch 801/1041, Loss: 0.30797430872917175, Acc: 0.90625\n",
            "Batch 802/1041, Loss: 0.43166500329971313, Acc: 0.8125\n",
            "Batch 803/1041, Loss: 0.5478640794754028, Acc: 0.78125\n",
            "Batch 804/1041, Loss: 0.4670344591140747, Acc: 0.84375\n",
            "Batch 805/1041, Loss: 0.4507032334804535, Acc: 0.84375\n",
            "Batch 806/1041, Loss: 0.2847610116004944, Acc: 0.90625\n",
            "Batch 807/1041, Loss: 0.3350624144077301, Acc: 0.90625\n",
            "Batch 808/1041, Loss: 0.29404133558273315, Acc: 0.90625\n",
            "Batch 809/1041, Loss: 0.4176839590072632, Acc: 0.8125\n",
            "Batch 810/1041, Loss: 0.4347359240055084, Acc: 0.75\n",
            "Batch 811/1041, Loss: 0.26480913162231445, Acc: 0.90625\n",
            "Batch 812/1041, Loss: 0.23966631293296814, Acc: 0.90625\n",
            "Batch 813/1041, Loss: 0.29715895652770996, Acc: 0.9375\n",
            "Batch 814/1041, Loss: 0.32234716415405273, Acc: 0.9375\n",
            "Batch 815/1041, Loss: 0.21140632033348083, Acc: 0.90625\n",
            "Batch 816/1041, Loss: 0.3698539137840271, Acc: 0.84375\n",
            "Batch 817/1041, Loss: 0.3503187894821167, Acc: 0.90625\n",
            "Batch 818/1041, Loss: 0.24884502589702606, Acc: 0.875\n",
            "Batch 819/1041, Loss: 0.22387148439884186, Acc: 0.90625\n",
            "Batch 820/1041, Loss: 0.3241439163684845, Acc: 0.875\n",
            "Batch 821/1041, Loss: 0.21343867480754852, Acc: 0.875\n",
            "Batch 822/1041, Loss: 0.30869796872138977, Acc: 0.90625\n",
            "Batch 823/1041, Loss: 0.503233015537262, Acc: 0.78125\n",
            "Batch 824/1041, Loss: 0.2156302034854889, Acc: 0.9375\n",
            "Batch 825/1041, Loss: 0.27338364720344543, Acc: 0.9375\n",
            "Batch 826/1041, Loss: 0.33928048610687256, Acc: 0.84375\n",
            "Batch 827/1041, Loss: 0.306417316198349, Acc: 0.84375\n",
            "Batch 828/1041, Loss: 0.315769761800766, Acc: 0.8125\n",
            "Batch 829/1041, Loss: 0.29397985339164734, Acc: 0.90625\n",
            "Batch 830/1041, Loss: 0.47270920872688293, Acc: 0.75\n",
            "Batch 831/1041, Loss: 0.22872865200042725, Acc: 0.9375\n",
            "Batch 832/1041, Loss: 0.48407867550849915, Acc: 0.75\n",
            "Batch 833/1041, Loss: 0.2680034339427948, Acc: 0.875\n",
            "Batch 834/1041, Loss: 0.4196195900440216, Acc: 0.875\n",
            "Batch 835/1041, Loss: 0.28168919682502747, Acc: 0.875\n",
            "Batch 836/1041, Loss: 0.37475427985191345, Acc: 0.875\n",
            "Batch 837/1041, Loss: 0.24920080602169037, Acc: 0.90625\n",
            "Batch 838/1041, Loss: 0.32693979144096375, Acc: 0.8125\n",
            "Batch 839/1041, Loss: 0.46792280673980713, Acc: 0.78125\n",
            "Batch 840/1041, Loss: 0.5472034215927124, Acc: 0.75\n",
            "Batch 841/1041, Loss: 0.281558632850647, Acc: 0.875\n",
            "Batch 842/1041, Loss: 0.4767271876335144, Acc: 0.75\n",
            "Batch 843/1041, Loss: 0.2908691167831421, Acc: 0.875\n",
            "Batch 844/1041, Loss: 0.39063623547554016, Acc: 0.84375\n",
            "Batch 845/1041, Loss: 0.16640955209732056, Acc: 0.96875\n",
            "Batch 846/1041, Loss: 0.2511868178844452, Acc: 0.9375\n",
            "Batch 847/1041, Loss: 0.6798525452613831, Acc: 0.6875\n",
            "Batch 848/1041, Loss: 0.2680031359195709, Acc: 0.90625\n",
            "Batch 849/1041, Loss: 0.21792864799499512, Acc: 0.875\n",
            "Batch 850/1041, Loss: 0.19058379530906677, Acc: 0.9375\n",
            "Batch 851/1041, Loss: 0.36820748448371887, Acc: 0.8125\n",
            "Batch 852/1041, Loss: 0.27439966797828674, Acc: 0.90625\n",
            "Batch 853/1041, Loss: 0.40558886528015137, Acc: 0.8125\n",
            "Batch 854/1041, Loss: 0.2991192042827606, Acc: 0.90625\n",
            "Batch 855/1041, Loss: 0.46157845854759216, Acc: 0.8125\n",
            "Batch 856/1041, Loss: 0.39796727895736694, Acc: 0.875\n",
            "Batch 857/1041, Loss: 0.21703332662582397, Acc: 0.90625\n",
            "Batch 858/1041, Loss: 0.32165300846099854, Acc: 0.875\n",
            "Batch 859/1041, Loss: 0.3348257541656494, Acc: 0.875\n",
            "[Update 1900] Train Loss: 0.3348, Train Acc: 0.8750 | Val Loss: 0.3246, Val Acc: 0.8677\n",
            "Batch 860/1041, Loss: 0.3249252736568451, Acc: 0.875\n",
            "Batch 861/1041, Loss: 0.2365163266658783, Acc: 0.9375\n",
            "Batch 862/1041, Loss: 0.26310718059539795, Acc: 0.8125\n",
            "Batch 863/1041, Loss: 0.41726261377334595, Acc: 0.78125\n",
            "Batch 864/1041, Loss: 0.31834444403648376, Acc: 0.875\n",
            "Batch 865/1041, Loss: 0.30248579382896423, Acc: 0.875\n",
            "Batch 866/1041, Loss: 0.23660625517368317, Acc: 0.875\n",
            "Batch 867/1041, Loss: 0.37681132555007935, Acc: 0.8125\n",
            "Batch 868/1041, Loss: 0.20141200721263885, Acc: 0.9375\n",
            "Batch 869/1041, Loss: 0.2029646635055542, Acc: 0.90625\n",
            "Batch 870/1041, Loss: 0.2554270327091217, Acc: 0.875\n",
            "Batch 871/1041, Loss: 0.6041163206100464, Acc: 0.71875\n",
            "Batch 872/1041, Loss: 0.48054689168930054, Acc: 0.78125\n",
            "Batch 873/1041, Loss: 0.23941202461719513, Acc: 0.90625\n",
            "Batch 874/1041, Loss: 0.22411592304706573, Acc: 0.9375\n",
            "Batch 875/1041, Loss: 0.24108219146728516, Acc: 0.9375\n",
            "Batch 876/1041, Loss: 0.3552638590335846, Acc: 0.84375\n",
            "Batch 877/1041, Loss: 0.31223323941230774, Acc: 0.875\n",
            "Batch 878/1041, Loss: 0.32027924060821533, Acc: 0.875\n",
            "Batch 879/1041, Loss: 0.36647510528564453, Acc: 0.84375\n",
            "Batch 880/1041, Loss: 0.511438250541687, Acc: 0.75\n",
            "Batch 881/1041, Loss: 0.21110782027244568, Acc: 0.90625\n",
            "Batch 882/1041, Loss: 0.4014543890953064, Acc: 0.8125\n",
            "Batch 883/1041, Loss: 0.32248491048812866, Acc: 0.84375\n",
            "Batch 884/1041, Loss: 0.3658585846424103, Acc: 0.84375\n",
            "Batch 885/1041, Loss: 0.21620914340019226, Acc: 0.9375\n",
            "Batch 886/1041, Loss: 0.3661976754665375, Acc: 0.84375\n",
            "Batch 887/1041, Loss: 0.22074778378009796, Acc: 0.90625\n",
            "Batch 888/1041, Loss: 0.511252224445343, Acc: 0.8125\n",
            "Batch 889/1041, Loss: 0.21211427450180054, Acc: 0.90625\n",
            "Batch 890/1041, Loss: 0.29275834560394287, Acc: 0.875\n",
            "Batch 891/1041, Loss: 0.25653377175331116, Acc: 0.875\n",
            "Batch 892/1041, Loss: 0.29155078530311584, Acc: 0.90625\n",
            "Batch 893/1041, Loss: 0.5041444897651672, Acc: 0.8125\n",
            "Batch 894/1041, Loss: 0.36453863978385925, Acc: 0.8125\n",
            "Batch 895/1041, Loss: 0.3622366189956665, Acc: 0.84375\n",
            "Batch 896/1041, Loss: 0.31333085894584656, Acc: 0.875\n",
            "Batch 897/1041, Loss: 0.2669964134693146, Acc: 0.875\n",
            "Batch 898/1041, Loss: 0.40148109197616577, Acc: 0.8125\n",
            "Batch 899/1041, Loss: 0.3449647128582001, Acc: 0.875\n",
            "Batch 900/1041, Loss: 0.39453649520874023, Acc: 0.875\n",
            "Batch 901/1041, Loss: 0.32039734721183777, Acc: 0.875\n",
            "Batch 902/1041, Loss: 0.27235180139541626, Acc: 0.90625\n",
            "Batch 903/1041, Loss: 0.4963933229446411, Acc: 0.84375\n",
            "Batch 904/1041, Loss: 0.33951520919799805, Acc: 0.84375\n",
            "Batch 905/1041, Loss: 0.34683385491371155, Acc: 0.84375\n",
            "Batch 906/1041, Loss: 0.26713696122169495, Acc: 0.875\n",
            "Batch 907/1041, Loss: 0.3068661093711853, Acc: 0.84375\n",
            "Batch 908/1041, Loss: 0.2909857928752899, Acc: 0.90625\n",
            "Batch 909/1041, Loss: 0.5852784514427185, Acc: 0.78125\n",
            "Batch 910/1041, Loss: 0.47723907232284546, Acc: 0.84375\n",
            "Batch 911/1041, Loss: 0.22199052572250366, Acc: 0.90625\n",
            "Batch 912/1041, Loss: 0.25632044672966003, Acc: 0.90625\n",
            "Batch 913/1041, Loss: 0.2729390561580658, Acc: 0.875\n",
            "Batch 914/1041, Loss: 0.37050577998161316, Acc: 0.8125\n",
            "Batch 915/1041, Loss: 0.4657773971557617, Acc: 0.8125\n",
            "Batch 916/1041, Loss: 0.43781813979148865, Acc: 0.8125\n",
            "Batch 917/1041, Loss: 0.3386717140674591, Acc: 0.78125\n",
            "Batch 918/1041, Loss: 0.4158603549003601, Acc: 0.75\n",
            "Batch 919/1041, Loss: 0.38952401280403137, Acc: 0.875\n",
            "Batch 920/1041, Loss: 0.28275835514068604, Acc: 0.84375\n",
            "Batch 921/1041, Loss: 0.27133750915527344, Acc: 0.875\n",
            "Batch 922/1041, Loss: 0.23145253956317902, Acc: 0.90625\n",
            "Batch 923/1041, Loss: 0.255917489528656, Acc: 0.90625\n",
            "Batch 924/1041, Loss: 0.2741934657096863, Acc: 0.90625\n",
            "Batch 925/1041, Loss: 0.2920212745666504, Acc: 0.875\n",
            "Batch 926/1041, Loss: 0.3883032500743866, Acc: 0.8125\n",
            "Batch 927/1041, Loss: 0.26659801602363586, Acc: 0.875\n",
            "Batch 928/1041, Loss: 0.3360079228878021, Acc: 0.9375\n",
            "Batch 929/1041, Loss: 0.6554485559463501, Acc: 0.65625\n",
            "Batch 930/1041, Loss: 0.5804055333137512, Acc: 0.75\n",
            "Batch 931/1041, Loss: 0.2449491322040558, Acc: 0.90625\n",
            "Batch 932/1041, Loss: 0.2964726686477661, Acc: 0.875\n",
            "Batch 933/1041, Loss: 0.2325105369091034, Acc: 0.875\n",
            "Batch 934/1041, Loss: 0.1928105354309082, Acc: 0.9375\n",
            "Batch 935/1041, Loss: 0.30315980315208435, Acc: 0.8125\n",
            "Batch 936/1041, Loss: 0.33467572927474976, Acc: 0.8125\n",
            "Batch 937/1041, Loss: 0.29320764541625977, Acc: 0.90625\n",
            "Batch 938/1041, Loss: 0.48383089900016785, Acc: 0.71875\n",
            "Batch 939/1041, Loss: 0.5961663722991943, Acc: 0.78125\n",
            "Batch 940/1041, Loss: 0.34784871339797974, Acc: 0.8125\n",
            "Batch 941/1041, Loss: 0.4178530275821686, Acc: 0.8125\n",
            "Batch 942/1041, Loss: 0.24785692989826202, Acc: 0.90625\n",
            "Batch 943/1041, Loss: 0.31209295988082886, Acc: 0.84375\n",
            "Batch 944/1041, Loss: 0.2314053773880005, Acc: 0.90625\n",
            "Batch 945/1041, Loss: 0.38308167457580566, Acc: 0.8125\n",
            "Batch 946/1041, Loss: 0.4092463552951813, Acc: 0.84375\n",
            "Batch 947/1041, Loss: 0.5836640000343323, Acc: 0.71875\n",
            "Batch 948/1041, Loss: 0.37860721349716187, Acc: 0.84375\n",
            "Batch 949/1041, Loss: 0.249583438038826, Acc: 0.9375\n",
            "Batch 950/1041, Loss: 0.4814684987068176, Acc: 0.84375\n",
            "Batch 951/1041, Loss: 0.1679031252861023, Acc: 0.96875\n",
            "Batch 952/1041, Loss: 0.26408901810646057, Acc: 0.90625\n",
            "Batch 953/1041, Loss: 0.3269475996494293, Acc: 0.8125\n",
            "Batch 954/1041, Loss: 0.25761398673057556, Acc: 0.90625\n",
            "Batch 955/1041, Loss: 0.45347097516059875, Acc: 0.8125\n",
            "Batch 956/1041, Loss: 0.23032070696353912, Acc: 0.90625\n",
            "Batch 957/1041, Loss: 0.262883722782135, Acc: 0.9375\n",
            "Batch 958/1041, Loss: 0.5203877091407776, Acc: 0.6875\n",
            "Batch 959/1041, Loss: 0.3198221027851105, Acc: 0.875\n",
            "[Update 2000] Train Loss: 0.3198, Train Acc: 0.8750 | Val Loss: 0.3153, Val Acc: 0.8661\n",
            "Batch 960/1041, Loss: 0.6103014349937439, Acc: 0.78125\n",
            "Batch 961/1041, Loss: 0.39020782709121704, Acc: 0.84375\n",
            "Batch 962/1041, Loss: 0.3836590051651001, Acc: 0.84375\n",
            "Batch 963/1041, Loss: 0.3299817144870758, Acc: 0.84375\n",
            "Batch 964/1041, Loss: 0.41308557987213135, Acc: 0.90625\n",
            "Batch 965/1041, Loss: 0.46361443400382996, Acc: 0.8125\n",
            "Batch 966/1041, Loss: 0.5570511221885681, Acc: 0.78125\n",
            "Batch 967/1041, Loss: 0.24214069545269012, Acc: 0.875\n",
            "Batch 968/1041, Loss: 0.39058318734169006, Acc: 0.78125\n",
            "Batch 969/1041, Loss: 0.29248329997062683, Acc: 0.90625\n",
            "Batch 970/1041, Loss: 0.2537803649902344, Acc: 0.90625\n",
            "Batch 971/1041, Loss: 0.5341458916664124, Acc: 0.75\n",
            "Batch 972/1041, Loss: 0.39700135588645935, Acc: 0.78125\n",
            "Batch 973/1041, Loss: 0.26592645049095154, Acc: 0.875\n",
            "Batch 974/1041, Loss: 0.40835732221603394, Acc: 0.75\n",
            "Batch 975/1041, Loss: 0.5075584053993225, Acc: 0.78125\n",
            "Batch 976/1041, Loss: 0.23146465420722961, Acc: 0.90625\n",
            "Batch 977/1041, Loss: 0.18571537733078003, Acc: 1.0\n",
            "Batch 978/1041, Loss: 0.3081858158111572, Acc: 0.84375\n",
            "Batch 979/1041, Loss: 0.2677474021911621, Acc: 0.875\n",
            "Batch 980/1041, Loss: 0.46573615074157715, Acc: 0.78125\n",
            "Batch 981/1041, Loss: 0.27602511644363403, Acc: 0.875\n",
            "Batch 982/1041, Loss: 0.3174564242362976, Acc: 0.90625\n",
            "Batch 983/1041, Loss: 0.47011131048202515, Acc: 0.78125\n",
            "Batch 984/1041, Loss: 0.3868243992328644, Acc: 0.84375\n",
            "Batch 985/1041, Loss: 0.1885751485824585, Acc: 0.9375\n",
            "Batch 986/1041, Loss: 0.3724876344203949, Acc: 0.875\n",
            "Batch 987/1041, Loss: 0.36908090114593506, Acc: 0.84375\n",
            "Batch 988/1041, Loss: 0.34778207540512085, Acc: 0.84375\n",
            "Batch 989/1041, Loss: 0.3009721338748932, Acc: 0.84375\n",
            "Batch 990/1041, Loss: 0.34548279643058777, Acc: 0.78125\n",
            "Batch 991/1041, Loss: 0.35420888662338257, Acc: 0.875\n",
            "Batch 992/1041, Loss: 0.29503217339515686, Acc: 0.875\n",
            "Batch 993/1041, Loss: 0.23008984327316284, Acc: 0.9375\n",
            "Batch 994/1041, Loss: 0.347024530172348, Acc: 0.84375\n",
            "Batch 995/1041, Loss: 0.3322862684726715, Acc: 0.78125\n",
            "Batch 996/1041, Loss: 0.4520832896232605, Acc: 0.84375\n",
            "Batch 997/1041, Loss: 0.45080479979515076, Acc: 0.84375\n",
            "Batch 998/1041, Loss: 0.3396422266960144, Acc: 0.8125\n",
            "Batch 999/1041, Loss: 0.35032594203948975, Acc: 0.84375\n",
            "Batch 1000/1041, Loss: 0.25002041459083557, Acc: 0.96875\n",
            "Batch 1001/1041, Loss: 0.4693669080734253, Acc: 0.78125\n",
            "Batch 1002/1041, Loss: 0.2691168487071991, Acc: 0.84375\n",
            "Batch 1003/1041, Loss: 0.4800907373428345, Acc: 0.84375\n",
            "Batch 1004/1041, Loss: 0.2509355843067169, Acc: 0.9375\n",
            "Batch 1005/1041, Loss: 0.2920996844768524, Acc: 0.875\n",
            "Batch 1006/1041, Loss: 0.2759203016757965, Acc: 0.875\n",
            "Batch 1007/1041, Loss: 0.20772229135036469, Acc: 0.90625\n",
            "Batch 1008/1041, Loss: 0.38363897800445557, Acc: 0.84375\n",
            "Batch 1009/1041, Loss: 0.21921215951442719, Acc: 0.90625\n",
            "Batch 1010/1041, Loss: 0.3098164498806, Acc: 0.84375\n",
            "Batch 1011/1041, Loss: 0.3318418562412262, Acc: 0.84375\n",
            "Batch 1012/1041, Loss: 0.3176557719707489, Acc: 0.84375\n",
            "Batch 1013/1041, Loss: 0.26651909947395325, Acc: 0.875\n",
            "Batch 1014/1041, Loss: 0.33639198541641235, Acc: 0.84375\n",
            "Batch 1015/1041, Loss: 0.6514432430267334, Acc: 0.71875\n",
            "Batch 1016/1041, Loss: 0.3449136018753052, Acc: 0.875\n",
            "Batch 1017/1041, Loss: 0.517152726650238, Acc: 0.78125\n",
            "Batch 1018/1041, Loss: 0.2995538115501404, Acc: 0.875\n",
            "Batch 1019/1041, Loss: 0.3626744747161865, Acc: 0.78125\n",
            "Batch 1020/1041, Loss: 0.3549697697162628, Acc: 0.78125\n",
            "Batch 1021/1041, Loss: 0.4123344421386719, Acc: 0.84375\n",
            "Batch 1022/1041, Loss: 0.15913377702236176, Acc: 0.96875\n",
            "Batch 1023/1041, Loss: 0.427887886762619, Acc: 0.84375\n",
            "Batch 1024/1041, Loss: 0.2427607923746109, Acc: 0.90625\n",
            "Batch 1025/1041, Loss: 0.3014860451221466, Acc: 0.875\n",
            "Batch 1026/1041, Loss: 0.243875190615654, Acc: 0.875\n",
            "Batch 1027/1041, Loss: 0.3423632085323334, Acc: 0.84375\n",
            "Batch 1028/1041, Loss: 0.24793396890163422, Acc: 0.90625\n",
            "Batch 1029/1041, Loss: 0.23209069669246674, Acc: 0.90625\n",
            "Batch 1030/1041, Loss: 0.31046560406684875, Acc: 0.84375\n",
            "Batch 1031/1041, Loss: 0.24727389216423035, Acc: 0.90625\n",
            "Batch 1032/1041, Loss: 0.27544793486595154, Acc: 0.9375\n",
            "Batch 1033/1041, Loss: 0.4068872928619385, Acc: 0.8125\n",
            "Batch 1034/1041, Loss: 0.19628944993019104, Acc: 0.9375\n",
            "Batch 1035/1041, Loss: 0.4621075391769409, Acc: 0.78125\n",
            "Batch 1036/1041, Loss: 0.35401663184165955, Acc: 0.8125\n",
            "Batch 1037/1041, Loss: 0.572253406047821, Acc: 0.6875\n",
            "Batch 1038/1041, Loss: 0.3265819847583771, Acc: 0.8125\n",
            "Batch 1039/1041, Loss: 0.21925655007362366, Acc: 0.875\n",
            "Batch 1040/1041, Loss: 0.26290661096572876, Acc: 0.90625\n",
            "Batch 1041/1041, Loss: 0.37610235810279846, Acc: 0.782608695652174\n",
            "Epoch 3/3\n",
            "----------\n",
            "Batch 1/1041, Loss: 0.32989057898521423, Acc: 0.875\n",
            "Batch 2/1041, Loss: 0.24335630238056183, Acc: 0.875\n",
            "Batch 3/1041, Loss: 0.2693295478820801, Acc: 0.84375\n",
            "Batch 4/1041, Loss: 0.3524174690246582, Acc: 0.84375\n",
            "Batch 5/1041, Loss: 0.45467403531074524, Acc: 0.71875\n",
            "Batch 6/1041, Loss: 0.33083707094192505, Acc: 0.875\n",
            "Batch 7/1041, Loss: 0.1952810436487198, Acc: 0.96875\n",
            "Batch 8/1041, Loss: 0.3453347086906433, Acc: 0.875\n",
            "Batch 9/1041, Loss: 0.25505369901657104, Acc: 0.90625\n",
            "Batch 10/1041, Loss: 0.24404527246952057, Acc: 0.90625\n",
            "Batch 11/1041, Loss: 0.2909589409828186, Acc: 0.9375\n",
            "Batch 12/1041, Loss: 0.16998884081840515, Acc: 0.9375\n",
            "Batch 13/1041, Loss: 0.20730134844779968, Acc: 0.96875\n",
            "Batch 14/1041, Loss: 0.20987755060195923, Acc: 0.90625\n",
            "Batch 15/1041, Loss: 0.3056517541408539, Acc: 0.875\n",
            "Batch 16/1041, Loss: 0.33278703689575195, Acc: 0.875\n",
            "Batch 17/1041, Loss: 0.3125191926956177, Acc: 0.9375\n",
            "Batch 18/1041, Loss: 0.2633554935455322, Acc: 0.9375\n",
            "[Update 2100] Train Loss: 0.2634, Train Acc: 0.9375 | Val Loss: 0.3130, Val Acc: 0.8663\n",
            "Batch 19/1041, Loss: 0.324020653963089, Acc: 0.8125\n",
            "Batch 20/1041, Loss: 0.35629966855049133, Acc: 0.8125\n",
            "Batch 21/1041, Loss: 0.37733447551727295, Acc: 0.8125\n",
            "Batch 22/1041, Loss: 0.3626396656036377, Acc: 0.78125\n",
            "Batch 23/1041, Loss: 0.1737734079360962, Acc: 0.9375\n",
            "Batch 24/1041, Loss: 0.468110054731369, Acc: 0.84375\n",
            "Batch 25/1041, Loss: 0.42946091294288635, Acc: 0.8125\n",
            "Batch 26/1041, Loss: 0.23351646959781647, Acc: 0.90625\n",
            "Batch 27/1041, Loss: 0.21203109622001648, Acc: 0.90625\n",
            "Batch 28/1041, Loss: 0.3448222875595093, Acc: 0.84375\n",
            "Batch 29/1041, Loss: 0.3123292326927185, Acc: 0.875\n",
            "Batch 30/1041, Loss: 0.4715518057346344, Acc: 0.84375\n",
            "Batch 31/1041, Loss: 0.2349347621202469, Acc: 0.90625\n",
            "Batch 32/1041, Loss: 0.24618621170520782, Acc: 0.875\n",
            "Batch 33/1041, Loss: 0.30345797538757324, Acc: 0.90625\n",
            "Batch 34/1041, Loss: 0.2581591010093689, Acc: 0.90625\n",
            "Batch 35/1041, Loss: 0.28226879239082336, Acc: 0.875\n",
            "Batch 36/1041, Loss: 0.20389583706855774, Acc: 0.90625\n",
            "Batch 37/1041, Loss: 0.4987475872039795, Acc: 0.84375\n",
            "Batch 38/1041, Loss: 0.1673153191804886, Acc: 0.9375\n",
            "Batch 39/1041, Loss: 0.32104676961898804, Acc: 0.875\n",
            "Batch 40/1041, Loss: 0.2605811357498169, Acc: 0.90625\n",
            "Batch 41/1041, Loss: 0.2027137577533722, Acc: 0.9375\n",
            "Batch 42/1041, Loss: 0.3521636128425598, Acc: 0.78125\n",
            "Batch 43/1041, Loss: 0.32134485244750977, Acc: 0.875\n",
            "Batch 44/1041, Loss: 0.321600079536438, Acc: 0.9375\n",
            "Batch 45/1041, Loss: 0.38378721475601196, Acc: 0.84375\n",
            "Batch 46/1041, Loss: 0.25917986035346985, Acc: 0.875\n",
            "Batch 47/1041, Loss: 0.3056459426879883, Acc: 0.84375\n",
            "Batch 48/1041, Loss: 0.29863762855529785, Acc: 0.875\n",
            "Batch 49/1041, Loss: 0.1682031750679016, Acc: 0.90625\n",
            "Batch 50/1041, Loss: 0.3104563057422638, Acc: 0.84375\n",
            "Batch 51/1041, Loss: 0.25313642621040344, Acc: 0.875\n",
            "Batch 52/1041, Loss: 0.17706748843193054, Acc: 0.96875\n",
            "Batch 53/1041, Loss: 0.356023371219635, Acc: 0.78125\n",
            "Batch 54/1041, Loss: 0.3721422553062439, Acc: 0.8125\n",
            "Batch 55/1041, Loss: 0.36477982997894287, Acc: 0.84375\n",
            "Batch 56/1041, Loss: 0.2538093626499176, Acc: 0.90625\n",
            "Batch 57/1041, Loss: 0.2888883054256439, Acc: 0.875\n",
            "Batch 58/1041, Loss: 0.15608152747154236, Acc: 0.96875\n",
            "Batch 59/1041, Loss: 0.4752746820449829, Acc: 0.84375\n",
            "Batch 60/1041, Loss: 0.48340439796447754, Acc: 0.78125\n",
            "Batch 61/1041, Loss: 0.35647910833358765, Acc: 0.90625\n",
            "Batch 62/1041, Loss: 0.19140666723251343, Acc: 0.9375\n",
            "Batch 63/1041, Loss: 0.4395010769367218, Acc: 0.75\n",
            "Batch 64/1041, Loss: 0.3108097016811371, Acc: 0.84375\n",
            "Batch 65/1041, Loss: 0.26947277784347534, Acc: 0.9375\n",
            "Batch 66/1041, Loss: 0.15720082819461823, Acc: 0.96875\n",
            "Batch 67/1041, Loss: 0.37665706872940063, Acc: 0.84375\n",
            "Batch 68/1041, Loss: 0.2112577110528946, Acc: 0.9375\n",
            "Batch 69/1041, Loss: 0.31008222699165344, Acc: 0.875\n",
            "Batch 70/1041, Loss: 0.2797115445137024, Acc: 0.875\n",
            "Batch 71/1041, Loss: 0.384237140417099, Acc: 0.84375\n",
            "Batch 72/1041, Loss: 0.2107953280210495, Acc: 0.9375\n",
            "Batch 73/1041, Loss: 0.2609082758426666, Acc: 0.90625\n",
            "Batch 74/1041, Loss: 0.1847119778394699, Acc: 0.90625\n",
            "Batch 75/1041, Loss: 0.4257182776927948, Acc: 0.875\n",
            "Batch 76/1041, Loss: 0.3542879521846771, Acc: 0.84375\n",
            "Batch 77/1041, Loss: 0.37951359152793884, Acc: 0.84375\n",
            "Batch 78/1041, Loss: 0.21005253493785858, Acc: 0.9375\n",
            "Batch 79/1041, Loss: 0.4549948573112488, Acc: 0.78125\n",
            "Batch 80/1041, Loss: 0.3912903964519501, Acc: 0.78125\n",
            "Batch 81/1041, Loss: 0.32404232025146484, Acc: 0.875\n",
            "Batch 82/1041, Loss: 0.2396823912858963, Acc: 0.875\n",
            "Batch 83/1041, Loss: 0.370034784078598, Acc: 0.8125\n",
            "Batch 84/1041, Loss: 0.26507368683815, Acc: 0.90625\n",
            "Batch 85/1041, Loss: 0.3406495153903961, Acc: 0.84375\n",
            "Batch 86/1041, Loss: 0.3462193012237549, Acc: 0.84375\n",
            "Batch 87/1041, Loss: 0.20155787467956543, Acc: 0.875\n",
            "Batch 88/1041, Loss: 0.16558054089546204, Acc: 0.96875\n",
            "Batch 89/1041, Loss: 0.2562806308269501, Acc: 0.90625\n",
            "Batch 90/1041, Loss: 0.26749947667121887, Acc: 0.875\n",
            "Batch 91/1041, Loss: 0.2774769961833954, Acc: 0.875\n",
            "Batch 92/1041, Loss: 0.40212559700012207, Acc: 0.75\n",
            "Batch 93/1041, Loss: 0.29031404852867126, Acc: 0.8125\n",
            "Batch 94/1041, Loss: 0.3739951252937317, Acc: 0.84375\n",
            "Batch 95/1041, Loss: 0.3676077425479889, Acc: 0.78125\n",
            "Batch 96/1041, Loss: 0.5192082524299622, Acc: 0.8125\n",
            "Batch 97/1041, Loss: 0.1409849375486374, Acc: 0.96875\n",
            "Batch 98/1041, Loss: 0.29094198346138, Acc: 0.875\n",
            "Batch 99/1041, Loss: 0.34696394205093384, Acc: 0.78125\n",
            "Batch 100/1041, Loss: 0.310417503118515, Acc: 0.84375\n",
            "Batch 101/1041, Loss: 0.302449107170105, Acc: 0.84375\n",
            "Batch 102/1041, Loss: 0.5316480398178101, Acc: 0.6875\n",
            "Batch 103/1041, Loss: 0.2266211062669754, Acc: 0.875\n",
            "Batch 104/1041, Loss: 0.3486676812171936, Acc: 0.84375\n",
            "Batch 105/1041, Loss: 0.313102126121521, Acc: 0.8125\n",
            "Batch 106/1041, Loss: 0.21156875789165497, Acc: 0.90625\n",
            "Batch 107/1041, Loss: 0.2509515583515167, Acc: 0.84375\n",
            "Batch 108/1041, Loss: 0.2084989696741104, Acc: 0.9375\n",
            "Batch 109/1041, Loss: 0.3451593220233917, Acc: 0.84375\n",
            "Batch 110/1041, Loss: 0.3090260624885559, Acc: 0.90625\n",
            "Batch 111/1041, Loss: 0.2939281165599823, Acc: 0.875\n",
            "Batch 112/1041, Loss: 0.19539807736873627, Acc: 0.9375\n",
            "Batch 113/1041, Loss: 0.46427303552627563, Acc: 0.6875\n",
            "Batch 114/1041, Loss: 0.11201541870832443, Acc: 1.0\n",
            "Batch 115/1041, Loss: 0.3800961375236511, Acc: 0.875\n",
            "Batch 116/1041, Loss: 0.3071540892124176, Acc: 0.875\n",
            "Batch 117/1041, Loss: 0.2954029440879822, Acc: 0.84375\n",
            "Batch 118/1041, Loss: 0.31280696392059326, Acc: 0.8125\n",
            "[Update 2200] Train Loss: 0.3128, Train Acc: 0.8125 | Val Loss: 0.3188, Val Acc: 0.8687\n",
            "Batch 119/1041, Loss: 0.12226291745901108, Acc: 1.0\n",
            "Batch 120/1041, Loss: 0.3144040107727051, Acc: 0.84375\n",
            "Batch 121/1041, Loss: 0.356014221906662, Acc: 0.8125\n",
            "Batch 122/1041, Loss: 0.1328699141740799, Acc: 0.96875\n",
            "Batch 123/1041, Loss: 0.33275917172431946, Acc: 0.875\n",
            "Batch 124/1041, Loss: 0.2568039298057556, Acc: 0.90625\n",
            "Batch 125/1041, Loss: 0.24020837247371674, Acc: 0.90625\n",
            "Batch 126/1041, Loss: 0.1515636146068573, Acc: 0.96875\n",
            "Batch 127/1041, Loss: 0.2560097575187683, Acc: 0.9375\n",
            "Batch 128/1041, Loss: 0.244425967335701, Acc: 0.90625\n",
            "Batch 129/1041, Loss: 0.4828090965747833, Acc: 0.78125\n",
            "Batch 130/1041, Loss: 0.5076290965080261, Acc: 0.8125\n",
            "Batch 131/1041, Loss: 0.24808742105960846, Acc: 0.90625\n",
            "Batch 132/1041, Loss: 0.35390931367874146, Acc: 0.8125\n",
            "Batch 133/1041, Loss: 0.3793349862098694, Acc: 0.84375\n",
            "Batch 134/1041, Loss: 0.2622084319591522, Acc: 0.84375\n",
            "Batch 135/1041, Loss: 0.2801462411880493, Acc: 0.90625\n",
            "Batch 136/1041, Loss: 0.30812373757362366, Acc: 0.90625\n",
            "Batch 137/1041, Loss: 0.2418822944164276, Acc: 0.90625\n",
            "Batch 138/1041, Loss: 0.3805082142353058, Acc: 0.78125\n",
            "Batch 139/1041, Loss: 0.25852859020233154, Acc: 0.90625\n",
            "Batch 140/1041, Loss: 0.3107159733772278, Acc: 0.84375\n",
            "Batch 141/1041, Loss: 0.3502757251262665, Acc: 0.8125\n",
            "Batch 142/1041, Loss: 0.2439371943473816, Acc: 0.875\n",
            "Batch 143/1041, Loss: 0.34344062209129333, Acc: 0.8125\n",
            "Batch 144/1041, Loss: 0.30127084255218506, Acc: 0.84375\n",
            "Batch 145/1041, Loss: 0.1689445525407791, Acc: 0.9375\n",
            "Batch 146/1041, Loss: 0.22105564177036285, Acc: 0.90625\n",
            "Batch 147/1041, Loss: 0.4177643060684204, Acc: 0.8125\n",
            "Batch 148/1041, Loss: 0.2905530333518982, Acc: 0.875\n",
            "Batch 149/1041, Loss: 0.20398201048374176, Acc: 0.90625\n",
            "Batch 150/1041, Loss: 0.34459760785102844, Acc: 0.84375\n",
            "Batch 151/1041, Loss: 0.4964028298854828, Acc: 0.78125\n",
            "Batch 152/1041, Loss: 0.3532998263835907, Acc: 0.84375\n",
            "Batch 153/1041, Loss: 0.27910226583480835, Acc: 0.84375\n",
            "Batch 154/1041, Loss: 0.22577719390392303, Acc: 0.875\n",
            "Batch 155/1041, Loss: 0.3020200729370117, Acc: 0.90625\n",
            "Batch 156/1041, Loss: 0.3774106800556183, Acc: 0.8125\n",
            "Batch 157/1041, Loss: 0.28583240509033203, Acc: 0.90625\n",
            "Batch 158/1041, Loss: 0.3275197446346283, Acc: 0.78125\n",
            "Batch 159/1041, Loss: 0.4109600782394409, Acc: 0.75\n",
            "Batch 160/1041, Loss: 0.3042326271533966, Acc: 0.875\n",
            "Batch 161/1041, Loss: 0.14922043681144714, Acc: 0.9375\n",
            "Batch 162/1041, Loss: 0.15013347566127777, Acc: 0.96875\n",
            "Batch 163/1041, Loss: 0.32367756962776184, Acc: 0.875\n",
            "Batch 164/1041, Loss: 0.27249449491500854, Acc: 0.875\n",
            "Batch 165/1041, Loss: 0.36103060841560364, Acc: 0.875\n",
            "Batch 166/1041, Loss: 0.19712217152118683, Acc: 0.9375\n",
            "Batch 167/1041, Loss: 0.31112879514694214, Acc: 0.84375\n",
            "Batch 168/1041, Loss: 0.28022974729537964, Acc: 0.90625\n",
            "Batch 169/1041, Loss: 0.3971879780292511, Acc: 0.84375\n",
            "Batch 170/1041, Loss: 0.18355949223041534, Acc: 0.9375\n",
            "Batch 171/1041, Loss: 0.22045984864234924, Acc: 0.90625\n",
            "Batch 172/1041, Loss: 0.5068942308425903, Acc: 0.78125\n",
            "Batch 173/1041, Loss: 0.41489577293395996, Acc: 0.84375\n",
            "Batch 174/1041, Loss: 0.320309042930603, Acc: 0.8125\n",
            "Batch 175/1041, Loss: 0.34010446071624756, Acc: 0.84375\n",
            "Batch 176/1041, Loss: 0.31371936202049255, Acc: 0.84375\n",
            "Batch 177/1041, Loss: 0.3000348210334778, Acc: 0.8125\n",
            "Batch 178/1041, Loss: 0.45914480090141296, Acc: 0.8125\n",
            "Batch 179/1041, Loss: 0.28451409935951233, Acc: 0.875\n",
            "Batch 180/1041, Loss: 0.36400124430656433, Acc: 0.8125\n",
            "Batch 181/1041, Loss: 0.18983621895313263, Acc: 0.90625\n",
            "Batch 182/1041, Loss: 0.3383115231990814, Acc: 0.84375\n",
            "Batch 183/1041, Loss: 0.4793219566345215, Acc: 0.78125\n",
            "Batch 184/1041, Loss: 0.27307239174842834, Acc: 0.84375\n",
            "Batch 185/1041, Loss: 0.26372039318084717, Acc: 0.9375\n",
            "Batch 186/1041, Loss: 0.22918781638145447, Acc: 0.90625\n",
            "Batch 187/1041, Loss: 0.386956125497818, Acc: 0.8125\n",
            "Batch 188/1041, Loss: 0.3904615640640259, Acc: 0.84375\n",
            "Batch 189/1041, Loss: 0.2802780270576477, Acc: 0.90625\n",
            "Batch 190/1041, Loss: 0.3363627791404724, Acc: 0.90625\n",
            "Batch 191/1041, Loss: 0.35546258091926575, Acc: 0.8125\n",
            "Batch 192/1041, Loss: 0.3730166256427765, Acc: 0.84375\n",
            "Batch 193/1041, Loss: 0.1430395543575287, Acc: 0.9375\n",
            "Batch 194/1041, Loss: 0.2016407698392868, Acc: 0.90625\n",
            "Batch 195/1041, Loss: 0.3634859323501587, Acc: 0.8125\n",
            "Batch 196/1041, Loss: 0.27003002166748047, Acc: 0.9375\n",
            "Batch 197/1041, Loss: 0.26518353819847107, Acc: 0.9375\n",
            "Batch 198/1041, Loss: 0.3201105296611786, Acc: 0.8125\n",
            "Batch 199/1041, Loss: 0.3606855273246765, Acc: 0.875\n",
            "Batch 200/1041, Loss: 0.2621038556098938, Acc: 0.875\n",
            "Batch 201/1041, Loss: 0.3476022183895111, Acc: 0.84375\n",
            "Batch 202/1041, Loss: 0.40032604336738586, Acc: 0.875\n",
            "Batch 203/1041, Loss: 0.41740256547927856, Acc: 0.78125\n",
            "Batch 204/1041, Loss: 0.3066491186618805, Acc: 0.875\n",
            "Batch 205/1041, Loss: 0.39689698815345764, Acc: 0.8125\n",
            "Batch 206/1041, Loss: 0.1785866767168045, Acc: 0.9375\n",
            "Batch 207/1041, Loss: 0.2522938847541809, Acc: 0.9375\n",
            "Batch 208/1041, Loss: 0.24399684369564056, Acc: 0.90625\n",
            "Batch 209/1041, Loss: 0.18181365728378296, Acc: 0.9375\n",
            "Batch 210/1041, Loss: 0.269119530916214, Acc: 0.84375\n",
            "Batch 211/1041, Loss: 0.32835543155670166, Acc: 0.875\n",
            "Batch 212/1041, Loss: 0.24281767010688782, Acc: 0.875\n",
            "Batch 213/1041, Loss: 0.24707019329071045, Acc: 0.9375\n",
            "Batch 214/1041, Loss: 0.3907093405723572, Acc: 0.875\n",
            "Batch 215/1041, Loss: 0.4419856667518616, Acc: 0.75\n",
            "Batch 216/1041, Loss: 0.32282841205596924, Acc: 0.84375\n",
            "Batch 217/1041, Loss: 0.3654167354106903, Acc: 0.8125\n",
            "Batch 218/1041, Loss: 0.1607154756784439, Acc: 0.96875\n",
            "[Update 2300] Train Loss: 0.1607, Train Acc: 0.9688 | Val Loss: 0.3250, Val Acc: 0.8673\n",
            "Batch 219/1041, Loss: 0.33869045972824097, Acc: 0.875\n",
            "Batch 220/1041, Loss: 0.3045319616794586, Acc: 0.875\n",
            "Batch 221/1041, Loss: 0.5483103394508362, Acc: 0.71875\n",
            "Batch 222/1041, Loss: 0.23837868869304657, Acc: 0.90625\n",
            "Batch 223/1041, Loss: 0.25347769260406494, Acc: 0.9375\n",
            "Batch 224/1041, Loss: 0.21862241625785828, Acc: 0.875\n",
            "Batch 225/1041, Loss: 0.417295902967453, Acc: 0.84375\n",
            "Batch 226/1041, Loss: 0.2003544718027115, Acc: 0.9375\n",
            "Batch 227/1041, Loss: 0.3038492202758789, Acc: 0.90625\n",
            "Batch 228/1041, Loss: 0.21685269474983215, Acc: 0.9375\n",
            "Batch 229/1041, Loss: 0.26843056082725525, Acc: 0.875\n",
            "Batch 230/1041, Loss: 0.3062826693058014, Acc: 0.8125\n",
            "Batch 231/1041, Loss: 0.41671624779701233, Acc: 0.84375\n",
            "Batch 232/1041, Loss: 0.14949363470077515, Acc: 0.96875\n",
            "Batch 233/1041, Loss: 0.4131081700325012, Acc: 0.8125\n",
            "Batch 234/1041, Loss: 0.5226541757583618, Acc: 0.8125\n",
            "Batch 235/1041, Loss: 0.35280728340148926, Acc: 0.84375\n",
            "Batch 236/1041, Loss: 0.31041276454925537, Acc: 0.875\n",
            "Batch 237/1041, Loss: 0.31129616498947144, Acc: 0.84375\n",
            "Batch 238/1041, Loss: 0.41069450974464417, Acc: 0.75\n",
            "Batch 239/1041, Loss: 0.3240986466407776, Acc: 0.78125\n",
            "Batch 240/1041, Loss: 0.29451918601989746, Acc: 0.84375\n",
            "Batch 241/1041, Loss: 0.21250855922698975, Acc: 0.90625\n",
            "Batch 242/1041, Loss: 0.3380618095397949, Acc: 0.84375\n",
            "Batch 243/1041, Loss: 0.21891070902347565, Acc: 0.875\n",
            "Batch 244/1041, Loss: 0.2901304066181183, Acc: 0.90625\n",
            "Batch 245/1041, Loss: 0.25878584384918213, Acc: 0.875\n",
            "Batch 246/1041, Loss: 0.2890741229057312, Acc: 0.875\n",
            "Batch 247/1041, Loss: 0.48816055059432983, Acc: 0.8125\n",
            "Batch 248/1041, Loss: 0.3399810194969177, Acc: 0.90625\n",
            "Batch 249/1041, Loss: 0.215425506234169, Acc: 0.9375\n",
            "Batch 250/1041, Loss: 0.38410770893096924, Acc: 0.8125\n",
            "Batch 251/1041, Loss: 0.3777739703655243, Acc: 0.84375\n",
            "Batch 252/1041, Loss: 0.29250726103782654, Acc: 0.90625\n",
            "Batch 253/1041, Loss: 0.45708510279655457, Acc: 0.84375\n",
            "Batch 254/1041, Loss: 0.4458164572715759, Acc: 0.71875\n",
            "Batch 255/1041, Loss: 0.3369118273258209, Acc: 0.875\n",
            "Batch 256/1041, Loss: 0.24328286945819855, Acc: 0.875\n",
            "Batch 257/1041, Loss: 0.24589231610298157, Acc: 0.875\n",
            "Batch 258/1041, Loss: 0.16615600883960724, Acc: 0.9375\n",
            "Batch 259/1041, Loss: 0.350399374961853, Acc: 0.875\n",
            "Batch 260/1041, Loss: 0.26646533608436584, Acc: 0.90625\n",
            "Batch 261/1041, Loss: 0.36453020572662354, Acc: 0.9375\n",
            "Batch 262/1041, Loss: 0.25095245242118835, Acc: 0.875\n",
            "Batch 263/1041, Loss: 0.22666366398334503, Acc: 0.875\n",
            "Batch 264/1041, Loss: 0.23050810396671295, Acc: 0.9375\n",
            "Batch 265/1041, Loss: 0.16892607510089874, Acc: 1.0\n",
            "Batch 266/1041, Loss: 0.2457365095615387, Acc: 0.875\n",
            "Batch 267/1041, Loss: 0.34262168407440186, Acc: 0.875\n",
            "Batch 268/1041, Loss: 0.30479007959365845, Acc: 0.875\n",
            "Batch 269/1041, Loss: 0.2764018177986145, Acc: 0.875\n",
            "Batch 270/1041, Loss: 0.37642401456832886, Acc: 0.84375\n",
            "Batch 271/1041, Loss: 0.25299131870269775, Acc: 0.875\n",
            "Batch 272/1041, Loss: 0.36023181676864624, Acc: 0.84375\n",
            "Batch 273/1041, Loss: 0.30570369958877563, Acc: 0.90625\n",
            "Batch 274/1041, Loss: 0.2120540738105774, Acc: 0.90625\n",
            "Batch 275/1041, Loss: 0.3177807033061981, Acc: 0.78125\n",
            "Batch 276/1041, Loss: 0.45988741517066956, Acc: 0.8125\n",
            "Batch 277/1041, Loss: 0.3464757204055786, Acc: 0.8125\n",
            "Batch 278/1041, Loss: 0.3011966347694397, Acc: 0.90625\n",
            "Batch 279/1041, Loss: 0.40947192907333374, Acc: 0.8125\n",
            "Batch 280/1041, Loss: 0.38569262623786926, Acc: 0.875\n",
            "Batch 281/1041, Loss: 0.2114880084991455, Acc: 0.90625\n",
            "Batch 282/1041, Loss: 0.30824366211891174, Acc: 0.84375\n",
            "Batch 283/1041, Loss: 0.18507935106754303, Acc: 0.9375\n",
            "Batch 284/1041, Loss: 0.5250656604766846, Acc: 0.71875\n",
            "Batch 285/1041, Loss: 0.2944873571395874, Acc: 0.875\n",
            "Batch 286/1041, Loss: 0.31649550795555115, Acc: 0.84375\n",
            "Batch 287/1041, Loss: 0.22078286111354828, Acc: 0.90625\n",
            "Batch 288/1041, Loss: 0.2033635675907135, Acc: 0.90625\n",
            "Batch 289/1041, Loss: 0.5031582117080688, Acc: 0.8125\n",
            "Batch 290/1041, Loss: 0.305230975151062, Acc: 0.875\n",
            "Batch 291/1041, Loss: 0.3663533926010132, Acc: 0.84375\n",
            "Batch 292/1041, Loss: 0.21474139392375946, Acc: 0.9375\n",
            "Batch 293/1041, Loss: 0.42331674695014954, Acc: 0.84375\n",
            "Batch 294/1041, Loss: 0.24936628341674805, Acc: 0.875\n",
            "Batch 295/1041, Loss: 0.25585630536079407, Acc: 0.875\n",
            "Batch 296/1041, Loss: 0.36081230640411377, Acc: 0.84375\n",
            "Batch 297/1041, Loss: 0.4074670076370239, Acc: 0.78125\n",
            "Batch 298/1041, Loss: 0.2044767141342163, Acc: 0.9375\n",
            "Batch 299/1041, Loss: 0.20542562007904053, Acc: 0.875\n",
            "Batch 300/1041, Loss: 0.25891444087028503, Acc: 0.875\n",
            "Batch 301/1041, Loss: 0.2530190944671631, Acc: 0.90625\n",
            "Batch 302/1041, Loss: 0.5516763925552368, Acc: 0.75\n",
            "Batch 303/1041, Loss: 0.324588805437088, Acc: 0.84375\n",
            "Batch 304/1041, Loss: 0.30884355306625366, Acc: 0.84375\n",
            "Batch 305/1041, Loss: 0.1840352863073349, Acc: 0.90625\n",
            "Batch 306/1041, Loss: 0.273120641708374, Acc: 0.90625\n",
            "Batch 307/1041, Loss: 0.23843005299568176, Acc: 0.90625\n",
            "Batch 308/1041, Loss: 0.2523256838321686, Acc: 0.90625\n",
            "Batch 309/1041, Loss: 0.3196278512477875, Acc: 0.8125\n",
            "Batch 310/1041, Loss: 0.19267502427101135, Acc: 0.9375\n",
            "Batch 311/1041, Loss: 0.25096437335014343, Acc: 0.90625\n",
            "Batch 312/1041, Loss: 0.2923390865325928, Acc: 0.90625\n",
            "Batch 313/1041, Loss: 0.4266206622123718, Acc: 0.75\n",
            "Batch 314/1041, Loss: 0.3577662706375122, Acc: 0.84375\n",
            "Batch 315/1041, Loss: 0.27293646335601807, Acc: 0.875\n",
            "Batch 316/1041, Loss: 0.2315933257341385, Acc: 0.875\n",
            "Batch 317/1041, Loss: 0.3222743570804596, Acc: 0.84375\n",
            "Batch 318/1041, Loss: 0.32284557819366455, Acc: 0.8125\n",
            "[Update 2400] Train Loss: 0.3228, Train Acc: 0.8125 | Val Loss: 0.3110, Val Acc: 0.8735\n",
            "Batch 319/1041, Loss: 0.4900566041469574, Acc: 0.78125\n",
            "Batch 320/1041, Loss: 0.2699587345123291, Acc: 0.875\n",
            "Batch 321/1041, Loss: 0.21072174608707428, Acc: 0.9375\n",
            "Batch 322/1041, Loss: 0.262228399515152, Acc: 0.90625\n",
            "Batch 323/1041, Loss: 0.33561575412750244, Acc: 0.84375\n",
            "Batch 324/1041, Loss: 0.21503955125808716, Acc: 0.90625\n",
            "Batch 325/1041, Loss: 0.4148104786872864, Acc: 0.84375\n",
            "Batch 326/1041, Loss: 0.22697143256664276, Acc: 0.9375\n",
            "Batch 327/1041, Loss: 0.3455612361431122, Acc: 0.875\n",
            "Batch 328/1041, Loss: 0.18441402912139893, Acc: 0.9375\n",
            "Batch 329/1041, Loss: 0.261736124753952, Acc: 0.875\n",
            "Batch 330/1041, Loss: 0.11907005310058594, Acc: 0.96875\n",
            "Batch 331/1041, Loss: 0.28463849425315857, Acc: 0.9375\n",
            "Batch 332/1041, Loss: 0.2595112919807434, Acc: 0.875\n",
            "Batch 333/1041, Loss: 0.15048180520534515, Acc: 0.96875\n",
            "Batch 334/1041, Loss: 0.238520547747612, Acc: 0.96875\n",
            "Batch 335/1041, Loss: 0.32465365529060364, Acc: 0.90625\n",
            "Batch 336/1041, Loss: 0.3910272419452667, Acc: 0.78125\n",
            "Batch 337/1041, Loss: 0.2945287823677063, Acc: 0.875\n",
            "Batch 338/1041, Loss: 0.18897727131843567, Acc: 0.90625\n",
            "Batch 339/1041, Loss: 0.14740963280200958, Acc: 0.96875\n",
            "Batch 340/1041, Loss: 0.3043037950992584, Acc: 0.875\n",
            "Batch 341/1041, Loss: 0.4365306794643402, Acc: 0.84375\n",
            "Batch 342/1041, Loss: 0.3182356357574463, Acc: 0.90625\n",
            "Batch 343/1041, Loss: 0.4035801291465759, Acc: 0.8125\n",
            "Batch 344/1041, Loss: 0.2707892656326294, Acc: 0.90625\n",
            "Batch 345/1041, Loss: 0.33614203333854675, Acc: 0.84375\n",
            "Batch 346/1041, Loss: 0.2631073594093323, Acc: 0.90625\n",
            "Batch 347/1041, Loss: 0.2578510344028473, Acc: 0.9375\n",
            "Batch 348/1041, Loss: 0.43360069394111633, Acc: 0.8125\n",
            "Batch 349/1041, Loss: 0.14480747282505035, Acc: 0.90625\n",
            "Batch 350/1041, Loss: 0.26576027274131775, Acc: 0.90625\n",
            "Batch 351/1041, Loss: 0.2060479074716568, Acc: 0.9375\n",
            "Batch 352/1041, Loss: 0.18370483815670013, Acc: 0.9375\n",
            "Batch 353/1041, Loss: 0.3639403283596039, Acc: 0.875\n",
            "Batch 354/1041, Loss: 0.2901581823825836, Acc: 0.875\n",
            "Batch 355/1041, Loss: 0.3158317506313324, Acc: 0.84375\n",
            "Batch 356/1041, Loss: 0.500522792339325, Acc: 0.8125\n",
            "Batch 357/1041, Loss: 0.43108993768692017, Acc: 0.84375\n",
            "Batch 358/1041, Loss: 0.11149220913648605, Acc: 0.96875\n",
            "Batch 359/1041, Loss: 0.3672749102115631, Acc: 0.875\n",
            "Batch 360/1041, Loss: 0.3798922002315521, Acc: 0.8125\n",
            "Batch 361/1041, Loss: 0.23409885168075562, Acc: 0.9375\n",
            "Batch 362/1041, Loss: 0.309870183467865, Acc: 0.84375\n",
            "Batch 363/1041, Loss: 0.24910317361354828, Acc: 0.875\n",
            "Batch 364/1041, Loss: 0.4371943771839142, Acc: 0.84375\n",
            "Batch 365/1041, Loss: 0.21307852864265442, Acc: 0.9375\n",
            "Batch 366/1041, Loss: 0.1167132779955864, Acc: 0.96875\n",
            "Batch 367/1041, Loss: 0.441834956407547, Acc: 0.6875\n",
            "Batch 368/1041, Loss: 0.6091768145561218, Acc: 0.71875\n",
            "Batch 369/1041, Loss: 0.4117317795753479, Acc: 0.84375\n",
            "Batch 370/1041, Loss: 0.33814120292663574, Acc: 0.875\n",
            "Batch 371/1041, Loss: 0.5983864665031433, Acc: 0.75\n",
            "Batch 372/1041, Loss: 0.2461010217666626, Acc: 0.875\n",
            "Batch 373/1041, Loss: 0.2352512627840042, Acc: 0.9375\n",
            "Batch 374/1041, Loss: 0.39110642671585083, Acc: 0.8125\n",
            "Batch 375/1041, Loss: 0.46790122985839844, Acc: 0.875\n",
            "Batch 376/1041, Loss: 0.35879233479499817, Acc: 0.84375\n",
            "Batch 377/1041, Loss: 0.14453616738319397, Acc: 0.9375\n",
            "Batch 378/1041, Loss: 0.1956941783428192, Acc: 0.90625\n",
            "Batch 379/1041, Loss: 0.28445130586624146, Acc: 0.875\n",
            "Batch 380/1041, Loss: 0.1881740689277649, Acc: 0.96875\n",
            "Batch 381/1041, Loss: 0.4392961263656616, Acc: 0.78125\n",
            "Batch 382/1041, Loss: 0.23588229715824127, Acc: 0.9375\n",
            "Batch 383/1041, Loss: 0.16035516560077667, Acc: 0.96875\n",
            "Batch 384/1041, Loss: 0.1676141917705536, Acc: 0.90625\n",
            "Batch 385/1041, Loss: 0.30451640486717224, Acc: 0.875\n",
            "Batch 386/1041, Loss: 0.380788654088974, Acc: 0.875\n",
            "Batch 387/1041, Loss: 0.35875725746154785, Acc: 0.8125\n",
            "Batch 388/1041, Loss: 0.20407797396183014, Acc: 0.9375\n",
            "Batch 389/1041, Loss: 0.19422677159309387, Acc: 0.9375\n",
            "Batch 390/1041, Loss: 0.3116174638271332, Acc: 0.8125\n",
            "Batch 391/1041, Loss: 0.31533873081207275, Acc: 0.8125\n",
            "Batch 392/1041, Loss: 0.4056996703147888, Acc: 0.90625\n",
            "Batch 393/1041, Loss: 0.49785488843917847, Acc: 0.75\n",
            "Batch 394/1041, Loss: 0.4325278103351593, Acc: 0.84375\n",
            "Batch 395/1041, Loss: 0.20880214869976044, Acc: 0.96875\n",
            "Batch 396/1041, Loss: 0.3496752083301544, Acc: 0.875\n",
            "Batch 397/1041, Loss: 0.2749931216239929, Acc: 0.90625\n",
            "Batch 398/1041, Loss: 0.4174167513847351, Acc: 0.75\n",
            "Batch 399/1041, Loss: 0.18986006081104279, Acc: 0.90625\n",
            "Batch 400/1041, Loss: 0.2765783965587616, Acc: 0.84375\n",
            "Batch 401/1041, Loss: 0.19505828619003296, Acc: 0.9375\n",
            "Batch 402/1041, Loss: 0.38564056158065796, Acc: 0.84375\n",
            "Batch 403/1041, Loss: 0.3121422529220581, Acc: 0.875\n",
            "Batch 404/1041, Loss: 0.228126659989357, Acc: 0.90625\n",
            "Batch 405/1041, Loss: 0.1602468490600586, Acc: 1.0\n",
            "Batch 406/1041, Loss: 0.36772698163986206, Acc: 0.875\n",
            "Batch 407/1041, Loss: 0.35676977038383484, Acc: 0.84375\n",
            "Batch 408/1041, Loss: 0.2324557900428772, Acc: 0.875\n",
            "Batch 409/1041, Loss: 0.25943607091903687, Acc: 0.875\n",
            "Batch 410/1041, Loss: 0.27435582876205444, Acc: 0.875\n",
            "Batch 411/1041, Loss: 0.2808881402015686, Acc: 0.875\n",
            "Batch 412/1041, Loss: 0.3516307473182678, Acc: 0.84375\n",
            "Batch 413/1041, Loss: 0.3714747130870819, Acc: 0.75\n",
            "Batch 414/1041, Loss: 0.4977882504463196, Acc: 0.75\n",
            "Batch 415/1041, Loss: 0.27510499954223633, Acc: 0.84375\n",
            "Batch 416/1041, Loss: 0.37853139638900757, Acc: 0.78125\n",
            "Batch 417/1041, Loss: 0.2810496389865875, Acc: 0.84375\n",
            "Batch 418/1041, Loss: 0.2508501410484314, Acc: 0.9375\n",
            "[Update 2500] Train Loss: 0.2509, Train Acc: 0.9375 | Val Loss: 0.3137, Val Acc: 0.8697\n",
            "Batch 419/1041, Loss: 0.4607701599597931, Acc: 0.84375\n",
            "Batch 420/1041, Loss: 0.4545508623123169, Acc: 0.8125\n",
            "Batch 421/1041, Loss: 0.23690825700759888, Acc: 0.875\n",
            "Batch 422/1041, Loss: 0.38396453857421875, Acc: 0.84375\n",
            "Batch 423/1041, Loss: 0.22276076674461365, Acc: 0.9375\n",
            "Batch 424/1041, Loss: 0.2759035527706146, Acc: 0.875\n",
            "Batch 425/1041, Loss: 0.24688857793807983, Acc: 0.9375\n",
            "Batch 426/1041, Loss: 0.3296164274215698, Acc: 0.84375\n",
            "Batch 427/1041, Loss: 0.18979457020759583, Acc: 0.9375\n",
            "Batch 428/1041, Loss: 0.2505737841129303, Acc: 0.90625\n",
            "Batch 429/1041, Loss: 0.3279378116130829, Acc: 0.84375\n",
            "Batch 430/1041, Loss: 0.3141923248767853, Acc: 0.875\n",
            "Batch 431/1041, Loss: 0.44898754358291626, Acc: 0.84375\n",
            "Batch 432/1041, Loss: 0.2956022322177887, Acc: 0.875\n",
            "Batch 433/1041, Loss: 0.5057471394538879, Acc: 0.84375\n",
            "Batch 434/1041, Loss: 0.30966120958328247, Acc: 0.875\n",
            "Batch 435/1041, Loss: 0.5058212876319885, Acc: 0.84375\n",
            "Batch 436/1041, Loss: 0.22823578119277954, Acc: 0.90625\n",
            "Batch 437/1041, Loss: 0.3239370584487915, Acc: 0.875\n",
            "Batch 438/1041, Loss: 0.2649727761745453, Acc: 0.875\n",
            "Batch 439/1041, Loss: 0.299152672290802, Acc: 0.875\n",
            "Batch 440/1041, Loss: 0.2525958716869354, Acc: 0.875\n",
            "Batch 441/1041, Loss: 0.28525447845458984, Acc: 0.875\n",
            "Batch 442/1041, Loss: 0.3124832510948181, Acc: 0.875\n",
            "Batch 443/1041, Loss: 0.2630367577075958, Acc: 0.875\n",
            "Batch 444/1041, Loss: 0.3649182915687561, Acc: 0.875\n",
            "Batch 445/1041, Loss: 0.1732037365436554, Acc: 0.96875\n",
            "Batch 446/1041, Loss: 0.14137163758277893, Acc: 1.0\n",
            "Batch 447/1041, Loss: 0.2624054551124573, Acc: 0.90625\n",
            "Batch 448/1041, Loss: 0.15312281250953674, Acc: 0.96875\n",
            "Batch 449/1041, Loss: 0.5867193341255188, Acc: 0.78125\n",
            "Batch 450/1041, Loss: 0.3952534794807434, Acc: 0.84375\n",
            "Batch 451/1041, Loss: 0.3744441270828247, Acc: 0.875\n",
            "Batch 452/1041, Loss: 0.4338530898094177, Acc: 0.875\n",
            "Batch 453/1041, Loss: 0.5240609049797058, Acc: 0.78125\n",
            "Batch 454/1041, Loss: 0.2226966917514801, Acc: 0.90625\n",
            "Batch 455/1041, Loss: 0.2892434298992157, Acc: 0.875\n",
            "Batch 456/1041, Loss: 0.469039648771286, Acc: 0.75\n",
            "Batch 457/1041, Loss: 0.2638682723045349, Acc: 0.90625\n",
            "Batch 458/1041, Loss: 0.25961536169052124, Acc: 0.875\n",
            "Batch 459/1041, Loss: 0.22458142042160034, Acc: 0.9375\n",
            "Batch 460/1041, Loss: 0.4396771788597107, Acc: 0.8125\n",
            "Batch 461/1041, Loss: 0.3745386600494385, Acc: 0.8125\n",
            "Batch 462/1041, Loss: 0.44440925121307373, Acc: 0.84375\n",
            "Batch 463/1041, Loss: 0.23706431686878204, Acc: 0.875\n",
            "Batch 464/1041, Loss: 0.42433393001556396, Acc: 0.875\n",
            "Batch 465/1041, Loss: 0.3082391619682312, Acc: 0.84375\n",
            "Batch 466/1041, Loss: 0.2787775695323944, Acc: 0.875\n",
            "Batch 467/1041, Loss: 0.3521360754966736, Acc: 0.875\n",
            "Batch 468/1041, Loss: 0.2910017669200897, Acc: 0.84375\n",
            "Batch 469/1041, Loss: 0.2977089583873749, Acc: 0.875\n",
            "Batch 470/1041, Loss: 0.4469602406024933, Acc: 0.75\n",
            "Batch 471/1041, Loss: 0.43650022149086, Acc: 0.84375\n",
            "Batch 472/1041, Loss: 0.3680923283100128, Acc: 0.875\n",
            "Batch 473/1041, Loss: 0.22065754234790802, Acc: 0.9375\n",
            "Batch 474/1041, Loss: 0.2433355748653412, Acc: 0.9375\n",
            "Batch 475/1041, Loss: 0.23114486038684845, Acc: 0.90625\n",
            "Batch 476/1041, Loss: 0.26640433073043823, Acc: 0.84375\n",
            "Batch 477/1041, Loss: 0.2986075282096863, Acc: 0.84375\n",
            "Batch 478/1041, Loss: 0.3832426369190216, Acc: 0.84375\n",
            "Batch 479/1041, Loss: 0.44537031650543213, Acc: 0.8125\n",
            "Batch 480/1041, Loss: 0.21124523878097534, Acc: 0.875\n",
            "Batch 481/1041, Loss: 0.23863323032855988, Acc: 0.90625\n",
            "Batch 482/1041, Loss: 0.2446422576904297, Acc: 0.84375\n",
            "Batch 483/1041, Loss: 0.2472718209028244, Acc: 0.875\n",
            "Batch 484/1041, Loss: 0.17912699282169342, Acc: 0.9375\n",
            "Batch 485/1041, Loss: 0.443685382604599, Acc: 0.75\n",
            "Batch 486/1041, Loss: 0.2793775498867035, Acc: 0.875\n",
            "Batch 487/1041, Loss: 0.25649240612983704, Acc: 0.90625\n",
            "Batch 488/1041, Loss: 0.30473944544792175, Acc: 0.78125\n",
            "Batch 489/1041, Loss: 0.3524773418903351, Acc: 0.78125\n",
            "Batch 490/1041, Loss: 0.2966204285621643, Acc: 0.9375\n",
            "Batch 491/1041, Loss: 0.3146202564239502, Acc: 0.84375\n",
            "Batch 492/1041, Loss: 0.2178976982831955, Acc: 0.90625\n",
            "Batch 493/1041, Loss: 0.3256334364414215, Acc: 0.8125\n",
            "Batch 494/1041, Loss: 0.3081519603729248, Acc: 0.84375\n",
            "Batch 495/1041, Loss: 0.2703389823436737, Acc: 0.84375\n",
            "Batch 496/1041, Loss: 0.17031386494636536, Acc: 0.9375\n",
            "Batch 497/1041, Loss: 0.28518980741500854, Acc: 0.875\n",
            "Batch 498/1041, Loss: 0.2975930869579315, Acc: 0.90625\n",
            "Batch 499/1041, Loss: 0.30375149846076965, Acc: 0.8125\n",
            "Batch 500/1041, Loss: 0.3268272876739502, Acc: 0.875\n",
            "Batch 501/1041, Loss: 0.40348899364471436, Acc: 0.84375\n",
            "Batch 502/1041, Loss: 0.23696400225162506, Acc: 0.875\n",
            "Batch 503/1041, Loss: 0.18804524838924408, Acc: 0.9375\n",
            "Batch 504/1041, Loss: 0.18396085500717163, Acc: 0.9375\n",
            "Batch 505/1041, Loss: 0.3569943904876709, Acc: 0.875\n",
            "Batch 506/1041, Loss: 0.2697383463382721, Acc: 0.90625\n",
            "Batch 507/1041, Loss: 0.24877767264842987, Acc: 0.90625\n",
            "Batch 508/1041, Loss: 0.2217390090227127, Acc: 0.96875\n",
            "Batch 509/1041, Loss: 0.29222571849823, Acc: 0.8125\n",
            "Batch 510/1041, Loss: 0.2478746622800827, Acc: 0.90625\n",
            "Batch 511/1041, Loss: 0.3836868405342102, Acc: 0.875\n",
            "Batch 512/1041, Loss: 0.3560012876987457, Acc: 0.84375\n",
            "Batch 513/1041, Loss: 0.33103618025779724, Acc: 0.84375\n",
            "Batch 514/1041, Loss: 0.17188933491706848, Acc: 0.9375\n",
            "Batch 515/1041, Loss: 0.29983919858932495, Acc: 0.84375\n",
            "Batch 516/1041, Loss: 0.2769751250743866, Acc: 0.90625\n",
            "Batch 517/1041, Loss: 0.5685548782348633, Acc: 0.78125\n",
            "Batch 518/1041, Loss: 0.26388952136039734, Acc: 0.875\n",
            "[Update 2600] Train Loss: 0.2639, Train Acc: 0.8750 | Val Loss: 0.3111, Val Acc: 0.8729\n",
            "Batch 519/1041, Loss: 0.3228413760662079, Acc: 0.875\n",
            "Batch 520/1041, Loss: 0.3719998300075531, Acc: 0.84375\n",
            "Batch 521/1041, Loss: 0.36362168192863464, Acc: 0.875\n",
            "Batch 522/1041, Loss: 0.1952742338180542, Acc: 0.90625\n",
            "Batch 523/1041, Loss: 0.2844625413417816, Acc: 0.90625\n",
            "Batch 524/1041, Loss: 0.3729639947414398, Acc: 0.875\n",
            "Batch 525/1041, Loss: 0.29269716143608093, Acc: 0.9375\n",
            "Batch 526/1041, Loss: 0.262525349855423, Acc: 0.84375\n",
            "Batch 527/1041, Loss: 0.38572314381599426, Acc: 0.84375\n",
            "Batch 528/1041, Loss: 0.37570682168006897, Acc: 0.8125\n",
            "Batch 529/1041, Loss: 0.45063236355781555, Acc: 0.84375\n",
            "Batch 530/1041, Loss: 0.24735209345817566, Acc: 0.9375\n",
            "Batch 531/1041, Loss: 0.500443160533905, Acc: 0.75\n",
            "Batch 532/1041, Loss: 0.27406665682792664, Acc: 0.96875\n",
            "Batch 533/1041, Loss: 0.32872474193573, Acc: 0.875\n",
            "Batch 534/1041, Loss: 0.40111836791038513, Acc: 0.84375\n",
            "Batch 535/1041, Loss: 0.45212239027023315, Acc: 0.8125\n",
            "Batch 536/1041, Loss: 0.30696770548820496, Acc: 0.84375\n",
            "Batch 537/1041, Loss: 0.38144928216934204, Acc: 0.78125\n",
            "Batch 538/1041, Loss: 0.5121829509735107, Acc: 0.6875\n",
            "Batch 539/1041, Loss: 0.18362627923488617, Acc: 0.90625\n",
            "Batch 540/1041, Loss: 0.2121753692626953, Acc: 0.9375\n",
            "Batch 541/1041, Loss: 0.64183509349823, Acc: 0.65625\n",
            "Batch 542/1041, Loss: 0.3146769106388092, Acc: 0.84375\n",
            "Batch 543/1041, Loss: 0.38973501324653625, Acc: 0.84375\n",
            "Batch 544/1041, Loss: 0.36453649401664734, Acc: 0.8125\n",
            "Batch 545/1041, Loss: 0.5443033576011658, Acc: 0.84375\n",
            "Batch 546/1041, Loss: 0.4447813630104065, Acc: 0.8125\n",
            "Batch 547/1041, Loss: 0.19705216586589813, Acc: 0.90625\n",
            "Batch 548/1041, Loss: 0.19561021029949188, Acc: 0.96875\n",
            "Batch 549/1041, Loss: 0.36113205552101135, Acc: 0.90625\n",
            "Batch 550/1041, Loss: 0.3451961874961853, Acc: 0.84375\n",
            "Batch 551/1041, Loss: 0.2853623032569885, Acc: 0.84375\n",
            "Batch 552/1041, Loss: 0.4295731782913208, Acc: 0.71875\n",
            "Batch 553/1041, Loss: 0.215326726436615, Acc: 0.9375\n",
            "Batch 554/1041, Loss: 0.41673675179481506, Acc: 0.78125\n",
            "Batch 555/1041, Loss: 0.3983711004257202, Acc: 0.84375\n",
            "Batch 556/1041, Loss: 0.5684680342674255, Acc: 0.78125\n",
            "Batch 557/1041, Loss: 0.3032955825328827, Acc: 0.875\n",
            "Batch 558/1041, Loss: 0.286840558052063, Acc: 0.90625\n",
            "Batch 559/1041, Loss: 0.25777938961982727, Acc: 0.875\n",
            "Batch 560/1041, Loss: 0.578787088394165, Acc: 0.8125\n",
            "Batch 561/1041, Loss: 0.3285726010799408, Acc: 0.875\n",
            "Batch 562/1041, Loss: 0.20070995390415192, Acc: 0.96875\n",
            "Batch 563/1041, Loss: 0.40085944533348083, Acc: 0.84375\n",
            "Batch 564/1041, Loss: 0.2209344059228897, Acc: 0.90625\n",
            "Batch 565/1041, Loss: 0.2900766432285309, Acc: 0.875\n",
            "Batch 566/1041, Loss: 0.3419930636882782, Acc: 0.8125\n",
            "Batch 567/1041, Loss: 0.3034230172634125, Acc: 0.875\n",
            "Batch 568/1041, Loss: 0.3990483582019806, Acc: 0.84375\n",
            "Batch 569/1041, Loss: 0.38064342737197876, Acc: 0.78125\n",
            "Batch 570/1041, Loss: 0.47862833738327026, Acc: 0.8125\n",
            "Batch 571/1041, Loss: 0.6039539575576782, Acc: 0.75\n",
            "Batch 572/1041, Loss: 0.3011576235294342, Acc: 0.9375\n",
            "Batch 573/1041, Loss: 0.22163189947605133, Acc: 0.875\n",
            "Batch 574/1041, Loss: 0.18083405494689941, Acc: 0.96875\n",
            "Batch 575/1041, Loss: 0.36064648628234863, Acc: 0.78125\n",
            "Batch 576/1041, Loss: 0.18941554427146912, Acc: 0.9375\n",
            "Batch 577/1041, Loss: 0.13470712304115295, Acc: 1.0\n",
            "Batch 578/1041, Loss: 0.321044385433197, Acc: 0.84375\n",
            "Batch 579/1041, Loss: 0.4301149249076843, Acc: 0.8125\n",
            "Batch 580/1041, Loss: 0.24952629208564758, Acc: 0.875\n",
            "Batch 581/1041, Loss: 0.16737253963947296, Acc: 0.96875\n",
            "Batch 582/1041, Loss: 0.3398001194000244, Acc: 0.90625\n",
            "Batch 583/1041, Loss: 0.27404144406318665, Acc: 0.90625\n",
            "Batch 584/1041, Loss: 0.21910355985164642, Acc: 0.90625\n",
            "Batch 585/1041, Loss: 0.31749796867370605, Acc: 0.90625\n",
            "Batch 586/1041, Loss: 0.6786544919013977, Acc: 0.75\n",
            "Batch 587/1041, Loss: 0.2968333661556244, Acc: 0.90625\n",
            "Batch 588/1041, Loss: 0.44951167702674866, Acc: 0.78125\n",
            "Batch 589/1041, Loss: 0.31148993968963623, Acc: 0.9375\n",
            "Batch 590/1041, Loss: 0.3854873478412628, Acc: 0.84375\n",
            "Batch 591/1041, Loss: 0.2689284086227417, Acc: 0.875\n",
            "Batch 592/1041, Loss: 0.31658124923706055, Acc: 0.84375\n",
            "Batch 593/1041, Loss: 0.4129401445388794, Acc: 0.84375\n",
            "Batch 594/1041, Loss: 0.2968807816505432, Acc: 0.875\n",
            "Batch 595/1041, Loss: 0.2986413836479187, Acc: 0.875\n",
            "Batch 596/1041, Loss: 0.19718484580516815, Acc: 0.9375\n",
            "Batch 597/1041, Loss: 0.33764925599098206, Acc: 0.875\n",
            "Batch 598/1041, Loss: 0.25033628940582275, Acc: 0.9375\n",
            "Batch 599/1041, Loss: 0.23857292532920837, Acc: 0.9375\n",
            "Batch 600/1041, Loss: 0.37821006774902344, Acc: 0.875\n",
            "Batch 601/1041, Loss: 0.2141454964876175, Acc: 0.9375\n",
            "Batch 602/1041, Loss: 0.4268193542957306, Acc: 0.8125\n",
            "Batch 603/1041, Loss: 0.3253532946109772, Acc: 0.78125\n",
            "Batch 604/1041, Loss: 0.40424612164497375, Acc: 0.8125\n",
            "Batch 605/1041, Loss: 0.3058486878871918, Acc: 0.875\n",
            "Batch 606/1041, Loss: 0.22692492604255676, Acc: 0.90625\n",
            "Batch 607/1041, Loss: 0.26993831992149353, Acc: 0.875\n",
            "Batch 608/1041, Loss: 0.20691494643688202, Acc: 0.9375\n",
            "Batch 609/1041, Loss: 0.2474817931652069, Acc: 0.875\n",
            "Batch 610/1041, Loss: 0.19752950966358185, Acc: 0.9375\n",
            "Batch 611/1041, Loss: 0.2747960090637207, Acc: 0.90625\n",
            "Batch 612/1041, Loss: 0.20700481534004211, Acc: 0.9375\n",
            "Batch 613/1041, Loss: 0.41723302006721497, Acc: 0.75\n",
            "Batch 614/1041, Loss: 0.23560990393161774, Acc: 0.9375\n",
            "Batch 615/1041, Loss: 0.3063735067844391, Acc: 0.84375\n",
            "Batch 616/1041, Loss: 0.42470288276672363, Acc: 0.8125\n",
            "Batch 617/1041, Loss: 0.4102286100387573, Acc: 0.8125\n",
            "Batch 618/1041, Loss: 0.16559872031211853, Acc: 0.9375\n",
            "[Update 2700] Train Loss: 0.1656, Train Acc: 0.9375 | Val Loss: 0.3139, Val Acc: 0.8711\n",
            "Batch 619/1041, Loss: 0.382019579410553, Acc: 0.875\n",
            "Batch 620/1041, Loss: 0.4053259491920471, Acc: 0.875\n",
            "Batch 621/1041, Loss: 0.2558005452156067, Acc: 0.875\n",
            "Batch 622/1041, Loss: 0.35359278321266174, Acc: 0.84375\n",
            "Batch 623/1041, Loss: 0.6662071943283081, Acc: 0.78125\n",
            "Batch 624/1041, Loss: 0.49729979038238525, Acc: 0.75\n",
            "Batch 625/1041, Loss: 0.2095079869031906, Acc: 0.90625\n",
            "Batch 626/1041, Loss: 0.17212656140327454, Acc: 0.96875\n",
            "Batch 627/1041, Loss: 0.23073570430278778, Acc: 0.9375\n",
            "Batch 628/1041, Loss: 0.5602832436561584, Acc: 0.6875\n",
            "Batch 629/1041, Loss: 0.20881494879722595, Acc: 0.875\n",
            "Batch 630/1041, Loss: 0.27497705817222595, Acc: 0.90625\n",
            "Batch 631/1041, Loss: 0.29668885469436646, Acc: 0.84375\n",
            "Batch 632/1041, Loss: 0.40077728033065796, Acc: 0.8125\n",
            "Batch 633/1041, Loss: 0.36978983879089355, Acc: 0.84375\n",
            "Batch 634/1041, Loss: 0.297560453414917, Acc: 0.875\n",
            "Batch 635/1041, Loss: 0.2992092967033386, Acc: 0.8125\n",
            "Batch 636/1041, Loss: 0.31495046615600586, Acc: 0.84375\n",
            "Batch 637/1041, Loss: 0.4168970584869385, Acc: 0.84375\n",
            "Batch 638/1041, Loss: 0.4085811376571655, Acc: 0.8125\n",
            "Batch 639/1041, Loss: 0.22124363481998444, Acc: 0.90625\n",
            "Batch 640/1041, Loss: 0.4400540888309479, Acc: 0.8125\n",
            "Batch 641/1041, Loss: 0.33172863721847534, Acc: 0.875\n",
            "Batch 642/1041, Loss: 0.4374138414859772, Acc: 0.78125\n",
            "Batch 643/1041, Loss: 0.2792998254299164, Acc: 0.84375\n",
            "Batch 644/1041, Loss: 0.3315627872943878, Acc: 0.84375\n",
            "Batch 645/1041, Loss: 0.21186698973178864, Acc: 0.9375\n",
            "Batch 646/1041, Loss: 0.2908982038497925, Acc: 0.875\n",
            "Batch 647/1041, Loss: 0.3356115520000458, Acc: 0.875\n",
            "Batch 648/1041, Loss: 0.28114038705825806, Acc: 0.90625\n",
            "Batch 649/1041, Loss: 0.3156672418117523, Acc: 0.75\n",
            "Batch 650/1041, Loss: 0.36549320816993713, Acc: 0.84375\n",
            "Batch 651/1041, Loss: 0.33017393946647644, Acc: 0.84375\n",
            "Batch 652/1041, Loss: 0.36541542410850525, Acc: 0.875\n",
            "Batch 653/1041, Loss: 0.38100937008857727, Acc: 0.8125\n",
            "Batch 654/1041, Loss: 0.1752159148454666, Acc: 0.9375\n",
            "Batch 655/1041, Loss: 0.2580127418041229, Acc: 0.90625\n",
            "Batch 656/1041, Loss: 0.30148863792419434, Acc: 0.875\n",
            "Batch 657/1041, Loss: 0.2911262512207031, Acc: 0.90625\n",
            "Batch 658/1041, Loss: 0.36972030997276306, Acc: 0.8125\n",
            "Batch 659/1041, Loss: 0.38514432311058044, Acc: 0.8125\n",
            "Batch 660/1041, Loss: 0.25175949931144714, Acc: 0.875\n",
            "Batch 661/1041, Loss: 0.4023154675960541, Acc: 0.84375\n",
            "Batch 662/1041, Loss: 0.1926904320716858, Acc: 0.90625\n",
            "Batch 663/1041, Loss: 0.35001102089881897, Acc: 0.875\n",
            "Batch 664/1041, Loss: 0.26415276527404785, Acc: 0.875\n",
            "Batch 665/1041, Loss: 0.3726933002471924, Acc: 0.84375\n",
            "Batch 666/1041, Loss: 0.2988806366920471, Acc: 0.875\n",
            "Batch 667/1041, Loss: 0.21927881240844727, Acc: 0.875\n",
            "Batch 668/1041, Loss: 0.30152270197868347, Acc: 0.8125\n",
            "Batch 669/1041, Loss: 0.43492525815963745, Acc: 0.75\n",
            "Batch 670/1041, Loss: 0.33923977613449097, Acc: 0.84375\n",
            "Batch 671/1041, Loss: 0.34273502230644226, Acc: 0.875\n",
            "Batch 672/1041, Loss: 0.40626490116119385, Acc: 0.75\n",
            "Batch 673/1041, Loss: 0.23778605461120605, Acc: 0.90625\n",
            "Batch 674/1041, Loss: 0.24438892304897308, Acc: 0.875\n",
            "Batch 675/1041, Loss: 0.34844183921813965, Acc: 0.8125\n",
            "Batch 676/1041, Loss: 0.28162825107574463, Acc: 0.84375\n",
            "Batch 677/1041, Loss: 0.28229260444641113, Acc: 0.875\n",
            "Batch 678/1041, Loss: 0.23331277072429657, Acc: 0.875\n",
            "Batch 679/1041, Loss: 0.4071660041809082, Acc: 0.8125\n",
            "Batch 680/1041, Loss: 0.21367612481117249, Acc: 0.9375\n",
            "Batch 681/1041, Loss: 0.285299152135849, Acc: 0.90625\n",
            "Batch 682/1041, Loss: 0.17756228148937225, Acc: 0.90625\n",
            "Batch 683/1041, Loss: 0.2605609893798828, Acc: 0.90625\n",
            "Batch 684/1041, Loss: 0.2523033916950226, Acc: 0.90625\n",
            "Batch 685/1041, Loss: 0.30612221360206604, Acc: 0.84375\n",
            "Batch 686/1041, Loss: 0.3318013846874237, Acc: 0.84375\n",
            "Batch 687/1041, Loss: 0.26298725605010986, Acc: 0.9375\n",
            "Batch 688/1041, Loss: 0.24518869817256927, Acc: 0.9375\n",
            "Batch 689/1041, Loss: 0.3010496199131012, Acc: 0.875\n",
            "Batch 690/1041, Loss: 0.3483405113220215, Acc: 0.8125\n",
            "Batch 691/1041, Loss: 0.3376103341579437, Acc: 0.84375\n",
            "Batch 692/1041, Loss: 0.26534801721572876, Acc: 0.90625\n",
            "Batch 693/1041, Loss: 0.18060262501239777, Acc: 0.90625\n",
            "Batch 694/1041, Loss: 0.32426345348358154, Acc: 0.875\n",
            "Batch 695/1041, Loss: 0.17151705920696259, Acc: 0.9375\n",
            "Batch 696/1041, Loss: 0.29132649302482605, Acc: 0.875\n",
            "Batch 697/1041, Loss: 0.28645047545433044, Acc: 0.84375\n",
            "Batch 698/1041, Loss: 0.3983832001686096, Acc: 0.84375\n",
            "Batch 699/1041, Loss: 0.3795352280139923, Acc: 0.875\n",
            "Batch 700/1041, Loss: 0.254513144493103, Acc: 0.90625\n",
            "Batch 701/1041, Loss: 0.4725859463214874, Acc: 0.875\n",
            "Batch 702/1041, Loss: 0.3288474977016449, Acc: 0.9375\n",
            "Batch 703/1041, Loss: 0.4457680583000183, Acc: 0.84375\n",
            "Batch 704/1041, Loss: 0.3553851246833801, Acc: 0.8125\n",
            "Batch 705/1041, Loss: 0.3662271201610565, Acc: 0.84375\n",
            "Batch 706/1041, Loss: 0.2941455543041229, Acc: 0.90625\n",
            "Batch 707/1041, Loss: 0.2955578565597534, Acc: 0.90625\n",
            "Batch 708/1041, Loss: 0.4964976906776428, Acc: 0.71875\n",
            "Batch 709/1041, Loss: 0.5213620066642761, Acc: 0.75\n",
            "Batch 710/1041, Loss: 0.35974982380867004, Acc: 0.8125\n",
            "Batch 711/1041, Loss: 0.3446161150932312, Acc: 0.875\n",
            "Batch 712/1041, Loss: 0.22585567831993103, Acc: 0.90625\n",
            "Batch 713/1041, Loss: 0.24551211297512054, Acc: 0.90625\n",
            "Batch 714/1041, Loss: 0.4291471242904663, Acc: 0.78125\n",
            "Batch 715/1041, Loss: 0.38518884778022766, Acc: 0.8125\n",
            "Batch 716/1041, Loss: 0.31226861476898193, Acc: 0.8125\n",
            "Batch 717/1041, Loss: 0.2907363176345825, Acc: 0.875\n",
            "Batch 718/1041, Loss: 0.30508163571357727, Acc: 0.90625\n",
            "[Update 2800] Train Loss: 0.3051, Train Acc: 0.9062 | Val Loss: 0.3000, Val Acc: 0.8780\n",
            "Batch 719/1041, Loss: 0.22459349036216736, Acc: 0.90625\n",
            "Batch 720/1041, Loss: 0.35194265842437744, Acc: 0.90625\n",
            "Batch 721/1041, Loss: 0.28035980463027954, Acc: 0.875\n",
            "Batch 722/1041, Loss: 0.1200547069311142, Acc: 0.96875\n",
            "Batch 723/1041, Loss: 0.2919049859046936, Acc: 0.90625\n",
            "Batch 724/1041, Loss: 0.22473111748695374, Acc: 0.9375\n",
            "Batch 725/1041, Loss: 0.3457864224910736, Acc: 0.90625\n",
            "Batch 726/1041, Loss: 0.2116142064332962, Acc: 0.9375\n",
            "Batch 727/1041, Loss: 0.32305771112442017, Acc: 0.90625\n",
            "Batch 728/1041, Loss: 0.30269521474838257, Acc: 0.84375\n",
            "Batch 729/1041, Loss: 0.357067346572876, Acc: 0.84375\n",
            "Batch 730/1041, Loss: 0.4185371696949005, Acc: 0.78125\n",
            "Batch 731/1041, Loss: 0.4972015917301178, Acc: 0.8125\n",
            "Batch 732/1041, Loss: 0.2937124967575073, Acc: 0.84375\n",
            "Batch 733/1041, Loss: 0.14548584818840027, Acc: 0.9375\n",
            "Batch 734/1041, Loss: 0.4213084280490875, Acc: 0.78125\n",
            "Batch 735/1041, Loss: 0.4769006371498108, Acc: 0.75\n",
            "Batch 736/1041, Loss: 0.18512406945228577, Acc: 0.96875\n",
            "Batch 737/1041, Loss: 0.2525942623615265, Acc: 0.875\n",
            "Batch 738/1041, Loss: 0.3170706331729889, Acc: 0.875\n",
            "Batch 739/1041, Loss: 0.5000044107437134, Acc: 0.71875\n",
            "Batch 740/1041, Loss: 0.3075031042098999, Acc: 0.875\n",
            "Batch 741/1041, Loss: 0.34328916668891907, Acc: 0.84375\n",
            "Batch 742/1041, Loss: 0.4097638726234436, Acc: 0.84375\n",
            "Batch 743/1041, Loss: 0.3707583248615265, Acc: 0.84375\n",
            "Batch 744/1041, Loss: 0.32688435912132263, Acc: 0.84375\n",
            "Batch 745/1041, Loss: 0.23486943542957306, Acc: 0.90625\n",
            "Batch 746/1041, Loss: 0.29898521304130554, Acc: 0.84375\n",
            "Batch 747/1041, Loss: 0.29929211735725403, Acc: 0.90625\n",
            "Batch 748/1041, Loss: 0.24171143770217896, Acc: 0.875\n",
            "Batch 749/1041, Loss: 0.2963097095489502, Acc: 0.90625\n",
            "Batch 750/1041, Loss: 0.2053144872188568, Acc: 0.875\n",
            "Batch 751/1041, Loss: 0.2216460257768631, Acc: 0.9375\n",
            "Batch 752/1041, Loss: 0.3768084645271301, Acc: 0.84375\n",
            "Batch 753/1041, Loss: 0.23301950097084045, Acc: 0.90625\n",
            "Batch 754/1041, Loss: 0.2416391223669052, Acc: 0.9375\n",
            "Batch 755/1041, Loss: 0.3268260359764099, Acc: 0.875\n",
            "Batch 756/1041, Loss: 0.37921324372291565, Acc: 0.78125\n",
            "Batch 757/1041, Loss: 0.43186184763908386, Acc: 0.84375\n",
            "Batch 758/1041, Loss: 0.11564288288354874, Acc: 1.0\n",
            "Batch 759/1041, Loss: 0.21699106693267822, Acc: 0.90625\n",
            "Batch 760/1041, Loss: 0.20089450478553772, Acc: 0.90625\n",
            "Batch 761/1041, Loss: 0.36717307567596436, Acc: 0.8125\n",
            "Batch 762/1041, Loss: 0.283648818731308, Acc: 0.90625\n",
            "Batch 763/1041, Loss: 0.3423910439014435, Acc: 0.84375\n",
            "Batch 764/1041, Loss: 0.3256921172142029, Acc: 0.84375\n",
            "Batch 765/1041, Loss: 0.3159235715866089, Acc: 0.84375\n",
            "Batch 766/1041, Loss: 0.36012887954711914, Acc: 0.78125\n",
            "Batch 767/1041, Loss: 0.3622311055660248, Acc: 0.78125\n",
            "Batch 768/1041, Loss: 0.2546641528606415, Acc: 0.84375\n",
            "Batch 769/1041, Loss: 0.27985167503356934, Acc: 0.84375\n",
            "Batch 770/1041, Loss: 0.2956591546535492, Acc: 0.90625\n",
            "Batch 771/1041, Loss: 0.1864427626132965, Acc: 0.9375\n",
            "Batch 772/1041, Loss: 0.1527498960494995, Acc: 0.9375\n",
            "Batch 773/1041, Loss: 0.22672195732593536, Acc: 0.875\n",
            "Batch 774/1041, Loss: 0.33182719349861145, Acc: 0.90625\n",
            "Batch 775/1041, Loss: 0.2350335717201233, Acc: 0.90625\n",
            "Batch 776/1041, Loss: 0.29414069652557373, Acc: 0.875\n",
            "Batch 777/1041, Loss: 0.220818892121315, Acc: 0.90625\n",
            "Batch 778/1041, Loss: 0.22543442249298096, Acc: 0.875\n",
            "Batch 779/1041, Loss: 0.3423255681991577, Acc: 0.8125\n",
            "Batch 780/1041, Loss: 0.5423117876052856, Acc: 0.78125\n",
            "Batch 781/1041, Loss: 0.35123953223228455, Acc: 0.90625\n",
            "Batch 782/1041, Loss: 0.3802867829799652, Acc: 0.84375\n",
            "Batch 783/1041, Loss: 0.4471864402294159, Acc: 0.8125\n",
            "Batch 784/1041, Loss: 0.30641481280326843, Acc: 0.90625\n",
            "Batch 785/1041, Loss: 0.1821913868188858, Acc: 0.96875\n",
            "Batch 786/1041, Loss: 0.28266891837120056, Acc: 0.875\n",
            "Batch 787/1041, Loss: 0.2193862646818161, Acc: 0.9375\n",
            "Batch 788/1041, Loss: 0.3790711760520935, Acc: 0.90625\n",
            "Batch 789/1041, Loss: 0.1900607794523239, Acc: 0.90625\n",
            "Batch 790/1041, Loss: 0.16364121437072754, Acc: 0.90625\n",
            "Batch 791/1041, Loss: 0.29031550884246826, Acc: 0.875\n",
            "Batch 792/1041, Loss: 0.20233054459095, Acc: 0.90625\n",
            "Batch 793/1041, Loss: 0.1714894324541092, Acc: 0.9375\n",
            "Batch 794/1041, Loss: 0.15296636521816254, Acc: 0.96875\n",
            "Batch 795/1041, Loss: 0.3662774860858917, Acc: 0.75\n",
            "Batch 796/1041, Loss: 0.26362743973731995, Acc: 0.875\n",
            "Batch 797/1041, Loss: 0.1807272583246231, Acc: 0.90625\n",
            "Batch 798/1041, Loss: 0.35000789165496826, Acc: 0.84375\n",
            "Batch 799/1041, Loss: 0.2604005038738251, Acc: 0.84375\n",
            "Batch 800/1041, Loss: 0.25175538659095764, Acc: 0.875\n",
            "Batch 801/1041, Loss: 0.3128340244293213, Acc: 0.875\n",
            "Batch 802/1041, Loss: 0.3278247117996216, Acc: 0.875\n",
            "Batch 803/1041, Loss: 0.24193473160266876, Acc: 0.9375\n",
            "Batch 804/1041, Loss: 0.4130968749523163, Acc: 0.84375\n",
            "Batch 805/1041, Loss: 0.23652318120002747, Acc: 0.9375\n",
            "Batch 806/1041, Loss: 0.26754623651504517, Acc: 0.90625\n",
            "Batch 807/1041, Loss: 0.2751789391040802, Acc: 0.875\n",
            "Batch 808/1041, Loss: 0.4305281937122345, Acc: 0.78125\n",
            "Batch 809/1041, Loss: 0.3362084627151489, Acc: 0.875\n",
            "Batch 810/1041, Loss: 0.1804772913455963, Acc: 0.9375\n",
            "Batch 811/1041, Loss: 0.5948665738105774, Acc: 0.71875\n",
            "Batch 812/1041, Loss: 0.16101647913455963, Acc: 0.96875\n",
            "Batch 813/1041, Loss: 0.4800027906894684, Acc: 0.75\n",
            "Batch 814/1041, Loss: 0.08770658075809479, Acc: 1.0\n",
            "Batch 815/1041, Loss: 0.2225797325372696, Acc: 0.9375\n",
            "Batch 816/1041, Loss: 0.3861522674560547, Acc: 0.8125\n",
            "Batch 817/1041, Loss: 0.2950618267059326, Acc: 0.90625\n",
            "Batch 818/1041, Loss: 0.3342764973640442, Acc: 0.84375\n",
            "[Update 2900] Train Loss: 0.3343, Train Acc: 0.8438 | Val Loss: 0.3157, Val Acc: 0.8703\n",
            "Batch 819/1041, Loss: 0.27124831080436707, Acc: 0.875\n",
            "Batch 820/1041, Loss: 0.26221978664398193, Acc: 0.90625\n",
            "Batch 821/1041, Loss: 0.1945757269859314, Acc: 0.9375\n",
            "Batch 822/1041, Loss: 0.2941502034664154, Acc: 0.9375\n",
            "Batch 823/1041, Loss: 0.29741838574409485, Acc: 0.875\n",
            "Batch 824/1041, Loss: 0.39871618151664734, Acc: 0.78125\n",
            "Batch 825/1041, Loss: 0.323569118976593, Acc: 0.8125\n",
            "Batch 826/1041, Loss: 0.34352052211761475, Acc: 0.875\n",
            "Batch 827/1041, Loss: 0.2534969449043274, Acc: 0.875\n",
            "Batch 828/1041, Loss: 0.3129899501800537, Acc: 0.84375\n",
            "Batch 829/1041, Loss: 0.24840563535690308, Acc: 0.90625\n",
            "Batch 830/1041, Loss: 0.2277330905199051, Acc: 0.9375\n",
            "Batch 831/1041, Loss: 0.37629804015159607, Acc: 0.875\n",
            "Batch 832/1041, Loss: 0.30416029691696167, Acc: 0.8125\n",
            "Batch 833/1041, Loss: 0.15907929837703705, Acc: 0.9375\n",
            "Batch 834/1041, Loss: 0.5030924081802368, Acc: 0.875\n",
            "Batch 835/1041, Loss: 0.3042850196361542, Acc: 0.875\n",
            "Batch 836/1041, Loss: 0.18484406173229218, Acc: 0.875\n",
            "Batch 837/1041, Loss: 0.24059754610061646, Acc: 0.90625\n",
            "Batch 838/1041, Loss: 0.3224746286869049, Acc: 0.875\n",
            "Batch 839/1041, Loss: 0.21943537890911102, Acc: 0.90625\n",
            "Batch 840/1041, Loss: 0.19169491529464722, Acc: 0.9375\n",
            "Batch 841/1041, Loss: 0.2911919355392456, Acc: 0.875\n",
            "Batch 842/1041, Loss: 0.30676212906837463, Acc: 0.90625\n",
            "Batch 843/1041, Loss: 0.19725404679775238, Acc: 0.90625\n",
            "Batch 844/1041, Loss: 0.2742435336112976, Acc: 0.90625\n",
            "Batch 845/1041, Loss: 0.16049054265022278, Acc: 0.96875\n",
            "Batch 846/1041, Loss: 0.24616596102714539, Acc: 0.90625\n",
            "Batch 847/1041, Loss: 0.21361371874809265, Acc: 0.90625\n",
            "Batch 848/1041, Loss: 0.2640814781188965, Acc: 0.9375\n",
            "Batch 849/1041, Loss: 0.22195906937122345, Acc: 0.90625\n",
            "Batch 850/1041, Loss: 0.4161645174026489, Acc: 0.84375\n",
            "Batch 851/1041, Loss: 0.30183276534080505, Acc: 0.90625\n",
            "Batch 852/1041, Loss: 0.5129835605621338, Acc: 0.78125\n",
            "Batch 853/1041, Loss: 0.3067830204963684, Acc: 0.90625\n",
            "Batch 854/1041, Loss: 0.32742613554000854, Acc: 0.8125\n",
            "Batch 855/1041, Loss: 0.5139859318733215, Acc: 0.8125\n",
            "Batch 856/1041, Loss: 0.29610931873321533, Acc: 0.90625\n",
            "Batch 857/1041, Loss: 0.30248600244522095, Acc: 0.875\n",
            "Batch 858/1041, Loss: 0.33975616097450256, Acc: 0.84375\n",
            "Batch 859/1041, Loss: 0.32345113158226013, Acc: 0.84375\n",
            "Batch 860/1041, Loss: 0.3867560625076294, Acc: 0.8125\n",
            "Batch 861/1041, Loss: 0.2467672973871231, Acc: 0.90625\n",
            "Batch 862/1041, Loss: 0.3514944314956665, Acc: 0.78125\n",
            "Batch 863/1041, Loss: 0.23751409351825714, Acc: 0.90625\n",
            "Batch 864/1041, Loss: 0.28412947058677673, Acc: 0.875\n",
            "Batch 865/1041, Loss: 0.21126267313957214, Acc: 0.90625\n",
            "Batch 866/1041, Loss: 0.291939377784729, Acc: 0.90625\n",
            "Batch 867/1041, Loss: 0.1783931702375412, Acc: 0.9375\n",
            "Batch 868/1041, Loss: 0.22012756764888763, Acc: 0.9375\n",
            "Batch 869/1041, Loss: 0.36707746982574463, Acc: 0.84375\n",
            "Batch 870/1041, Loss: 0.22788147628307343, Acc: 0.90625\n",
            "Batch 871/1041, Loss: 0.3759702742099762, Acc: 0.8125\n",
            "Batch 872/1041, Loss: 0.4496020972728729, Acc: 0.71875\n",
            "Batch 873/1041, Loss: 0.28901344537734985, Acc: 0.875\n",
            "Batch 874/1041, Loss: 0.32280898094177246, Acc: 0.875\n",
            "Batch 875/1041, Loss: 0.3227565884590149, Acc: 0.8125\n",
            "Batch 876/1041, Loss: 0.246130108833313, Acc: 0.875\n",
            "Batch 877/1041, Loss: 0.11924891918897629, Acc: 1.0\n",
            "Batch 878/1041, Loss: 0.44807979464530945, Acc: 0.8125\n",
            "Batch 879/1041, Loss: 0.29343682527542114, Acc: 0.875\n",
            "Batch 880/1041, Loss: 0.24443838000297546, Acc: 0.90625\n",
            "Batch 881/1041, Loss: 0.6391223669052124, Acc: 0.75\n",
            "Batch 882/1041, Loss: 0.25644204020500183, Acc: 0.875\n",
            "Batch 883/1041, Loss: 0.343863308429718, Acc: 0.84375\n",
            "Batch 884/1041, Loss: 0.26389801502227783, Acc: 0.9375\n",
            "Batch 885/1041, Loss: 0.2151639759540558, Acc: 0.9375\n",
            "Batch 886/1041, Loss: 0.30999499559402466, Acc: 0.8125\n",
            "Batch 887/1041, Loss: 0.2839779555797577, Acc: 0.9375\n",
            "Batch 888/1041, Loss: 0.3039107024669647, Acc: 0.9375\n",
            "Batch 889/1041, Loss: 0.2298043668270111, Acc: 0.90625\n",
            "Batch 890/1041, Loss: 0.30290547013282776, Acc: 0.84375\n",
            "Batch 891/1041, Loss: 0.251631498336792, Acc: 0.9375\n",
            "Batch 892/1041, Loss: 0.2795303761959076, Acc: 0.90625\n",
            "Batch 893/1041, Loss: 0.2514433264732361, Acc: 0.875\n",
            "Batch 894/1041, Loss: 0.3000187575817108, Acc: 0.90625\n",
            "Batch 895/1041, Loss: 0.33084142208099365, Acc: 0.78125\n",
            "Batch 896/1041, Loss: 0.20832516252994537, Acc: 0.90625\n",
            "Batch 897/1041, Loss: 0.22047773003578186, Acc: 0.90625\n",
            "Batch 898/1041, Loss: 0.35451871156692505, Acc: 0.84375\n",
            "Batch 899/1041, Loss: 0.3070490062236786, Acc: 0.875\n",
            "Batch 900/1041, Loss: 0.2131168693304062, Acc: 0.90625\n",
            "Batch 901/1041, Loss: 0.3991630971431732, Acc: 0.875\n",
            "Batch 902/1041, Loss: 0.32572630047798157, Acc: 0.90625\n",
            "Batch 903/1041, Loss: 0.3378470242023468, Acc: 0.9375\n",
            "Batch 904/1041, Loss: 0.30231335759162903, Acc: 0.90625\n",
            "Batch 905/1041, Loss: 0.25076979398727417, Acc: 0.90625\n",
            "Batch 906/1041, Loss: 0.17452771961688995, Acc: 0.9375\n",
            "Batch 907/1041, Loss: 0.44363701343536377, Acc: 0.84375\n",
            "Batch 908/1041, Loss: 0.4153980314731598, Acc: 0.8125\n",
            "Batch 909/1041, Loss: 0.40390560030937195, Acc: 0.90625\n",
            "Batch 910/1041, Loss: 0.5747979283332825, Acc: 0.71875\n",
            "Batch 911/1041, Loss: 0.21781226992607117, Acc: 0.90625\n",
            "Batch 912/1041, Loss: 0.37553873658180237, Acc: 0.84375\n",
            "Batch 913/1041, Loss: 0.24976316094398499, Acc: 0.875\n",
            "Batch 914/1041, Loss: 0.263728529214859, Acc: 0.90625\n",
            "Batch 915/1041, Loss: 0.27749359607696533, Acc: 0.90625\n",
            "Batch 916/1041, Loss: 0.29816025495529175, Acc: 0.90625\n",
            "Batch 917/1041, Loss: 0.3041643500328064, Acc: 0.875\n",
            "Batch 918/1041, Loss: 0.2003309279680252, Acc: 0.96875\n",
            "[Update 3000] Train Loss: 0.2003, Train Acc: 0.9688 | Val Loss: 0.3287, Val Acc: 0.8665\n",
            "Batch 919/1041, Loss: 0.5734463930130005, Acc: 0.75\n",
            "Batch 920/1041, Loss: 0.4387003183364868, Acc: 0.78125\n",
            "Batch 921/1041, Loss: 0.43209654092788696, Acc: 0.84375\n",
            "Batch 922/1041, Loss: 0.17312844097614288, Acc: 0.96875\n",
            "Batch 923/1041, Loss: 0.54261714220047, Acc: 0.78125\n",
            "Batch 924/1041, Loss: 0.2103317379951477, Acc: 0.9375\n",
            "Batch 925/1041, Loss: 0.2776806652545929, Acc: 0.875\n",
            "Batch 926/1041, Loss: 0.4938926696777344, Acc: 0.6875\n",
            "Batch 927/1041, Loss: 0.13025730848312378, Acc: 0.9375\n",
            "Batch 928/1041, Loss: 0.2564680874347687, Acc: 0.90625\n",
            "Batch 929/1041, Loss: 0.2521461546421051, Acc: 0.84375\n",
            "Batch 930/1041, Loss: 0.27567774057388306, Acc: 0.90625\n",
            "Batch 931/1041, Loss: 0.22278031706809998, Acc: 0.90625\n",
            "Batch 932/1041, Loss: 0.5494899749755859, Acc: 0.8125\n",
            "Batch 933/1041, Loss: 0.4686875343322754, Acc: 0.8125\n",
            "Batch 934/1041, Loss: 0.2468802034854889, Acc: 0.84375\n",
            "Batch 935/1041, Loss: 0.360114187002182, Acc: 0.8125\n",
            "Batch 936/1041, Loss: 0.3236873745918274, Acc: 0.90625\n",
            "Batch 937/1041, Loss: 0.3276081383228302, Acc: 0.8125\n",
            "Batch 938/1041, Loss: 0.37424173951148987, Acc: 0.78125\n",
            "Batch 939/1041, Loss: 0.602383017539978, Acc: 0.71875\n",
            "Batch 940/1041, Loss: 0.2764756977558136, Acc: 0.90625\n",
            "Batch 941/1041, Loss: 0.2632640600204468, Acc: 0.90625\n",
            "Batch 942/1041, Loss: 0.43051281571388245, Acc: 0.84375\n",
            "Batch 943/1041, Loss: 0.47551146149635315, Acc: 0.75\n",
            "Batch 944/1041, Loss: 0.3363819122314453, Acc: 0.84375\n",
            "Batch 945/1041, Loss: 0.24570128321647644, Acc: 0.90625\n",
            "Batch 946/1041, Loss: 0.19585078954696655, Acc: 0.9375\n",
            "Batch 947/1041, Loss: 0.3344569206237793, Acc: 0.8125\n",
            "Batch 948/1041, Loss: 0.31387096643447876, Acc: 0.8125\n",
            "Batch 949/1041, Loss: 0.18916404247283936, Acc: 0.96875\n",
            "Batch 950/1041, Loss: 0.23984535038471222, Acc: 0.9375\n",
            "Batch 951/1041, Loss: 0.2339361608028412, Acc: 0.9375\n",
            "Batch 952/1041, Loss: 0.25948384404182434, Acc: 0.90625\n",
            "Batch 953/1041, Loss: 0.6312482357025146, Acc: 0.78125\n",
            "Batch 954/1041, Loss: 0.46115022897720337, Acc: 0.8125\n",
            "Batch 955/1041, Loss: 0.3410617709159851, Acc: 0.84375\n",
            "Batch 956/1041, Loss: 0.15138453245162964, Acc: 0.96875\n",
            "Batch 957/1041, Loss: 0.26559069752693176, Acc: 0.84375\n",
            "Batch 958/1041, Loss: 0.26665791869163513, Acc: 0.9375\n",
            "Batch 959/1041, Loss: 0.20638591051101685, Acc: 0.9375\n",
            "Batch 960/1041, Loss: 0.2798237204551697, Acc: 0.875\n",
            "Batch 961/1041, Loss: 0.35602790117263794, Acc: 0.90625\n",
            "Batch 962/1041, Loss: 0.11408106982707977, Acc: 1.0\n",
            "Batch 963/1041, Loss: 0.2512516975402832, Acc: 0.90625\n",
            "Batch 964/1041, Loss: 0.4046677052974701, Acc: 0.8125\n",
            "Batch 965/1041, Loss: 0.36855390667915344, Acc: 0.8125\n",
            "Batch 966/1041, Loss: 0.40807223320007324, Acc: 0.8125\n",
            "Batch 967/1041, Loss: 0.415192186832428, Acc: 0.84375\n",
            "Batch 968/1041, Loss: 0.23287424445152283, Acc: 0.90625\n",
            "Batch 969/1041, Loss: 0.2554025948047638, Acc: 0.90625\n",
            "Batch 970/1041, Loss: 0.28417354822158813, Acc: 0.875\n",
            "Batch 971/1041, Loss: 0.3405379354953766, Acc: 0.84375\n",
            "Batch 972/1041, Loss: 0.36307084560394287, Acc: 0.875\n",
            "Batch 973/1041, Loss: 0.20280663669109344, Acc: 0.90625\n",
            "Batch 974/1041, Loss: 0.3262019157409668, Acc: 0.875\n",
            "Batch 975/1041, Loss: 0.3983258605003357, Acc: 0.75\n",
            "Batch 976/1041, Loss: 0.25998640060424805, Acc: 0.90625\n",
            "Batch 977/1041, Loss: 0.17807939648628235, Acc: 0.9375\n",
            "Batch 978/1041, Loss: 0.4233222007751465, Acc: 0.78125\n",
            "Batch 979/1041, Loss: 0.19572332501411438, Acc: 0.9375\n",
            "Batch 980/1041, Loss: 0.32064488530158997, Acc: 0.84375\n",
            "Batch 981/1041, Loss: 0.2540501058101654, Acc: 0.90625\n",
            "Batch 982/1041, Loss: 0.21668142080307007, Acc: 0.90625\n",
            "Batch 983/1041, Loss: 0.4285256862640381, Acc: 0.8125\n",
            "Batch 984/1041, Loss: 0.3084332048892975, Acc: 0.875\n",
            "Batch 985/1041, Loss: 0.17360499501228333, Acc: 0.96875\n",
            "Batch 986/1041, Loss: 0.4931463897228241, Acc: 0.78125\n",
            "Batch 987/1041, Loss: 0.21948237717151642, Acc: 0.9375\n",
            "Batch 988/1041, Loss: 0.34682130813598633, Acc: 0.84375\n",
            "Batch 989/1041, Loss: 0.36805081367492676, Acc: 0.78125\n",
            "Batch 990/1041, Loss: 0.18484462797641754, Acc: 0.90625\n",
            "Batch 991/1041, Loss: 0.24847739934921265, Acc: 0.90625\n",
            "Batch 992/1041, Loss: 0.25849148631095886, Acc: 0.90625\n",
            "Batch 993/1041, Loss: 0.16089071333408356, Acc: 0.96875\n",
            "Batch 994/1041, Loss: 0.4727516174316406, Acc: 0.78125\n",
            "Batch 995/1041, Loss: 0.2873065173625946, Acc: 0.875\n",
            "Batch 996/1041, Loss: 0.24774189293384552, Acc: 0.875\n",
            "Batch 997/1041, Loss: 0.41565507650375366, Acc: 0.78125\n",
            "Batch 998/1041, Loss: 0.35525932908058167, Acc: 0.84375\n",
            "Batch 999/1041, Loss: 0.20639096200466156, Acc: 0.90625\n",
            "Batch 1000/1041, Loss: 0.27147501707077026, Acc: 0.875\n",
            "Batch 1001/1041, Loss: 0.348178893327713, Acc: 0.8125\n",
            "Batch 1002/1041, Loss: 0.320597767829895, Acc: 0.8125\n",
            "Batch 1003/1041, Loss: 0.29035013914108276, Acc: 0.875\n",
            "Batch 1004/1041, Loss: 0.2658535838127136, Acc: 0.875\n",
            "Batch 1005/1041, Loss: 0.32174062728881836, Acc: 0.875\n",
            "Batch 1006/1041, Loss: 0.25002825260162354, Acc: 0.84375\n",
            "Batch 1007/1041, Loss: 0.47016918659210205, Acc: 0.84375\n",
            "Batch 1008/1041, Loss: 0.19796359539031982, Acc: 0.9375\n",
            "Batch 1009/1041, Loss: 0.37725409865379333, Acc: 0.75\n",
            "Batch 1010/1041, Loss: 0.42625561356544495, Acc: 0.8125\n",
            "Batch 1011/1041, Loss: 0.3251427412033081, Acc: 0.8125\n",
            "Batch 1012/1041, Loss: 0.2877955734729767, Acc: 0.84375\n",
            "Batch 1013/1041, Loss: 0.38270333409309387, Acc: 0.84375\n",
            "Batch 1014/1041, Loss: 0.24924589693546295, Acc: 0.9375\n",
            "Batch 1015/1041, Loss: 0.32926324009895325, Acc: 0.8125\n",
            "Batch 1016/1041, Loss: 0.1701951026916504, Acc: 0.90625\n",
            "Batch 1017/1041, Loss: 0.1923590749502182, Acc: 0.9375\n",
            "Batch 1018/1041, Loss: 0.42820924520492554, Acc: 0.8125\n",
            "[Update 3100] Train Loss: 0.4282, Train Acc: 0.8125 | Val Loss: 0.3068, Val Acc: 0.8772\n",
            "Batch 1019/1041, Loss: 0.45096874237060547, Acc: 0.8125\n",
            "Batch 1020/1041, Loss: 0.27194762229919434, Acc: 0.84375\n",
            "Batch 1021/1041, Loss: 0.30888351798057556, Acc: 0.84375\n",
            "Batch 1022/1041, Loss: 0.26610708236694336, Acc: 0.9375\n",
            "Batch 1023/1041, Loss: 0.286307692527771, Acc: 0.84375\n",
            "Batch 1024/1041, Loss: 0.4373771548271179, Acc: 0.8125\n",
            "Batch 1025/1041, Loss: 0.35479599237442017, Acc: 0.90625\n",
            "Batch 1026/1041, Loss: 0.43336018919944763, Acc: 0.8125\n",
            "Batch 1027/1041, Loss: 0.3366447985172272, Acc: 0.78125\n",
            "Batch 1028/1041, Loss: 0.24344173073768616, Acc: 0.9375\n",
            "Batch 1029/1041, Loss: 0.34012728929519653, Acc: 0.90625\n",
            "Batch 1030/1041, Loss: 0.19944868981838226, Acc: 0.96875\n",
            "Batch 1031/1041, Loss: 0.3079889714717865, Acc: 0.875\n",
            "Batch 1032/1041, Loss: 0.5667015314102173, Acc: 0.78125\n",
            "Batch 1033/1041, Loss: 0.3847939074039459, Acc: 0.8125\n",
            "Batch 1034/1041, Loss: 0.410524845123291, Acc: 0.8125\n",
            "Batch 1035/1041, Loss: 0.23192760348320007, Acc: 0.90625\n",
            "Batch 1036/1041, Loss: 0.14059734344482422, Acc: 0.96875\n",
            "Batch 1037/1041, Loss: 0.245921790599823, Acc: 0.9375\n",
            "Batch 1038/1041, Loss: 0.3317616879940033, Acc: 0.8125\n",
            "Batch 1039/1041, Loss: 0.12792740762233734, Acc: 0.96875\n",
            "Batch 1040/1041, Loss: 0.18548984825611115, Acc: 0.90625\n",
            "Batch 1041/1041, Loss: 0.2225906401872635, Acc: 0.9130434782608695\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache() # clear CUDA cache before training\n",
        "\n",
        "train_losses, train_accs, val_losses, val_accs = train_model(\n",
        "    model, train_loader, validation_loader, custom_criterion, optimizer, epochs=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kSuTi4krKld3",
      "metadata": {
        "id": "kSuTi4krKld3"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "KSkfReiWEljU",
      "metadata": {
        "id": "KSkfReiWEljU"
      },
      "outputs": [],
      "source": [
        "## Load in saved loss and accuracy values\n",
        "\n",
        "# step_df = pd.read_csv(\"step_losses.csv\")\n",
        "# update_df = pd.read_csv(\"update_losses.csv\")\n",
        "\n",
        "# train_losses = step_df[\"train_loss\"].to_numpy()\n",
        "# train_accs = step_df[\"train_accuracy\"].to_numpy()\n",
        "\n",
        "# val_losses = update_df[\"val_loss\"].to_numpy()\n",
        "# val_accs = update_df[\"val_acc\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4ad096cb",
      "metadata": {
        "id": "4ad096cb"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"CLIP_QKV_metrics.pkl\", \"wb\") as f:\n",
        "    pickle.dump({\n",
        "        \"train_losses\": train_losses,\n",
        "        \"train_accs\": train_accs,\n",
        "        \"val_losses\": val_losses,\n",
        "        \"val_accs\": val_accs\n",
        "    }, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2141bcf0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "2141bcf0",
        "outputId": "abe0685a-fc31-4cb2-ab21-ad5b973aadd8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "axs[0, 0].plot(train_losses)\n",
        "axs[0, 0].set_title(\"Train Losses\")\n",
        "\n",
        "axs[0, 1].plot(train_accs)\n",
        "axs[0, 1].set_title(\"Train Accuracies\")\n",
        "\n",
        "axs[1, 0].plot(val_losses)\n",
        "axs[1, 0].set_title(\"Validation Losses\")\n",
        "\n",
        "axs[1, 1].plot(val_accs)\n",
        "axs[1, 1].set_title(\"Validation Accuracies\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d52e4c74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d52e4c74",
        "outputId": "143ac308-a1ad-4fad-9f59-472b46285091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Val Accuracy: 0.8771508603441377\n"
          ]
        }
      ],
      "source": [
        "print(f\"Final Val Accuracy: {val_accs[-1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ccbf132e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ccbf132e",
        "outputId": "21ccb23a-e620-4a1d-eb2f-400fc071ab8e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Smooth the train losses\n",
        "window = 10\n",
        "smooth_train_losses = pd.Series(train_losses).rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_losses, alpha=0.3, label=\"Original Train Loss\")\n",
        "plt.plot(smooth_train_losses, color='red', label=\"Smoothed Train Loss\")\n",
        "plt.title(\"Train Losses (Original vs Smoothed)\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "4c923bc4",
      "metadata": {
        "id": "4c923bc4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics(logits, labels):\n",
        "    logits = np.array(logits)\n",
        "    labels = np.array(labels)\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, predictions),\n",
        "\n",
        "        \"pos_precision\": precision_score(labels, predictions, pos_label=1, average=\"binary\", zero_division=0),\n",
        "        \"pos_recall\": recall_score(labels, predictions, pos_label=1, average=\"binary\", zero_division=0),\n",
        "        \"pos_f1\": f1_score(labels, predictions, pos_label=1, average=\"binary\", zero_division=0),\n",
        "\n",
        "        \"neg_precision\": precision_score(labels, predictions, pos_label=0, average=\"binary\", zero_division=0),\n",
        "        \"neg_recall\": recall_score(labels, predictions, pos_label=0, average=\"binary\", zero_division=0),\n",
        "        \"neg_f1\": f1_score(labels, predictions, pos_label=0, average=\"binary\", zero_division=0),\n",
        "\n",
        "        \"f1_macro\": f1_score(labels, predictions, average=\"macro\"),\n",
        "        \"f1_micro\": f1_score(labels, predictions, average=\"micro\"),\n",
        "        \"f1_weighted\": f1_score(labels, predictions, average=\"weighted\"),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8b647528",
      "metadata": {
        "id": "8b647528"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for txts, imgs, labels in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(txts, imgs)      # logits\n",
        "            all_logits.append(outputs.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    all_logits = np.concatenate(all_logits, axis=0)\n",
        "    all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    return compute_metrics(all_logits, all_labels)\n",
        "\n",
        "\n",
        "\n",
        "def print_metrics(name, metrics):\n",
        "    print(f\"\\n===== {name} Metrics =====\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k:15s} : {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "383d5992",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "383d5992",
        "outputId": "4fd6902e-2db1-49d9-adb8-b077c694a749"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/lib/python3.12/site-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/lib/python3.12/site-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== TRAIN Metrics =====\n",
            "accuracy        : 0.9001\n",
            "pos_precision   : 0.9008\n",
            "pos_recall      : 0.9210\n",
            "pos_f1          : 0.9108\n",
            "neg_precision   : 0.8992\n",
            "neg_recall      : 0.8742\n",
            "neg_f1          : 0.8865\n",
            "f1_macro        : 0.8986\n",
            "f1_micro        : 0.9001\n",
            "f1_weighted     : 0.8999\n",
            "\n",
            "===== VALIDATION Metrics =====\n",
            "accuracy        : 0.8780\n",
            "pos_precision   : 0.8766\n",
            "pos_recall      : 0.9076\n",
            "pos_f1          : 0.8918\n",
            "neg_precision   : 0.8798\n",
            "neg_recall      : 0.8410\n",
            "neg_f1          : 0.8600\n",
            "f1_macro        : 0.8759\n",
            "f1_micro        : 0.8780\n",
            "f1_weighted     : 0.8776\n",
            "\n",
            "===== TEST Metrics =====\n",
            "accuracy        : 0.8651\n",
            "pos_precision   : 0.8709\n",
            "pos_recall      : 0.8891\n",
            "pos_f1          : 0.8799\n",
            "neg_precision   : 0.8575\n",
            "neg_recall      : 0.8351\n",
            "neg_f1          : 0.8461\n",
            "f1_macro        : 0.8630\n",
            "f1_micro        : 0.8651\n",
            "f1_weighted     : 0.8649\n"
          ]
        }
      ],
      "source": [
        "# Load best checkpoint before evaluation\n",
        "model.load_state_dict(torch.load(\"Milestone_4/best_model_QKV.pt\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate\n",
        "train_metrics = evaluate_model(model, train_loader)\n",
        "val_metrics   = evaluate_model(model, validation_loader)\n",
        "test_metrics  = evaluate_model(model, test_loader)\n",
        "\n",
        "print_metrics(\"TRAIN\", train_metrics)\n",
        "print_metrics(\"VALIDATION\", val_metrics)\n",
        "print_metrics(\"TEST\", test_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "fU4vTluzNUkw",
      "metadata": {
        "id": "fU4vTluzNUkw"
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "pd.DataFrame([train_metrics]).to_csv(\"FND_CLIP_QKV_train_metrics.csv\", index=False)\n",
        "pd.DataFrame([val_metrics]).to_csv(\"FND_CLIP_QKV_val_metrics.csv\", index=False)\n",
        "pd.DataFrame([test_metrics]).to_csv(\"FND_CLIP_QKV_test_metrics.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eb1533e8",
        "6bb63096",
        "b3590e75"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
